<!doctype html><html lang=vi dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=54532&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu | The Financial Engineer</title>
<meta name=keywords content><meta name=description content="3 cách ước lượng hệ số beta của cổ phiếu"><meta name=author content><link rel=canonical href=http://localhost:54532/posts/2024/2024-10-10-linear-regression/my-first-post/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:54532/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:54532/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:54532/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:54532/apple-touch-icon.png><link rel=mask-icon href=http://localhost:54532/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=vi href=http://localhost:54532/posts/2024/2024-10-10-linear-regression/my-first-post/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu"><meta property="og:description" content="3 cách ước lượng hệ số beta của cổ phiếu"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:54532/posts/2024/2024-10-10-linear-regression/my-first-post/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-10T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-10T00:00:00+00:00"><meta property="og:site_name" content="QHung's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu"><meta name=twitter:description content="3 cách ước lượng hệ số beta của cổ phiếu"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu","item":"http://localhost:54532/posts/2024/2024-10-10-linear-regression/my-first-post/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu","name":"Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu","description":"3 cách ước lượng hệ số beta của cổ phiếu","keywords":[],"articleBody":"Hôm nay, chúng ta sẽ cùng nhau thảo luận về các phương pháp khác nhau để giải quyết bài toán Linear regression - Hồi quy tuyến tính.\nVậy Linear regression là gì? Hồi quy tuyến tính là phương pháp thống kê dùng để mô hình hóa mối quan hệ giữa biến phụ thuộc và các biến độc lập. Hay nói cách khác, hồi quy tuyến tính là đi tìm mối quan hệ tuyến tính (y=ax+b) giữa 2 biến với nhau.\nỞ bài này, tôi sẽ không bàn luận sâu về toán, các bạn có thể đọc ở đây để nắm lý thuyết cần thiết link. Thay vào đó, bài viết này sẽ đi thực hiện bài toán đơn giản này theo 3 cách tiếp cận khác nhau:\nSử dụng linear algebra để tính trực tiếp Thông qua deep learning, sử dụng đạo hàm Thông qua bayesian inference, sử dụng phương pháp lấy mẫu (sampling) Ngoài ra, bài viết sẽ áp dụng phương pháp này để đi xác định hệ số Beta cho cổ phiếu HPG. Các bạn có thể đọc về beta tại đây.\nỞ bài toán này, dữ liệu X sẽ là VNINDEX, trong khi y sẽ là HPG.\nVề mặt tài chính, điều này có thể được xem như là ước tính rủi ro thị trường, hay rủi ro hệ thống (market risk, systematic risk) cho HPG.\n1. Tính trực tiếp từ dữ liệu Lời giả cho phương pháp này là:\n$$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top y $$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Algebra_linear_regression: def __init__(self): self.coef_ = None self.intercept_ = None def fit(self, X, y): X = np.array(X) y = np.array(y) X = np.c_[np.ones(X.shape[0]), X] self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y self.intercept_ = self.coef_[0] self.coef_ = self.coef_[1:] def predict(self, X): X = np.array(X) return X @ self.coef_ + self.intercept_ def score(self, X, y): X = np.array(X) y = np.array(y) y_pred = self.predict(X) return 1 - ((y - y_pred) ** 2).sum() / ((y - y.mean()) ** 2).sum() model = Algebra_linear_regression() model.fit(X,y) model.coef_.round(3), model.intercept_.round(4) -\u003e output: (array([[1.23]]), array([0.0005])) Từ phương pháp này, ta có thể ước lượng được rằng hệ số beta cho cổ phiếu HPG là 1.23 tương ứng với việc rủi ro thị trường tương đối cao.\n2. Sử dụng deep learning Deep learning cũng là một trong những phương pháp thông dụng có thể được sử dụng trong bài toán này. Thông qua thuật toán Gradient Descent, ta có đi tìm bộ tham số phù hợp với hàm mất mát (loss function) là thấp nhất.\nQuá trình đi tìm điểm tối ưu của bài toán này giống như khi bạn đi xuống núi. Ban đầu, bạn sẽ bắt đầu ở một điểm nào đó, tại mỗi điểm bạn sẽ luôn biết nên đi hướng nào. Mục tiêu của bạn sẽ đi xuống núi từng bước nhỏ một. Bạn cứ liên tục đi cho đến khi bạn đạt đến điểm trũng của thung lũng!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import torch import torch.nn as nn # Create class class LinearRegressionModel(nn.Module): def __init__(self, input_dim, output_dim): super(LinearRegressionModel, self).__init__() self.linear = nn.Linear(input_dim, output_dim) def forward(self, x): out = self.linear(x) return out input_dim = 1 output_dim = 1 model = LinearRegressionModel(input_dim, output_dim) criterion = nn.MSELoss() learning_rate = 0.001 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) epochs = 1000 losses = [] # List to store loss at each epoch for epoch in range(epochs): epoch += 1 # Convert numpy array to torch Variable inputs = torch.from_numpy(X).requires_grad_() labels = torch.from_numpy(y) # Clear gradients w.r.t. parameters optimizer.zero_grad() # Forward to get output outputs = model(inputs) # Calculate Loss loss = criterion(outputs, labels) # Getting gradients w.r.t. parameters loss.backward() # Updating parameters optimizer.step() losses.append(loss.item()) print('epoch {}, loss {}'.format(epoch, loss.item())) Thông qua phương pháp này, ta cũng tìm được mối quan hệ giống hệt với phương pháp tính trực tiếp!\n3. Bayesian linear regression Thay vì chỉ đưa ra một giá trị cố định cho các hệ số như hồi quy tuyến tính thông thường, phương pháp bayes coi các hệ số là những giá trị có thể thay đổi và có xác suất xảy ra. Ban đầu, ta có một “niềm tin” về các tham số này (prior). Khi thu thập thêm dữ liệu, ta sẽ cập nhật niềm tin đó, từ đó giúp dự đoán chính xác hơn và biết mức độ chắc chắn của các kết quả (posterior). Khoá Coursera này sẽ cho bạn cái nhìn kĩ hơn về phương pháp này.\nĐể hiểu đơn giản hơn, ta có một ví dụ này: Với 2 phương pháp trên, hệ số beta của HPG là 1.23. Vậy có bao nhiêu phần trăm (%) hệ số beta là 1.23, hệ số beta lớn hơn 1 với độ tự tin bao nhiêu phần trăm (%)? Giá trị của hệ số beta của HPG có thể nhận từ đâu tới đâu với độ tư tin là bao nhiêu phần trăm (%)?\nĐây là một trong những vấn đề có thể được giải quyết thông qua phương pháp Bayes. Bạn có thể đọc kĩ hơn về ý tưởng đằng sau phương pháp này tại đây.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def numpyro_model(X, y): # Priors for the parameters num_features = X.shape[1] beta = numpyro.sample(\"beta\", dist.Normal(0,1)) # Coefficients intercept = numpyro.sample(\"intercept\", dist.Normal(0, 1)) # Intercept sigma = numpyro.sample(\"sigma\", dist.Normal(0,1)) # Noise level # Linear model mean = jnp.dot(X, beta) + intercept # Likelihood numpyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y) # Instantiate a `MCMC` object using a NUTS sampler mcmc = MCMC(sampler=NUTS(numpyro_model), num_warmup=1000, num_samples=1000, num_chains=4) # Run the MCMC sampler and collect samples mcmc.run(rng_key=random.PRNGKey(seed=42), X=X, y=y) az.plot_trace(mcmc, var_names=['intercept', 'beta', 'sigma'], figsize=(9,9)); $$ Y = \\beta_0 + \\beta_1 X + \\epsilon $$\nPhương pháp biểu diễn các biến trong Bayesian inference (plate notion). Ở bài toán này, ta sẽ có 3 biến chính: beta, intercept và sigma. Tất cả đều được giả định là phân phối chuẩn.\nmean std median 5.0% 95.0% n_eff r_hat beta 1.23 0.03 1.23 1.18 1.28 734.39 1.01 intercept 0.00 0.00 0.00 -0.00 0.00 3212.78 1.00 sigma 0.02 0.00 0.02 0.02 0.02 5063.55 1.00 Hình này được gọi là trace plot. Phương pháp này được dùng để đánh giá quá trình hội tụ của mô hình Bayes. Cột bên trái cho ta thấy phân phối, trong khi bên phải cho ta thấy sự giao động của các tham số.\nTừ kết quả mô hình trên, ta ra được kết luận rằng, hệ số beta trung bình cho cổ phiếu HPG cũng. là 1.23, tuy nhiên, ta có thể tự tin nói rằng, 90% trường hợp hệ số này sẽ trong vùng 1.18 - 1.23.\nKết luận Vậy, từ 3 phương pháp trên ta đều tiếp nhận chung 1 kết quả, tuy nhiên, mỗi phương pháp có cái hay riêng.\nVới phương pháp tính toán trực tiếp, ta có thể dễ dàng tính toán ra được đáp án với độ phức tạp là thấp nhất. Tuy nhiên, với những trường hợp mà dữ liệu là không khả nghịch (singular), thì bài toán có khả năng không có khả năng giải được theo phương pháp này (analytical solution).\nNgược lại, với phương pháp deep learning, ta có thể dễ dàng xử lý các bài toán khi không thể giải trực tiếp (analytical solution). Thông qua Gradient Descent, ta có thể ước tính được các điểm tối ưu, tuy nhiên đi kèm với đó là yêu cầu tính toán lớn hơn nhiều (computational cost).\nCuối cùng, phương pháp Bayesian có thể được sử dụng khi ta mong muốn đưa niềm tin của ta vào mô hình, cũng như đầu ra mong muốn là một phân phối các kết quả có thể xảy ra thay vì chỉ muốn một điểm ước lượng duy nhất. Quan trọng nhất là mô hình hoá được độ không chắc chắn (uncertainty).\nVà tất nhiên, 2 phương pháp sau là phức tạp hoá vấn đề cho bài toán đơn giản này. Tuy nhiên, để gần gũi nhất thì mình chọn ước lượng beta cho dễ hình dung!\n","wordCount":"1416","inLanguage":"vi","datePublished":"2024-05-10T00:00:00Z","dateModified":"2024-05-10T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:54532/posts/2024/2024-10-10-linear-regression/my-first-post/"},"publisher":{"@type":"Organization","name":"The Financial Engineer","logo":{"@type":"ImageObject","url":"http://localhost:54532/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:54532/ accesskey=h title="The Financial Engineer (Alt + H)">The Financial Engineer</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:54532/about/ title=About><span>About</span></a></li><li><a href=http://localhost:54532/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:54532/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:54532/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu</h1><div class=post-description>3 cách ước lượng hệ số beta của cổ phiếu</div><div class=post-meta><span title='2024-05-10 00:00:00 +0000 UTC'>tháng 5 10, 2024</span>&nbsp;·&nbsp;7 phút</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Mục lục</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#vậy-linear-regression-là-gì>Vậy Linear regression là gì?</a><ul><li><a href=#1-tính-trực-tiếp-từ-dữ-liệu>1. Tính trực tiếp từ dữ liệu</a></li><li><a href=#2-sử-dụng-deep-learning>2. Sử dụng deep learning</a></li><li><a href=#3-bayesian-linear-regression>3. Bayesian linear regression</a></li></ul></li><li><a href=#kết-luận>Kết luận</a></li></ul></nav></div></details></div><div class=post-content><p>Hôm nay, chúng ta sẽ cùng nhau thảo luận về các phương pháp khác nhau để giải quyết bài toán Linear regression - Hồi quy tuyến tính.</p><h2 id=vậy-linear-regression-là-gì>Vậy Linear regression là gì?<a hidden class=anchor aria-hidden=true href=#vậy-linear-regression-là-gì>#</a></h2><p>Hồi quy tuyến tính là phương pháp thống kê dùng để mô hình hóa mối quan hệ giữa biến phụ thuộc và các biến độc lập. Hay nói cách khác, hồi quy tuyến tính là đi tìm mối quan hệ tuyến tính (y=ax+b) giữa 2 biến với nhau.</p><p>Ở bài này, tôi sẽ không bàn luận sâu về toán, các bạn có thể đọc ở đây để nắm lý thuyết cần thiết <a href=https://machinelearningcoban.com/2016/12/28/linearregression/>link</a>. Thay vào đó, bài viết này sẽ đi thực hiện bài toán đơn giản này theo 3 cách tiếp cận khác nhau:</p><ul><li>Sử dụng linear algebra để tính trực tiếp</li><li>Thông qua deep learning, sử dụng đạo hàm</li><li>Thông qua bayesian inference, sử dụng phương pháp lấy mẫu (sampling)</li></ul><p>Ngoài ra, bài viết sẽ áp dụng phương pháp này để đi xác định hệ số Beta cho cổ phiếu HPG. Các bạn có thể đọc về beta <a href=https://www.cmcmarkets.com/en/trading-guides/stock-beta>tại đây.</a></p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/aa1a6827-2040-4e67-b875-a97a4ce67237/image.png alt=image.png></p><p>Ở bài toán này, dữ liệu X sẽ là VNINDEX, trong khi y sẽ là HPG.</p><p>Về mặt tài chính, điều này có thể được xem như là ước tính rủi ro thị trường, hay rủi ro hệ thống (market risk, systematic risk) cho HPG.</p><h3 id=1-tính-trực-tiếp-từ-dữ-liệu>1. Tính trực tiếp từ dữ liệu<a hidden class=anchor aria-hidden=true href=#1-tính-trực-tiếp-từ-dữ-liệu>#</a></h3><p>Lời giả cho phương pháp này là:</p><p>$$
\hat{\beta} = (X^\top X)^{-1} X^\top y 
$$</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Algebra_linear_regression</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>coef_ <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>intercept_ <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X, y):
</span></span><span style=display:flex><span>        X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(X)
</span></span><span style=display:flex><span>        y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(y)
</span></span><span style=display:flex><span>        X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>c_[np<span style=color:#f92672>.</span>ones(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]), X]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>coef_ <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linalg<span style=color:#f92672>.</span>inv(X<span style=color:#f92672>.</span>T <span style=color:#f92672>@</span> X) <span style=color:#f92672>@</span> X<span style=color:#f92672>.</span>T <span style=color:#f92672>@</span> y
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>intercept_ <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>coef_[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>coef_ <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>coef_[<span style=color:#ae81ff>1</span>:]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(self, X):
</span></span><span style=display:flex><span>        X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(X)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> X <span style=color:#f92672>@</span> self<span style=color:#f92672>.</span>coef_ <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>intercept_
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>score</span>(self, X, y):
</span></span><span style=display:flex><span>        X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(X)
</span></span><span style=display:flex><span>        y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(y)
</span></span><span style=display:flex><span>        y_pred <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>predict(X)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> ((y <span style=color:#f92672>-</span> y_pred) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)<span style=color:#f92672>.</span>sum() <span style=color:#f92672>/</span> ((y <span style=color:#f92672>-</span> y<span style=color:#f92672>.</span>mean()) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> Algebra_linear_regression()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X,y)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>coef_<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>3</span>), model<span style=color:#f92672>.</span>intercept_<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>-&gt;</span> output: (array([[<span style=color:#ae81ff>1.23</span>]]), array([<span style=color:#ae81ff>0.0005</span>]))
</span></span></code></pre></td></tr></table></div></div><p>Từ phương pháp này, ta có thể ước lượng được rằng hệ số beta cho cổ phiếu HPG là 1.23 tương ứng với việc rủi ro thị trường tương đối cao.</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/6be25b4e-c706-4365-99c9-006283ac3af2/image.png alt=image.png></p><h3 id=2-sử-dụng-deep-learning>2. Sử dụng deep learning<a hidden class=anchor aria-hidden=true href=#2-sử-dụng-deep-learning>#</a></h3><p>Deep learning cũng là một trong những phương pháp thông dụng có thể được sử dụng trong bài toán này. Thông qua thuật toán <strong>Gradient Descent,</strong> ta có đi tìm bộ tham số phù hợp với hàm mất mát (loss function) là thấp nhất.</p><p>Quá trình đi tìm điểm tối ưu của bài toán này giống như khi bạn đi xuống núi. Ban đầu, bạn sẽ bắt đầu ở một điểm nào đó, tại mỗi điểm bạn sẽ luôn biết nên đi hướng nào. Mục tiêu của bạn sẽ đi xuống núi từng bước nhỏ một. Bạn cứ liên tục đi cho đến khi bạn đạt đến điểm trũng của thung lũng!</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/30b53a00-7c02-46af-b233-d5cfa5aae37b/Screenshot_2024-10-05_at_21.09.24.png alt="Screenshot 2024-10-05 at 21.09.24.png"></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create class</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LinearRegressionModel</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, input_dim, output_dim):
</span></span><span style=display:flex><span>        super(LinearRegressionModel, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>linear <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(input_dim, output_dim)  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>linear(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>input_dim <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>output_dim <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegressionModel(input_dim, output_dim)
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MSELoss()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>learning_rate <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.001</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span>learning_rate)
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>losses <span style=color:#f92672>=</span> []  <span style=color:#75715e># List to store loss at each epoch</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(epochs):
</span></span><span style=display:flex><span>    epoch <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Convert numpy array to torch Variable</span>
</span></span><span style=display:flex><span>    inputs <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(X)<span style=color:#f92672>.</span>requires_grad_()
</span></span><span style=display:flex><span>    labels <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Clear gradients w.r.t. parameters</span>
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>zero_grad() 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Forward to get output</span>
</span></span><span style=display:flex><span>    outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Calculate Loss</span>
</span></span><span style=display:flex><span>    loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Getting gradients w.r.t. parameters</span>
</span></span><span style=display:flex><span>    loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Updating parameters</span>
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>    losses<span style=color:#f92672>.</span>append(loss<span style=color:#f92672>.</span>item())
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;epoch </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>, loss </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(epoch, loss<span style=color:#f92672>.</span>item()))
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/477d75b8-e3be-4cb3-aae4-b5e6e4b0a155/image.png alt=image.png></p><p>Thông qua phương pháp này, ta cũng tìm được mối quan hệ giống hệt với phương pháp tính trực tiếp!</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/8c9a435b-de55-4e3e-b1da-3c661c67cb31/image.png alt=image.png></p><h3 id=3-bayesian-linear-regression>3. Bayesian linear regression<a hidden class=anchor aria-hidden=true href=#3-bayesian-linear-regression>#</a></h3><p>Thay vì chỉ đưa ra một giá trị cố định cho các hệ số như hồi quy tuyến tính thông thường, phương pháp bayes coi các hệ số là những giá trị có thể thay đổi và có xác suất xảy ra. Ban đầu, ta có một &ldquo;niềm tin&rdquo; về các tham số này (prior). Khi thu thập thêm dữ liệu, ta sẽ cập nhật niềm tin đó, từ đó giúp dự đoán chính xác hơn và biết mức độ chắc chắn của các kết quả (posterior). Khoá <a href="https://www.coursera.org/learn/mcmc-bayesian-statistics?specialization=bayesian-statistics">Coursera</a> này sẽ cho bạn cái nhìn kĩ hơn về phương pháp này.</p><p>Để hiểu đơn giản hơn, ta có một ví dụ này: Với 2 phương pháp trên, hệ số beta của HPG là 1.23. Vậy có bao nhiêu phần trăm (%) hệ số beta là 1.23, hệ số beta lớn hơn 1 với độ tự tin bao nhiêu phần trăm (%)? Giá trị của hệ số beta của HPG có thể nhận từ đâu tới đâu với độ tư tin là bao nhiêu phần trăm (%)?</p><p>Đây là một trong những vấn đề có thể được giải quyết thông qua phương pháp Bayes. Bạn có thể đọc kĩ hơn về ý tưởng đằng sau phương pháp này <a href=https://brunaw.com/phd/bayes-regression/report.pdf>tại đây</a>.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>numpyro_model</span>(X, y):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Priors for the parameters</span>
</span></span><span style=display:flex><span>    num_features <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    beta <span style=color:#f92672>=</span> numpyro<span style=color:#f92672>.</span>sample(<span style=color:#e6db74>&#34;beta&#34;</span>, dist<span style=color:#f92672>.</span>Normal(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>))  <span style=color:#75715e># Coefficients</span>
</span></span><span style=display:flex><span>    intercept <span style=color:#f92672>=</span> numpyro<span style=color:#f92672>.</span>sample(<span style=color:#e6db74>&#34;intercept&#34;</span>, dist<span style=color:#f92672>.</span>Normal(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>))  <span style=color:#75715e># Intercept</span>
</span></span><span style=display:flex><span>    sigma <span style=color:#f92672>=</span> numpyro<span style=color:#f92672>.</span>sample(<span style=color:#e6db74>&#34;sigma&#34;</span>, dist<span style=color:#f92672>.</span>Normal(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>))  <span style=color:#75715e># Noise level</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Linear model</span>
</span></span><span style=display:flex><span>    mean <span style=color:#f92672>=</span> jnp<span style=color:#f92672>.</span>dot(X, beta) <span style=color:#f92672>+</span> intercept
</span></span><span style=display:flex><span>    <span style=color:#75715e># Likelihood</span>
</span></span><span style=display:flex><span>    numpyro<span style=color:#f92672>.</span>sample(<span style=color:#e6db74>&#34;obs&#34;</span>, dist<span style=color:#f92672>.</span>Normal(mean, sigma), obs<span style=color:#f92672>=</span>y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Instantiate a `MCMC` object using a NUTS sampler</span>
</span></span><span style=display:flex><span>mcmc <span style=color:#f92672>=</span> MCMC(sampler<span style=color:#f92672>=</span>NUTS(numpyro_model),
</span></span><span style=display:flex><span>            num_warmup<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>,
</span></span><span style=display:flex><span>            num_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>,
</span></span><span style=display:flex><span>            num_chains<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Run the MCMC sampler and collect samples</span>
</span></span><span style=display:flex><span>mcmc<span style=color:#f92672>.</span>run(rng_key<span style=color:#f92672>=</span>random<span style=color:#f92672>.</span>PRNGKey(seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>),
</span></span><span style=display:flex><span>         X<span style=color:#f92672>=</span>X,
</span></span><span style=display:flex><span>         y<span style=color:#f92672>=</span>y)
</span></span><span style=display:flex><span>         
</span></span><span style=display:flex><span>az<span style=color:#f92672>.</span>plot_trace(mcmc, var_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;intercept&#39;</span>, <span style=color:#e6db74>&#39;beta&#39;</span>, <span style=color:#e6db74>&#39;sigma&#39;</span>], figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>9</span>,<span style=color:#ae81ff>9</span>));
</span></span></code></pre></td></tr></table></div></div><p>$$
Y = \beta_0 + \beta_1 X + \epsilon
$$</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/4a3c743b-b9af-4521-bf45-53ae8a14b068/Screenshot_2024-10-05_at_21.29.34.png alt="Screenshot 2024-10-05 at 21.29.34.png"></p><p>Phương pháp biểu diễn các biến trong Bayesian inference (plate notion). Ở bài toán này, ta sẽ có 3 biến chính: beta, intercept và sigma. Tất cả đều được giả định là phân phối chuẩn.</p><pre tabindex=0><code>             mean       std    median      5.0%     95.0%     n_eff     r_hat
  beta       1.23      0.03      1.23      1.18      1.28    734.39      1.01
  intercept  0.00      0.00      0.00     -0.00      0.00   3212.78      1.00
	sigma      0.02      0.00      0.02      0.02      0.02   5063.55      1.00
</code></pre><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/1cf09e5d-400c-45e8-9e50-9a24c1fd082a/image.png alt=image.png></p><p>Hình này được gọi là trace plot. Phương pháp này được dùng để đánh giá quá trình hội tụ của mô hình Bayes. Cột bên trái cho ta thấy phân phối, trong khi bên phải cho ta thấy sự giao động của các tham số.</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/db2726b2-db0d-4fb0-83ed-a2bf7b534f5b/image.png alt=image.png></p><p>Từ kết quả mô hình trên, ta ra được kết luận rằng, hệ số beta trung bình cho cổ phiếu HPG cũng. là 1.23, tuy nhiên, ta có thể tự tin nói rằng, 90% trường hợp hệ số này sẽ trong vùng 1.18 - 1.23.</p><p><img loading=lazy src=https://prod-files-secure.s3.us-west-2.amazonaws.com/f36c1e52-f6b6-4d1c-be2b-dc7c016ca43f/d34c5b78-7fe7-4f48-bfb5-90539a56379c/image.png alt=image.png></p><h2 id=kết-luận>Kết luận<a hidden class=anchor aria-hidden=true href=#kết-luận>#</a></h2><p>Vậy, từ 3 phương pháp trên ta đều tiếp nhận chung 1 kết quả, tuy nhiên, mỗi phương pháp có cái hay riêng.</p><p>Với phương pháp tính toán trực tiếp, ta có thể dễ dàng tính toán ra được đáp án với độ phức tạp là thấp nhất. Tuy nhiên, với những trường hợp mà dữ liệu là không khả nghịch (singular), thì bài toán có khả năng không có khả năng giải được theo phương pháp này (analytical solution).</p><p>Ngược lại, với phương pháp deep learning, ta có thể dễ dàng xử lý các bài toán khi không thể giải trực tiếp (analytical solution). Thông qua Gradient Descent, ta có thể ước tính được các điểm tối ưu, tuy nhiên đi kèm với đó là yêu cầu tính toán lớn hơn nhiều (computational cost).</p><p>Cuối cùng, phương pháp Bayesian có thể được sử dụng khi ta mong muốn đưa niềm tin của ta vào mô hình, cũng như đầu ra mong muốn là một phân phối các kết quả có thể xảy ra thay vì chỉ muốn một điểm ước lượng duy nhất. Quan trọng nhất là mô hình hoá được độ không chắc chắn (uncertainty).</p><p>Và tất nhiên, 2 phương pháp sau là phức tạp hoá vấn đề cho bài toán đơn giản này. Tuy nhiên, để gần gũi nhất thì mình chọn ước lượng beta cho dễ hình dung!</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=http://localhost:54532/posts/my-first/><span class=title>Bài cũ hơn »</span><br><span>29 câu lệnh Linux bạn nên biết - Phần 1</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on x" href="https://x.com/intent/tweet/?text=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu&amp;url=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f&amp;title=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu&amp;summary=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu&amp;source=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f&title=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on whatsapp" href="https://api.whatsapp.com/send?text=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu%20-%20http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on telegram" href="https://telegram.me/share/url?text=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu&amp;url=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Linear regression: 3 cách ước lượng hệ số beta của cổ phiếu on ycombinator" href="https://news.ycombinator.com/submitlink?t=Linear%20regression%3a%203%20c%c3%a1ch%20%c6%b0%e1%bb%9bc%20l%c6%b0%e1%bb%a3ng%20h%e1%bb%87%20s%e1%bb%91%20beta%20c%e1%bb%a7a%20c%e1%bb%95%20phi%e1%ba%bfu&u=http%3a%2f%2flocalhost%3a54532%2fposts%2f2024%2f2024-10-10-linear-regression%2fmy-first-post%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:54532/>The Financial Engineer</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Sao chép";function s(){t.innerHTML="Đã sao chép!",setTimeout(()=>{t.innerHTML="Sao chép"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>