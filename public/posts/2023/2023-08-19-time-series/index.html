<!doctype html><html lang=vi dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Time Series | The Financial Engineer</title>
<meta name=keywords content="Time Series,Forecasting,Python"><meta name=description content="My Kaggle Learning Note "><meta name=author content="Kean Teng Blog"><link rel=canonical href=http://localhost:1313/posts/2023/2023-08-19-time-series/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=vi href=http://localhost:1313/posts/2023/2023-08-19-time-series/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Time Series"><meta property="og:description" content="My Kaggle Learning Note "><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/2023/2023-08-19-time-series/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-19T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-19T00:00:00+00:00"><meta property="og:site_name" content="QHung's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Time Series"><meta name=twitter:description content="My Kaggle Learning Note "><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Time Series","item":"http://localhost:1313/posts/2023/2023-08-19-time-series/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Time Series","name":"Time Series","description":"My Kaggle Learning Note ","keywords":["Time Series","Forecasting","Python"],"articleBody":" Disclaimer: This article is my learning note from the courses I took from Kaggle.\nThe most common application of machine learning in the real world is forecasting. For example, businesses forecasting product demand, governments forecasting economic growth and meteorologists forecasting the weather. The understanding of things to come has become a pressing need across the science, government and industry, and machine learning is increasingly being applied to address this need.\nIn this course, we will learn about time series forecasting. We will also learn about:\nEngineering features to model major time series components such as trends, seasons and cycles Visualize time series with plot Create forecasting hybrids (combine the strength of complementary models) Adapt machine learning methods to various forecasting tasks 1. Introduction Basically, a time series is a set of observations recorded over time. The observations are recorded with a regular frequency such as day, week, month, quarter or year. We can use linear regression to build forecasting model for time series data:\ntarget = weight_1 * feature_1 + weight_2 * feature_2 + bias Parameters such as weight_1, weight_2 and bias are learned by the regression algorithm during training.\nThere are two unique features to time series:\nTime-step feature Lag feature Time-step feature can be derived from the time index. The most basic time-step feature is the time dummy that counts time steps in series from the beginning to the end:\n| | Hardcover | Time | |----------|-----------|------| | 1/4/2000 | 139 | 1 | | 2/4/2000 | 219 | 2 | | 3/4/2000 | 135 | 3 | Linear regression with the time dummy produces the model:\ntarget = weight * time + bias In a time plot:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import matplotlib.pyplot as plt import seaborn as sns plt.style.use(\"seaborn-whitegrid\") plt.rc( \"figure\", autolayout=True, figsize=(11, 4), titlesize=18, titleweight='bold', ) plt.rc( \"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlesize=16, titlepad=10, ) %config InlineBackend.figure_format = 'retina' fig, ax = plt.subplots() ax.plot('Time', 'Hardcover', data=df, color='0.75') ax = sns.regplot(x='Time', y='Hardcover', data=df, ci=None, scatter_kws=dict(color='0.25')) ax.set_title('Time Plot of Hardcover Sales'); Time-step features let us model time dependence. A series is time dependent if its value can be predicted from the time they occurred in.\nMoreover, to make a lag feature from the dataset we will shift the observation of the target series so that they appear to have occurred later in time. Here’s a 1-step lag feature:\n| |Hardcover|Lag_1| |------------|---------|-----| |Date | | | |2000-04-01 |139 |NaN | |2000-04-02 |128 |139.0| |2000-04-03\t|172 |128.0| |2000-04-04 |139 |172.0| |2000-04-05 |191 |139.0| Linear regression with the time dummy produces the model:\ntarget = weight * lag + bias In a time plot:\n1 2 3 4 fig, ax = plt.subplots() ax = sns.regplot(x='Lag_1', y='Hardcover', data=df, ci=None, scatter_kws=dict(color='0.25')) ax.set_aspect('equal') ax.set_title('Lag Plot of Hardcover Sales'); From the plot, it seems that sales on one day are correlated with sales from the previous day. In general, lag features let us model serial dependence which means an observation can be predicted from previous observation.\n1.1 Example In this section, we will look at an example using the tunnel traffic dataset from November 2003 to November 2005\nAdd time features to the data:\n1 2 3 4 df = tunnel.copy() df['Time'] = np.arange(len(tunnel.index)) df.head() To produce a linear regression plot:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from sklearn.linear_model import LinearRegression # Training data X = df.loc[:, ['Time']] # features y = df.loc[:, 'NumVehicles'] # target # Train the model model = LinearRegression() model.fit(X, y) # Store the fitted values as a time series with the same time index as # the training data y_pred = pd.Series(model.predict(X), index=X.index) ax = y.plot(**plot_params) ax = y_pred.plot(ax=ax, linewidth=3) ax.set_title('Time Plot of Tunnel Traffic'); Now let’s add a lag column and use it for a linear regression plot:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 df['Lag_1'] = df['NumVehicles'].shift(1) from sklearn.linear_model import LinearRegression X = df.loc[:, ['Lag_1']] X.dropna(inplace=True) # drop missing values in the feature set y = df.loc[:, 'NumVehicles'] # create the target y, X = y.align(X, join='inner') # drop corresponding values in target model = LinearRegression() model.fit(X, y) y_pred = pd.Series(model.predict(X), index=X.index) fig, ax = plt.subplots() ax.plot(X['Lag_1'], y, '.', color='0.25') ax.plot(X['Lag_1'], y_pred) ax.set_aspect('equal') ax.set_ylabel('NumVehicles') ax.set_xlabel('Lag_1') ax.set_title('Lag Plot of Tunnel Traffic'); Here is how our forecast respond to the behavior of the series in the recent past:\n1 2 ax = y.plot(**plot_params) ax = y_pred.plot() 2. Trend Trend is a component of a time series that represents a persistent, long-term change in the mean of the series. It is the slowest-moving part of a series, the part representing the largest timescale of importance.\nTo see what kind of trend a series have, we can use the moving average plot. We compute the average values within a sliding window of some defined width.\nEach point on the graph represents the average of all the values in the series that fall within the window on either side. The idea is to smooth out any short-term fluctuations in the series so that only long-term changes remain.\nFrom the above plot, we can see there is a repeating up and down movement yearly (seasonal change). For a change to be a part of the trend, it should occur over a longer period than the seasonal change. Thus, we take an average over a longer period than any seasonal period in the series (window size of 12) to smooth over the season within each year to visualize the trend.\nAfter identifying the trend, we can model it using a time-step feature. For example, a linear trend:\ntarget = a * time + b If we notice the trend to be quadratic, we can square the time dummy to the feature set:\ntarget = a * time ** 2 + b * time + c 2.1 Example Let’s look back at the tunnel traffic dataset that we used for the previous section, in the series the observations are on a daily basis. We will use windows of 365 days to smooth over short-term changes within the year:\n1 2 3 4 5 6 7 8 9 10 moving_average = tunnel.rolling( window=365, # 365-day window center=True, # puts the average at the center of the window min_periods=183, # choose about half the window size ).mean() # compute the mean (could also do median, std, min, max, ...) ax = tunnel.plot(style=\".\", color=\"0.5\") moving_average.plot( ax=ax, linewidth=3, title=\"Tunnel Traffic - 365-Day Moving Average\", legend=False, ); Now we will use the DeterministicProcess function from the statsmodels library to perform linear regression on the series:\n1 2 3 4 5 6 7 8 9 10 11 12 13 from statsmodels.tsa.deterministic import DeterministicProcess dp = DeterministicProcess( index=tunnel.index, # dates from the training data constant=True, # dummy feature for the bias (y_intercept) order=1, # the time dummy (trend) drop=True, # drop terms if necessary to avoid collinearity ) # `in_sample` creates features for the dates given in the `index` argument X = dp.in_sample() X.head() const\ttrend\tDay 2003-11-01\t1.0\t1.0 2003-11-02\t1.0\t2.0 2003-11-03\t1.0\t3.0 2003-11-04\t1.0\t4.0 2003-11-05\t1.0\t5.0 Model fitting:\n1 2 3 4 5 6 7 8 9 10 11 from sklearn.linear_model import LinearRegression y = tunnel[\"NumVehicles\"] # the target # The intercept is the same as the `const` feature from # DeterministicProcess. LinearRegression behaves badly with duplicated # features, so we need to be sure to exclude it here. model = LinearRegression(fit_intercept=False) model.fit(X, y) y_pred = pd.Series(model.predict(X), index=X.index) Plotting:\n1 2 ax = tunnel.plot(style=\".\", color=\"0.5\", title=\"Tunnel Traffic - Linear Trend\") _ = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\") Now let’s make a forecast using the fitted model:\n1 2 3 4 X = dp.out_of_sample(steps=30) y_fore = pd.Series(model.predict(X), index=X.index) y_fore.head() 2005-11-17 114981.801146 2005-11-18 115004.298595 2005-11-19 115026.796045 2005-11-20 115049.293494 2005-11-21 115071.790944 Freq: D, dtype: float64 1 2 3 4 ax = tunnel[\"2005-05\":].plot(title=\"Tunnel Traffic - Linear Trend Forecast\", **plot_params) ax = y_pred[\"2005-05\":].plot(ax=ax, linewidth=3, label=\"Trend\") ax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color=\"C3\") _ = ax.legend() 3. Seasonality A time series exhibits seasonality if there is a regular, periodic change in the mean of the series. Normally, such changes follow the clock and calendar. It can be repetitions over a day, week, or year.\nIn this section, we will explore two kinds of feature to model seasonality:\nIndicator: Best for season with few observations like weekly or daily observation Fourier Feature: Best for season with many observations (annual season of daily observations) Seasonal plot can be used to discover seasonal patterns where it shows segments of the time series plot against some common period (period you want to observe). Seasonal indicators are binary features that represent seasonal differences in the level of a time series. We can perform one-hot encoding to get weekly seasonal indicators or monthly seasonal indicator.\n3.1 Fourier Features \u0026 The Periodogram For long seasons over many observations, indicators seem to be impractical to capture the overall shape of the seasonal curve:\nFor the above plot, we can see the repetitions of various frequencies such as yearly and weekly. Of course, we want to capture these frequencies with Fourier features.\nFourier features are pairs of sine and cosine curves, one pair for each potential frequency in the season starting with the longest. Fourier pairs modeling annual seasonality would have frequencies: once per year, twice per year, three times per year, and so on.\nIf we add a set of these sine / cosine curves to our training data, the linear regression algorithm will figure out the weights that will fit the seasonal component in the target series.\nIn fact, we only need eight features (4 sin and cosine pairs) to get a good estimate of the annual seasonality. The question remains is how do we get to choose the number of Fourier pairs? We can approach the problem with a periodogram where it tells us the frequencies in a time series.\nFrom the above plot, the periodogram drops off after the quarterly frequency, so we will choose four Fourier pairs to estimate the annual season. We ignore the weekly frequency as it is better to model with indicators.\nHere’s how we can derive a set of Fourier features from the index of time series:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import numpy as np def fourier_features(index, freq, order): time = np.arange(len(index), dtype=np.float32) k = 2 * np.pi * (1 / freq) * time features = {} for i in range(1, order + 1): features.update({ f\"sin_{freq}_{i}\": np.sin(i * k), f\"cos_{freq}_{i}\": np.cos(i * k), }) return pd.DataFrame(features, index=index) # Compute Fourier features to the 4th order (8 new features) for a # series y with daily observations and annual seasonality: # # fourier_features(y, freq=365.25, order=4) 3.2 Example Defining some functions. We are using the same tunnel traffic dataset as before:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # annotations: https://stackoverflow.com/a/49238256/5769929 def seasonal_plot(X, y, period, freq, ax=None): if ax is None: _, ax = plt.subplots() palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),) ax = sns.lineplot( x=freq, y=y, hue=period, data=X, ci=False, ax=ax, palette=palette, legend=False, ) ax.set_title(f\"Seasonal Plot ({period}/{freq})\") for line, name in zip(ax.lines, X[period].unique()): y_ = line.get_ydata()[-1] ax.annotate( name, xy=(1, y_), xytext=(6, 0), color=line.get_color(), xycoords=ax.get_yaxis_transform(), textcoords=\"offset points\", size=14, va=\"center\", ) return ax def plot_periodogram(ts, detrend='linear', ax=None): from scipy.signal import periodogram fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\") freqencies, spectrum = periodogram( ts, fs=fs, detrend=detrend, window=\"boxcar\", scaling='spectrum', ) if ax is None: _, ax = plt.subplots() ax.step(freqencies, spectrum, color=\"purple\") ax.set_xscale(\"log\") ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104]) ax.set_xticklabels( [ \"Annual (1)\", \"Semiannual (2)\", \"Quarterly (4)\", \"Bimonthly (6)\", \"Monthly (12)\", \"Biweekly (26)\", \"Weekly (52)\", \"Semiweekly (104)\", ], rotation=30, ) ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0)) ax.set_ylabel(\"Variance\") ax.set_title(\"Periodogram\") return ax We will start with the seasonal plots over a week and a year:\n1 2 3 4 5 6 7 8 9 10 11 12 X = tunnel.copy() # days within a week X[\"day\"] = X.index.dayofweek # the x-axis (freq) X[\"week\"] = X.index.week # the seasonal period (period) # days within a year X[\"dayofyear\"] = X.index.dayofyear X[\"year\"] = X.index.year fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(11, 6)) seasonal_plot(X, y=\"NumVehicles\", period=\"week\", freq=\"day\", ax=ax0) seasonal_plot(X, y=\"NumVehicles\", period=\"year\", freq=\"dayofyear\", ax=ax1); For the periodogram:\n1 plot_periodogram(tunnel.NumVehicles); From the periodogram, there is a strong weekly season and a weaker annual season. We’ll model the weekly season with indicator and the yearly season with Fourier features. From right to left, the periodogram falls off between Bimonthly (6) and Monthly (12), so let’s use 10 Fourier pairs.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess fourier = CalendarFourier(freq=\"A\", order=10) # 10 sin/cos pairs for \"A\"nnual seasonality dp = DeterministicProcess( index=tunnel.index, constant=True, # dummy feature for bias (y-intercept) order=1, # trend (order 1 means linear) seasonal=True, # weekly seasonality (indicators) additional_terms=[fourier], # annual seasonality (fourier) drop=True, # drop terms to avoid collinearity ) X = dp.in_sample() # create features for dates in tunnel.index Model prediction:\n1 2 3 4 5 6 7 8 9 10 11 12 13 y = tunnel[\"NumVehicles\"] model = LinearRegression(fit_intercept=False) _ = model.fit(X, y) y_pred = pd.Series(model.predict(X), index=y.index) X_fore = dp.out_of_sample(steps=90) y_fore = pd.Series(model.predict(X_fore), index=X_fore.index) ax = y.plot(color='0.25', style='.', title=\"Tunnel Traffic - Seasonal Forecast\") ax = y_pred.plot(ax=ax, label=\"Seasonal\") ax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3') _ = ax.legend() 4. Time Series as Features For some time series, they can only be modeled as a serially dependent properties, that is using as features past values of the target series. The goal in this lesson is to train models to fit curves to plots like those on the right – we want them to learn serial dependence:\nOne common way for serial dependence to manifest is in cycle - patterns of growth and decay in a time series associated with how the value in a series at one time depends on values at previous times, but not necessarily on the time step itself. Cyclic behavior is a characteristic of systems that can effect themselves, economies, epidemics, animal populations and volcano eruptions often display cyclic behavior:\nWhat distinguishes cyclic behavior from seasonality is that cycles are not necessarily time dependent, as seasons are. What happens in a cycle is less about the particular date of occurrence, and more about what has happened in the recent past\n4.1 Lagged Series \u0026 Lag Plots To investigate serial dependence, we need to create “lagged” copies of the series. When we say “lagging”, it means we are shifting the time series values forward by one or more time steps. By lagging a time series, we make past values appear contemporaneous with the values we are trying to predict.\ny\ty_lag_1\ty_lag_2\t1954-07\t5.8\tNaN\tNaN 1954-08\t6.0\t5.8\tNaN 1954-09\t6.1\t6.0\t5.8 1954-10\t5.7\t6.1\t6.0 1954-11\t5.3\t5.7\t6.1 A lag plot shows a time series values plotted against its lags. In the below images, there is a strong linear relationship between current unemployment rate and past rates.\nIn order to measure serial dependence, we can use autocorrelation - the correlation a time series has with one of its lag. In general, it would not be useful to include every lag with a large autocorrelation. We can find the partial autocorrelation that tells us the correlation of a lag accounting for all the previous lags (amount of new correlation the lag contribute).\nIn the figure below, lag 1 through lag 6 fall outside the intervals of “no correlation” (in blue), so we might choose lags 1 through lag 6 as features for US Unemployment. (Lag 11 is likely a false positive.)\nImportantly, we need to be mindful that autocorrelation and partial autocorrelation are measures of linear dependence. Real-world time series often have non-linear dependences, it’s good that a make a lag plot when choosing lag features.\nSome non-linear relationship is the above image can be transformed to linear or learned by an appropriate algorithm.\n4.2 Example Let’s define some functions for it to be used for the flu trend dataset, containing records of doctor’s visits for the flu for weeks between 2009 and 2016:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from scipy.signal import periodogram from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from statsmodels.graphics.tsaplots import plot_pacf def lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs): from matplotlib.offsetbox import AnchoredText x_ = x.shift(lag) if standardize: x_ = (x_ - x_.mean()) / x_.std() if y is not None: y_ = (y - y.mean()) / y.std() if standardize else y else: y_ = x corr = y_.corr(x_) if ax is None: fig, ax = plt.subplots() scatter_kws = dict( alpha=0.75, s=3, ) line_kws = dict(color='C3', ) ax = sns.regplot(x=x_, y=y_, scatter_kws=scatter_kws, line_kws=line_kws, lowess=True, ax=ax, **kwargs) at = AnchoredText( f\"{corr:.2f}\", prop=dict(size=\"large\"), frameon=True, loc=\"upper left\", ) at.patch.set_boxstyle(\"square, pad=0.0\") ax.add_artist(at) ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name) return ax def plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs): import math kwargs.setdefault('nrows', nrows) kwargs.setdefault('ncols', math.ceil(lags / nrows)) kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5)) fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs) for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])): if k + 1 \u003c= lags: ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs) ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14)) ax.set(xlabel=\"\", ylabel=\"\") else: ax.axis('off') plt.setp(axs[-1, :], xlabel=x.name) plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name) fig.tight_layout(w_pad=0.1, h_pad=0.1) return fig data_dir = Path(\"../input/ts-course-data\") flu_trends = pd.read_csv(data_dir / \"flu-trends.csv\") flu_trends.set_index( pd.PeriodIndex(flu_trends.Week, freq=\"W\"), inplace=True, ) flu_trends.drop(\"Week\", axis=1, inplace=True) ax = flu_trends.FluVisits.plot(title='Flu Trends', **plot_params) _ = ax.set(ylabel=\"Office Visits\") Flu Trends data shows irregular cycles instead of a regular seasonality: the peak tends to occur around the new year, but sometimes earlier or later, sometimes larger or smaller.\nLet’s look at the lag and autocorrelation plot:\n1 2 _ = plot_lags(flu_trends.FluVisits, lags=12, nrows=2) _ = plot_pacf(flu_trends.FluVisits, lags=12) From the lag plot, it seems that the relationship of the flu visits to its lags is mostly linear. For PACF plot, we can capture the serial dependence using lags 1, 2, 3 and 4. Here’s how to make lag and fill the NaN cells with 0:\n1 2 3 4 5 6 7 8 9 10 11 def make_lags(ts, lags): return pd.concat( { f'y_lag_{i}': ts.shift(i) for i in range(1, lags + 1) }, axis=1) X = make_lags(flu_trends.FluVisits, lags=4) X = X.fillna(0.0) Making forecast:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create target series and data splits y = flu_trends.FluVisits.copy() X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=60, shuffle=False) # Fit and predict model = LinearRegression() # `fit_intercept=True` since we didn't use DeterministicProcess model.fit(X_train, y_train) y_pred = pd.Series(model.predict(X_train), index=y_train.index) y_fore = pd.Series(model.predict(X_test), index=y_test.index) ax = y_train.plot(**plot_params) ax = y_test.plot(**plot_params) ax = y_pred.plot(ax=ax) _ = y_fore.plot(ax=ax, color='C3') To improve the forecast we could try to find leading indicators, time series that could provide an “early warning” for changes in flu cases. For our second approach then we’ll add to our training data the popularity of some flu-related search terms as measured by Google Trends.\nPlotting the search phrase ‘FluCough’ against the target ‘FluVisits’ suggests such search terms could be useful as leading indicators: flu-related searches tend to become more popular in the weeks prior to office visits.\n1 2 3 4 ax = flu_trends.plot( y=[\"FluCough\", \"FluVisits\"], secondary_y=\"FluCough\", ) Filtering the search terms:\n1 2 3 4 5 6 7 8 9 10 11 search_terms = [\"FluContagious\", \"FluCough\", \"FluFever\", \"InfluenzaA\", \"TreatFlu\", \"IHaveTheFlu\", \"OverTheCounterFlu\", \"HowLongFlu\"] # Create three lags for each search term X0 = make_lags(flu_trends[search_terms], lags=3) X0.columns = [' '.join(col).strip() for col in X0.columns.values] # Create four lags for the target, as before X1 = make_lags(flu_trends['FluVisits'], lags=4) # Combine to create the training data X = pd.concat([X0, X1], axis=1).fillna(0.0) Forecast:\n1 2 3 4 5 6 7 8 9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=60, shuffle=False) model = LinearRegression() model.fit(X_train, y_train) y_pred = pd.Series(model.predict(X_train), index=y_train.index) y_fore = pd.Series(model.predict(X_test), index=y_test.index) ax = y_test.plot(**plot_params) _ = y_fore.plot(ax=ax, color='C3') Our forecasts are a bit rougher, but our model appears to be better able to anticipate sudden increases in flu visits, suggesting that the several time series of search popularity were indeed effective as leading indicators.\nThe time series illustrated in this lesson are what you might call “purely cyclic”: they have no obvious trend or seasonality. It’s not uncommon though for time series to possess trend, seasonality, and cycles – all three components at once. You could model such series with linear regression by just adding the appropriate features for each component. You can even combine models trained to learn the components separately\n5. Hybrid Models To design an effective hybrid, we have to know how a time series is constructed. Previously, we learned about trend, season and cycles. Many time series can be described by an additive model of these three components plus some error term:\nseries = trend + seasons + cycles + error Residuals of a model are the difference between the model’s target and the prediction, as illustrated below:\nNow imagine that we learn the time series components in an iterative manner: we start by learning the trend, then by subtracting it out, we learn the series seasonality, follow by cycles and then the error term:\nOf course, it is possible for use to use one algorithm for some components and another algorithm for the rest. That means, we use one algorithm to fit the original series and another algorithm for the residuals series:\n1 2 3 4 5 6 7 8 9 10 # 1. Train and predict with first model model_1.fit(X_train_1, y_train) y_pred_1 = model_1.predict(X_train) # 2. Train and predict with second model on residuals model_2.fit(X_train_2, y_train - y_pred_1) y_pred_2 = model_2.predict(X_train_2) # 3. Add to get overall predictions y_pred = y_pred_1 + y_pred_2 While it’s possible to use more than two models, in practice it doesn’t seem to be especially helpful. In fact, the most common strategy for constructing hybrids is the one we’ve just described: a simple (usually linear) learning algorithm followed by a complex, non-linear learner like GBDTs or a deep neural net, the simple model typically designed as a “helper” for the powerful algorithm that follows.\nThere are generally two ways a regression algorithm can make predictions: either by transforming the features or by transforming the target. Feature-transforming algorithms learn some mathematical function that takes features as an input and then combines and transforms them to produce an output that matches the target values in the training set. Linear regression and neural nets are of this kind.\nTarget-transforming algorithms use the features to group the target values in the training set and make predictions by averaging values in a group; a set of feature just indicates which group to average. Decision trees and nearest neighbors are of this kind.\nThe important thing is this: feature transformers generally can extrapolate target values beyond the training set given appropriate features as inputs, but the predictions of target transformers will always be bound within the range of the training set. If the time dummy continues counting time steps, linear regression continues drawing the trend line. Given the same time dummy, a decision tree will predict the trend indicated by the last step of the training data into the future forever. Decision trees cannot extrapolate trends. Random forests and gradient boosted decision trees (like XGBoost) are ensembles of decision trees, so they also cannot extrapolate trends.\nSo, we could use linear regression to extrapolate the trend, transform the target to remove the trend, and apply XGBoost to the detrended residuals. To hybridize a neural net (a feature transformer), you could instead include the predictions of another model as a feature, which the neural net would then include as part of its own predictions. The method of fitting to residuals is actually the same method the gradient boosting algorithm uses, so we will call these boosted hybrids; the method of using predictions as features is known as “stacking”, so we will call these stacked hybrids.\n5.1 Example In this example, we will use the US Retail Sales data set from 1992 to 2019. We will also create a linear regression and XGBoost hybrid for prediction.\nBuildingMaterials\tFoodAndBeverage\t1992-01-01\t8964\t29589 1992-02-01\t9023\t28570 1992-03-01\t10608\t29682 1992-04-01\t11630\t30228 1992-05-01\t12327\t31677 We will start by learning the trend of the series using linear regression (a quadratic trend is used)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 y = retail.copy() # Create trend features dp = DeterministicProcess( index=y.index, # dates from the training data constant=True, # the intercept order=2, # quadratic trend drop=True, # drop terms to avoid collinearity ) X = dp.in_sample() # features for the training data # Test on the years 2016-2019. It will be easier for us later if we # split the date index instead of the dataframe directly. idx_train, idx_test = train_test_split( y.index, test_size=12 * 4, shuffle=False, ) X_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :] y_train, y_test = y.loc[idx_train], y.loc[idx_test] # Fit trend model model = LinearRegression(fit_intercept=False) model.fit(X_train, y_train) # Make predictions y_fit = pd.DataFrame( model.predict(X_train), index=y_train.index, columns=y_train.columns, ) y_pred = pd.DataFrame( model.predict(X_test), index=y_test.index, columns=y_test.columns, ) # Plot axs = y_train.plot(color='0.25', subplots=True, sharex=True) axs = y_test.plot(color='0.25', subplots=True, sharex=True, ax=axs) axs = y_fit.plot(color='C0', subplots=True, sharex=True, ax=axs) axs = y_pred.plot(color='C3', subplots=True, sharex=True, ax=axs) for ax in axs: ax.legend([]) _ = plt.suptitle(\"Trends\") Linear regression algorithm is capable of multi-output regression, the XGBoost algorithm is not. To predict multiple series at once with XGBoost, we’ll instead convert these series from wide format, with one time series per column, to long format, with series indexed by categories along rows.\n1 2 3 4 # The `stack` method converts column labels to row labels, pivoting from wide format to long X = retail.stack() # pivot dataset wide to long display(X.head()) y = X.pop('Sales') # grab target series Industries\t1992-01-01\tBuildingMaterials\t8964 FoodAndBeverage\t29589 1992-02-01\tBuildingMaterials\t9023 FoodAndBeverage\t28570 1992-03-01\tBuildingMaterials\t10608 Construct the train and test set:\n1 2 3 4 5 6 7 8 9 10 11 12 # Turn row labels into categorical feature columns with a label encoding X = X.reset_index('Industries') # Label encoding for 'Industries' feature for colname in X.select_dtypes([\"object\", \"category\"]): X[colname], _ = X[colname].factorize() # Label encoding for annual seasonality X[\"Month\"] = X.index.month # values are 1, 2, ..., 12 # Create splits X_train, X_test = X.loc[idx_train, :], X.loc[idx_test, :] y_train, y_test = y.loc[idx_train], y.loc[idx_test] Convert the trend predictions made earlier to long format and then subtract them from the original series. That will give us detrended (residual) series that XGBoost can learn.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Pivot wide to long (stack) and convert DataFrame to Series (squeeze) y_fit = y_fit.stack().squeeze() # trend from training set y_pred = y_pred.stack().squeeze() # trend from test set # Create residuals (the collection of detrended series) from the training set y_resid = y_train - y_fit # Train XGBoost on the residuals xgb = XGBRegressor() xgb.fit(X_train, y_resid) # Add the predicted residuals onto the predicted trends y_fit_boosted = xgb.predict(X_train) + y_fit y_pred_boosted = xgb.predict(X_test) + y_pred 1 2 3 4 5 6 7 8 9 10 11 12 13 14 axs = y_train.unstack(['Industries']).plot( color='0.25', figsize=(11, 5), subplots=True, sharex=True, title=['BuildingMaterials', 'FoodAndBeverage'], ) axs = y_test.unstack(['Industries']).plot( color='0.25', subplots=True, sharex=True, ax=axs, ) axs = y_fit_boosted.unstack(['Industries']).plot( color='C0', subplots=True, sharex=True, ax=axs, ) axs = y_pred_boosted.unstack(['Industries']).plot( color='C3', subplots=True, sharex=True, ax=axs, ) for ax in axs: ax.legend([]) 6. Forecasting with Machine Learning Before we design a forecasting model, we should ask:\nWhat information is available at the time the forecast is made Time period during which you require the forecasted values The forecast origin is time at which you are making a forecast. Practically, you might consider the forecast origin to be the last time for which you have training data for the time being predicted. Everything up to he origin can be used to create features.\nThe forecast horizon is the time for which you are making a forecast. We often describe a forecast by the number of time steps in its horizon: a “1-step” forecast or “5-step” forecast, say. The forecast horizon describes the target.\nThe time between the origin and the horizon is the lead time (or sometimes latency) of the forecast. A forecast’s lead time is described by the number of steps from origin to horizon: a “1-step ahead” or “3-step ahead” forecast, say. In practice, it may be necessary for a forecast to begin multiple steps ahead of the origin because of delays in data acquisition or processing.\nTo forecast time series with ML algorithm, we have to transform the series into a DataFrame that we can use with the algorithms. Each row in a DataFrame represents a single forecast. The time index of the row is the first time in the forecast horizon, but we arrange values for the entire horizon in the same row. For multistep forecasts, this means we are requiring a model to produce multiple outputs, one for each step.\nThe above illustrates how a dataset would be prepared similar to the Defining a Forecast figure: a three-step forecasting task with a two-step lead time using five lag features. The original time series is y_step_1. The missing values we could either fill in or drop.\n6.1 Multistep Forecasting Strategies Direct Strategy Train a separate model for each step in the horizon: one model forecasts 1-step ahead, another 2-steps ahead, and so on. Forecasting 1-step ahead is a different problem than 2-steps ahead (and so on), so it can help to have a different model make forecasts for each step. The downside is that training lots of models can be computationally expensive.\nRecursive Strategy Train a single one-step model and use its forecasts to update the lag features for the next step. With the recursive method, we feed a model’s 1-step forecast back in to that same model to use as a lag feature for the next forecasting step. We only need to train one model, but since errors will propagate from step to step, forecasts can be inaccurate for long horizons.\nDirRec Strategy A combination of the direct and recursive strategies: train a model for each step and use forecasts from previous steps as new lag features. Step by step, each model gets an additional lag input. Since each model always has an up-to-date set of lag features, the DirRec strategy can capture serial dependence better than Direct, but it can also suffer from error propagation like Recursive.\n6.2 Example Here, let’s take a look at the flu trends dataset previously used. We will apply multi-output and direct strategy to the dataset for forecast.\nPreparing datset:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def make_lags(ts, lags, lead_time=1): return pd.concat( { f'y_lag_{i}': ts.shift(i) for i in range(lead_time, lags + lead_time) }, axis=1) # Four weeks of lag features y = flu_trends.FluVisits.copy() X = make_lags(y, lags=4).fillna(0.0) def make_multistep_target(ts, steps): return pd.concat( {f'y_step_{i + 1}': ts.shift(-i) for i in range(steps)}, axis=1) # Eight-week forecast y = make_multistep_target(y, steps=8).dropna() # Shifting has created indexes that don't match. Only keep times for # which we have both targets and features. y, X = y.align(X, join='inner', axis=0) 1 2 3 4 5 6 7 8 # Create splits X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False) model = LinearRegression() model.fit(X_train, y_train) y_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns) y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns) 1 2 3 4 5 6 7 8 9 10 11 12 train_rmse = mean_squared_error(y_train, y_fit, squared=False) test_rmse = mean_squared_error(y_test, y_pred, squared=False) print((f\"Train RMSE: {train_rmse:.2f}\\n\" f\"Test RMSE: {test_rmse:.2f}\")) palette = dict(palette='husl', n_colors=64) fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6)) ax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1) ax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette) _ = ax1.legend(['FluVisits (train)', 'Forecast']) ax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2) ax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette) _ = ax2.legend(['FluVisits (test)', 'Forecast']) XGBoost can’t produce multiple outputs for regression tasks. But by applying the Direct reduction strategy, we can still use it to produce multi-step forecasts. This is as easy as wrapping it with scikit-learn’s MultiOutputRegressor.\n1 2 3 4 5 6 7 from sklearn.multioutput import MultiOutputRegressor model = MultiOutputRegressor(XGBRegressor()) model.fit(X_train, y_train) y_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns) y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns) 1 2 3 4 5 6 7 8 9 10 11 12 train_rmse = mean_squared_error(y_train, y_fit, squared=False) test_rmse = mean_squared_error(y_test, y_pred, squared=False) print((f\"Train RMSE: {train_rmse:.2f}\\n\" f\"Test RMSE: {test_rmse:.2f}\")) palette = dict(palette='husl', n_colors=64) fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6)) ax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1) ax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette) _ = ax1.legend(['FluVisits (train)', 'Forecast']) ax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2) ax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette) _ = ax2.legend(['FluVisits (test)', 'Forecast']) ","wordCount":"5594","inLanguage":"vi","datePublished":"2023-08-19T00:00:00Z","dateModified":"2023-08-19T00:00:00Z","author":{"@type":"Person","name":"Kean Teng Blog"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2023/2023-08-19-time-series/"},"publisher":{"@type":"Organization","name":"The Financial Engineer","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="The Financial Engineer (Alt + H)">The Financial Engineer</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Time Series</h1><div class=post-description>My Kaggle Learning Note</div><div class=post-meta><span title='2023-08-19 00:00:00 +0000 UTC'>tháng 8 19, 2023</span>&nbsp;·&nbsp;27 phút&nbsp;·&nbsp;Kean Teng Blog</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Mục lục</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a><ul><li><a href=#11-example>1.1 Example</a></li></ul></li><li><a href=#2-trend>2. Trend</a><ul><li><a href=#21-example>2.1 Example</a></li></ul></li><li><a href=#3-seasonality>3. Seasonality</a><ul><li><a href=#31-fourier-features--the-periodogram>3.1 Fourier Features & The Periodogram</a></li><li><a href=#32-example>3.2 Example</a></li></ul></li><li><a href=#4-time-series-as-features>4. Time Series as Features</a><ul><li><a href=#41-lagged-series--lag-plots>4.1 Lagged Series & Lag Plots</a></li><li><a href=#42-example>4.2 Example</a></li></ul></li><li><a href=#5-hybrid-models>5. Hybrid Models</a><ul><li><a href=#51-example>5.1 Example</a></li></ul></li><li><a href=#6-forecasting-with-machine-learning>6. Forecasting with Machine Learning</a><ul><li><a href=#61-multistep-forecasting-strategies>6.1 Multistep Forecasting Strategies</a></li><li><a href=#62-example>6.2 Example</a></li></ul></li></ul></nav></div></details></div><div class=post-content><blockquote><p><em>Disclaimer: This article is my learning note from the courses I took from Kaggle.</em></p></blockquote><p>The most common application of machine learning in the real world is forecasting. For example, businesses forecasting product demand, governments forecasting economic growth and meteorologists forecasting the weather. The understanding of things to come has become a pressing need across the science, government and industry, and machine learning is increasingly being applied to address this need.</p><p>In this course, we will learn about time series forecasting. We will also learn about:</p><ul><li>Engineering features to model major time series components such as trends, seasons and cycles</li><li>Visualize time series with plot</li><li>Create forecasting hybrids (combine the strength of complementary models)</li><li>Adapt machine learning methods to various forecasting tasks</li></ul><h2 id=1-introduction>1. Introduction<a hidden class=anchor aria-hidden=true href=#1-introduction>#</a></h2><p>Basically, a time series is a set of observations recorded over time. The observations are recorded with a regular frequency such as day, week, month, quarter or year. We can use linear regression to build forecasting model for time series data:</p><pre tabindex=0><code>target  = weight_1 * feature_1 + weight_2 * feature_2 + bias
</code></pre><p>Parameters such as <code>weight_1</code>, <code>weight_2</code> and <code>bias</code> are learned by the regression algorithm during training.</p><p>There are two unique features to time series:</p><ul><li>Time-step feature</li><li>Lag feature</li></ul><p>Time-step feature can be derived from the time index. The most basic time-step feature is the time dummy that counts time steps in series from the beginning to the end:</p><pre tabindex=0><code>|          | Hardcover | Time |
|----------|-----------|------|
| 1/4/2000 |    139    |   1  |
| 2/4/2000 |    219    |   2  |
| 3/4/2000 |    135    |   3  |
</code></pre><p>Linear regression with the time dummy produces the model:</p><pre tabindex=0><code>target = weight * time + bias
</code></pre><p>In a time plot:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>style<span style=color:#f92672>.</span>use(<span style=color:#e6db74>&#34;seaborn-whitegrid&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>rc(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;figure&#34;</span>,
</span></span><span style=display:flex><span>    autolayout<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>    titlesize<span style=color:#f92672>=</span><span style=color:#ae81ff>18</span>,
</span></span><span style=display:flex><span>    titleweight<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bold&#39;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>rc(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;axes&#34;</span>,
</span></span><span style=display:flex><span>    labelweight<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bold&#34;</span>,
</span></span><span style=display:flex><span>    labelsize<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;large&#34;</span>,
</span></span><span style=display:flex><span>    titleweight<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bold&#34;</span>,
</span></span><span style=display:flex><span>    titlesize<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>,
</span></span><span style=display:flex><span>    titlepad<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>config InlineBackend<span style=color:#f92672>.</span>figure_format <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;retina&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>plot(<span style=color:#e6db74>&#39;Time&#39;</span>, <span style=color:#e6db74>&#39;Hardcover&#39;</span>, data<span style=color:#f92672>=</span>df, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.75&#39;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>regplot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Time&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Hardcover&#39;</span>, data<span style=color:#f92672>=</span>df, ci<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, scatter_kws<span style=color:#f92672>=</span>dict(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>))
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Time Plot of Hardcover Sales&#39;</span>);
</span></span></code></pre></td></tr></table></div></div><p>Time-step features let us model time dependence. A series is time dependent if its value can be predicted from the time they occurred in.</p><p>Moreover, to make a lag feature from the dataset we will shift the observation of the target series so that they appear to have occurred later in time. Here&rsquo;s a 1-step lag feature:</p><pre tabindex=0><code>|            |Hardcover|Lag_1|
|------------|---------|-----|
|Date        |         |     |
|2000-04-01  |139      |NaN  |
|2000-04-02  |128      |139.0|  
|2000-04-03	 |172      |128.0|
|2000-04-04  |139      |172.0|
|2000-04-05  |191      |139.0|
</code></pre><p>Linear regression with the time dummy produces the model:</p><pre tabindex=0><code>target = weight * lag + bias
</code></pre><p>In a time plot:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>regplot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Lag_1&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Hardcover&#39;</span>, data<span style=color:#f92672>=</span>df, ci<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, scatter_kws<span style=color:#f92672>=</span>dict(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>))
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_aspect(<span style=color:#e6db74>&#39;equal&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Lag Plot of Hardcover Sales&#39;</span>);
</span></span></code></pre></td></tr></table></div></div><p>From the plot, it seems that sales on one day are correlated with sales from the previous day. In general, lag features let us model serial dependence which means an observation can be predicted from previous observation.</p><h3 id=11-example>1.1 Example<a hidden class=anchor aria-hidden=true href=#11-example>#</a></h3><p>In this section, we will look at an example using the tunnel traffic dataset from November 2003 to November 2005</p><p>Add time features to the data:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>df <span style=color:#f92672>=</span> tunnel<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Time&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(len(tunnel<span style=color:#f92672>.</span>index))
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></td></tr></table></div></div><p>To produce a linear regression plot:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Training data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;Time&#39;</span>]]  <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[:, <span style=color:#e6db74>&#39;NumVehicles&#39;</span>]  <span style=color:#75715e># target</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Store the fitted values as a time series with the same time index as</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the training data</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X), index<span style=color:#f92672>=</span>X<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Time Plot of Tunnel Traffic&#39;</span>);
</span></span></code></pre></td></tr></table></div></div><p>Now let&rsquo;s add a lag column and use it for a linear regression plot:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Lag_1&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;NumVehicles&#39;</span>]<span style=color:#f92672>.</span>shift(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;Lag_1&#39;</span>]]
</span></span><span style=display:flex><span>X<span style=color:#f92672>.</span>dropna(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)  <span style=color:#75715e># drop missing values in the feature set</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[:, <span style=color:#e6db74>&#39;NumVehicles&#39;</span>]  <span style=color:#75715e># create the target</span>
</span></span><span style=display:flex><span>y, X <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>align(X, join<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;inner&#39;</span>)  <span style=color:#75715e># drop corresponding values in target</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X), index<span style=color:#f92672>=</span>X<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>plot(X[<span style=color:#e6db74>&#39;Lag_1&#39;</span>], y, <span style=color:#e6db74>&#39;.&#39;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>plot(X[<span style=color:#e6db74>&#39;Lag_1&#39;</span>], y_pred)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_aspect(<span style=color:#e6db74>&#39;equal&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#39;NumVehicles&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#39;Lag_1&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;Lag Plot of Tunnel Traffic&#39;</span>);
</span></span></code></pre></td></tr></table></div></div><p>Here is how our forecast respond to the behavior of the series in the recent past:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>ax <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot()
</span></span></code></pre></td></tr></table></div></div><h2 id=2-trend>2. Trend<a hidden class=anchor aria-hidden=true href=#2-trend>#</a></h2><p>Trend is a component of a time series that represents a persistent, long-term change in the mean of the series. It is the slowest-moving part of a series, the part representing the largest timescale of importance.</p><p>To see what kind of trend a series have, we can use the moving average plot. We compute the average values within a sliding window of some defined width.</p><blockquote><p>Each point on the graph represents the average of all the values in the series that fall within the window on either side. The idea is to smooth out any short-term fluctuations in the series so that only long-term changes remain.</p></blockquote><p>From the above plot, we can see there is a repeating up and down movement yearly (seasonal change). For a change to be a part of the trend, it should occur over a longer period than the seasonal change. Thus, we take an average over a longer period than any seasonal period in the series (window size of 12) to smooth over the season within each year to visualize the trend.</p><p>After identifying the trend, we can model it using a time-step feature. For example, a linear trend:</p><pre tabindex=0><code>target = a * time + b
</code></pre><p>If we notice the trend to be quadratic, we can square the time dummy to the feature set:</p><pre tabindex=0><code>target = a * time ** 2 + b * time + c
</code></pre><h3 id=21-example>2.1 Example<a hidden class=anchor aria-hidden=true href=#21-example>#</a></h3><p>Let&rsquo;s look back at the tunnel traffic dataset that we used for the previous section, in the series the observations are on a daily basis. We will use windows of 365 days to smooth over short-term changes within the year:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>moving_average <span style=color:#f92672>=</span> tunnel<span style=color:#f92672>.</span>rolling(
</span></span><span style=display:flex><span>    window<span style=color:#f92672>=</span><span style=color:#ae81ff>365</span>,       <span style=color:#75715e># 365-day window</span>
</span></span><span style=display:flex><span>    center<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,      <span style=color:#75715e># puts the average at the center of the window</span>
</span></span><span style=display:flex><span>    min_periods<span style=color:#f92672>=</span><span style=color:#ae81ff>183</span>,  <span style=color:#75715e># choose about half the window size</span>
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>mean()              <span style=color:#75715e># compute the mean (could also do median, std, min, max, ...)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> tunnel<span style=color:#f92672>.</span>plot(style<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;.&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.5&#34;</span>)
</span></span><span style=display:flex><span>moving_average<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>=</span>ax, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Tunnel Traffic - 365-Day Moving Average&#34;</span>, legend<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>);
</span></span></code></pre></td></tr></table></div></div><p>Now we will use the <code>DeterministicProcess</code> function from the <code>statsmodels</code> library to perform linear regression on the series:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> statsmodels.tsa.deterministic <span style=color:#f92672>import</span> DeterministicProcess
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dp <span style=color:#f92672>=</span> DeterministicProcess(
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>tunnel<span style=color:#f92672>.</span>index,  <span style=color:#75715e># dates from the training data</span>
</span></span><span style=display:flex><span>    constant<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,       <span style=color:#75715e># dummy feature for the bias (y_intercept)</span>
</span></span><span style=display:flex><span>    order<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,             <span style=color:#75715e># the time dummy (trend)</span>
</span></span><span style=display:flex><span>    drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,           <span style=color:#75715e># drop terms if necessary to avoid collinearity</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># `in_sample` creates features for the dates given in the `index` argument</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> dp<span style=color:#f92672>.</span>in_sample()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X<span style=color:#f92672>.</span>head()
</span></span></code></pre></td></tr></table></div></div><pre tabindex=0><code>            const	trend	
Day
2003-11-01	1.0	    1.0
2003-11-02	1.0	    2.0
2003-11-03	1.0	    3.0
2003-11-04	1.0	    4.0
2003-11-05	1.0	    5.0
</code></pre><p>Model fitting:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> tunnel[<span style=color:#e6db74>&#34;NumVehicles&#34;</span>]  <span style=color:#75715e># the target</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The intercept is the same as the `const` feature from</span>
</span></span><span style=display:flex><span><span style=color:#75715e># DeterministicProcess. LinearRegression behaves badly with duplicated</span>
</span></span><span style=display:flex><span><span style=color:#75715e># features, so we need to be sure to exclude it here.</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression(fit_intercept<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X), index<span style=color:#f92672>=</span>X<span style=color:#f92672>.</span>index)
</span></span></code></pre></td></tr></table></div></div><p>Plotting:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>ax <span style=color:#f92672>=</span> tunnel<span style=color:#f92672>.</span>plot(style<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;.&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.5&#34;</span>, title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Tunnel Traffic - Linear Trend&#34;</span>)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Trend&#34;</span>)
</span></span></code></pre></td></tr></table></div></div><p>Now let&rsquo;s make a forecast using the fitted model:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>X <span style=color:#f92672>=</span> dp<span style=color:#f92672>.</span>out_of_sample(steps<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_fore <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X), index<span style=color:#f92672>=</span>X<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>y_fore<span style=color:#f92672>.</span>head()
</span></span></code></pre></td></tr></table></div></div><pre tabindex=0><code>2005-11-17    114981.801146
2005-11-18    115004.298595
2005-11-19    115026.796045
2005-11-20    115049.293494
2005-11-21    115071.790944
Freq: D, dtype: float64
</code></pre><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>ax <span style=color:#f92672>=</span> tunnel[<span style=color:#e6db74>&#34;2005-05&#34;</span>:]<span style=color:#f92672>.</span>plot(title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Tunnel Traffic - Linear Trend Forecast&#34;</span>, <span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_pred[<span style=color:#e6db74>&#34;2005-05&#34;</span>:]<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Trend&#34;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_fore<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Trend Forecast&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;C3&#34;</span>)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax<span style=color:#f92672>.</span>legend()
</span></span></code></pre></td></tr></table></div></div><h2 id=3-seasonality>3. Seasonality<a hidden class=anchor aria-hidden=true href=#3-seasonality>#</a></h2><p>A time series exhibits seasonality if there is a regular, periodic change in the mean of the series. Normally, such changes follow the clock and calendar. It can be repetitions over a day, week, or year.</p><p>In this section, we will explore two kinds of feature to model seasonality:</p><ul><li>Indicator: Best for season with few observations like weekly or daily observation</li><li>Fourier Feature: Best for season with many observations (annual season of daily observations)</li></ul><p>Seasonal plot can be used to discover seasonal patterns where it shows segments of the time series plot against some common period (period you want to observe). Seasonal indicators are binary features that represent seasonal differences in the level of a time series. We can perform <strong>one-hot encoding</strong> to get weekly seasonal indicators or monthly seasonal indicator.</p><h3 id=31-fourier-features--the-periodogram>3.1 Fourier Features & The Periodogram<a hidden class=anchor aria-hidden=true href=#31-fourier-features--the-periodogram>#</a></h3><p>For long seasons over many observations, indicators seem to be impractical to capture the overall shape of the seasonal curve:</p><p>For the above plot, we can see the repetitions of various frequencies such as yearly and weekly. Of course, we want to capture these frequencies with Fourier features.</p><p>Fourier features are pairs of sine and cosine curves, one pair for each potential frequency in the season starting with the longest. Fourier pairs modeling annual seasonality would have frequencies: once per year, twice per year, three times per year, and so on.</p><blockquote><p>If we add a set of these sine / cosine curves to our training data, the linear regression algorithm will figure out the weights that will fit the seasonal component in the target series.</p></blockquote><p>In fact, we only need eight features (4 sin and cosine pairs) to get a good estimate of the annual seasonality. The question remains is how do we get to choose the number of Fourier pairs? We can approach the problem with a periodogram where it tells us the frequencies in a time series.</p><p>From the above plot, the periodogram drops off after the quarterly frequency, so we will choose four Fourier pairs to estimate the annual season. We ignore the weekly frequency as it is better to model with indicators.</p><p>Here&rsquo;s how we can derive a set of Fourier features from the index of time series:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fourier_features</span>(index, freq, order):
</span></span><span style=display:flex><span>    time <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(len(index), dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    k <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>pi <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> freq) <span style=color:#f92672>*</span> time
</span></span><span style=display:flex><span>    features <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, order <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        features<span style=color:#f92672>.</span>update({
</span></span><span style=display:flex><span>            <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;sin_</span><span style=color:#e6db74>{</span>freq<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>: np<span style=color:#f92672>.</span>sin(i <span style=color:#f92672>*</span> k),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;cos_</span><span style=color:#e6db74>{</span>freq<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>: np<span style=color:#f92672>.</span>cos(i <span style=color:#f92672>*</span> k),
</span></span><span style=display:flex><span>        })
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> pd<span style=color:#f92672>.</span>DataFrame(features, index<span style=color:#f92672>=</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Compute Fourier features to the 4th order (8 new features) for a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># series y with daily observations and annual seasonality:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># fourier_features(y, freq=365.25, order=4)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=32-example>3.2 Example<a hidden class=anchor aria-hidden=true href=#32-example>#</a></h3><p>Defining some functions. We are using the same tunnel traffic dataset as before:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># annotations: https://stackoverflow.com/a/49238256/5769929</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>seasonal_plot</span>(X, y, period, freq, ax<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> ax <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        _, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>    palette <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>color_palette(<span style=color:#e6db74>&#34;husl&#34;</span>, n_colors<span style=color:#f92672>=</span>X[period]<span style=color:#f92672>.</span>nunique(),)
</span></span><span style=display:flex><span>    ax <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>lineplot(
</span></span><span style=display:flex><span>        x<span style=color:#f92672>=</span>freq,
</span></span><span style=display:flex><span>        y<span style=color:#f92672>=</span>y,
</span></span><span style=display:flex><span>        hue<span style=color:#f92672>=</span>period,
</span></span><span style=display:flex><span>        data<span style=color:#f92672>=</span>X,
</span></span><span style=display:flex><span>        ci<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>=</span>ax,
</span></span><span style=display:flex><span>        palette<span style=color:#f92672>=</span>palette,
</span></span><span style=display:flex><span>        legend<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Seasonal Plot (</span><span style=color:#e6db74>{</span>period<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>freq<span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> line, name <span style=color:#f92672>in</span> zip(ax<span style=color:#f92672>.</span>lines, X[period]<span style=color:#f92672>.</span>unique()):
</span></span><span style=display:flex><span>        y_ <span style=color:#f92672>=</span> line<span style=color:#f92672>.</span>get_ydata()[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>        ax<span style=color:#f92672>.</span>annotate(
</span></span><span style=display:flex><span>            name,
</span></span><span style=display:flex><span>            xy<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, y_),
</span></span><span style=display:flex><span>            xytext<span style=color:#f92672>=</span>(<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>0</span>),
</span></span><span style=display:flex><span>            color<span style=color:#f92672>=</span>line<span style=color:#f92672>.</span>get_color(),
</span></span><span style=display:flex><span>            xycoords<span style=color:#f92672>=</span>ax<span style=color:#f92672>.</span>get_yaxis_transform(),
</span></span><span style=display:flex><span>            textcoords<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;offset points&#34;</span>,
</span></span><span style=display:flex><span>            size<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>,
</span></span><span style=display:flex><span>            va<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;center&#34;</span>,
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> ax
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_periodogram</span>(ts, detrend<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;linear&#39;</span>, ax<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#f92672>from</span> scipy.signal <span style=color:#f92672>import</span> periodogram
</span></span><span style=display:flex><span>    fs <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Timedelta(<span style=color:#e6db74>&#34;1Y&#34;</span>) <span style=color:#f92672>/</span> pd<span style=color:#f92672>.</span>Timedelta(<span style=color:#e6db74>&#34;1D&#34;</span>)
</span></span><span style=display:flex><span>    freqencies, spectrum <span style=color:#f92672>=</span> periodogram(
</span></span><span style=display:flex><span>        ts,
</span></span><span style=display:flex><span>        fs<span style=color:#f92672>=</span>fs,
</span></span><span style=display:flex><span>        detrend<span style=color:#f92672>=</span>detrend,
</span></span><span style=display:flex><span>        window<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;boxcar&#34;</span>,
</span></span><span style=display:flex><span>        scaling<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;spectrum&#39;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> ax <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        _, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>step(freqencies, spectrum, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;purple&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xscale(<span style=color:#e6db74>&#34;log&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticks([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>26</span>, <span style=color:#ae81ff>52</span>, <span style=color:#ae81ff>104</span>])
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_xticklabels(
</span></span><span style=display:flex><span>        [
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Annual (1)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Semiannual (2)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Quarterly (4)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Bimonthly (6)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Monthly (12)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Biweekly (26)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Weekly (52)&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;Semiweekly (104)&#34;</span>,
</span></span><span style=display:flex><span>        ],
</span></span><span style=display:flex><span>        rotation<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>ticklabel_format(axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;y&#34;</span>, style<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sci&#34;</span>, scilimits<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>))
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_ylabel(<span style=color:#e6db74>&#34;Variance&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#34;Periodogram&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> ax
</span></span></code></pre></td></tr></table></div></div><p>We will start with the seasonal plots over a week and a year:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>X <span style=color:#f92672>=</span> tunnel<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># days within a week</span>
</span></span><span style=display:flex><span>X[<span style=color:#e6db74>&#34;day&#34;</span>] <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>dayofweek  <span style=color:#75715e># the x-axis (freq)</span>
</span></span><span style=display:flex><span>X[<span style=color:#e6db74>&#34;week&#34;</span>] <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>week  <span style=color:#75715e># the seasonal period (period)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># days within a year</span>
</span></span><span style=display:flex><span>X[<span style=color:#e6db74>&#34;dayofyear&#34;</span>] <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>dayofyear
</span></span><span style=display:flex><span>X[<span style=color:#e6db74>&#34;year&#34;</span>] <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>year
</span></span><span style=display:flex><span>fig, (ax0, ax1) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>seasonal_plot(X, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;NumVehicles&#34;</span>, period<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;week&#34;</span>, freq<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;day&#34;</span>, ax<span style=color:#f92672>=</span>ax0)
</span></span><span style=display:flex><span>seasonal_plot(X, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;NumVehicles&#34;</span>, period<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;year&#34;</span>, freq<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;dayofyear&#34;</span>, ax<span style=color:#f92672>=</span>ax1);
</span></span></code></pre></td></tr></table></div></div><p>For the periodogram:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>plot_periodogram(tunnel<span style=color:#f92672>.</span>NumVehicles);
</span></span></code></pre></td></tr></table></div></div><p>From the periodogram, there is a strong weekly season and a weaker annual season. We&rsquo;ll model the weekly season with indicator and the yearly season with Fourier features. From right to left, the periodogram falls off between Bimonthly (6) and Monthly (12), so let&rsquo;s use 10 Fourier pairs.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> statsmodels.tsa.deterministic <span style=color:#f92672>import</span> CalendarFourier, DeterministicProcess
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fourier <span style=color:#f92672>=</span> CalendarFourier(freq<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;A&#34;</span>, order<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)  <span style=color:#75715e># 10 sin/cos pairs for &#34;A&#34;nnual seasonality</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dp <span style=color:#f92672>=</span> DeterministicProcess(
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>tunnel<span style=color:#f92672>.</span>index,
</span></span><span style=display:flex><span>    constant<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,               <span style=color:#75715e># dummy feature for bias (y-intercept)</span>
</span></span><span style=display:flex><span>    order<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,                     <span style=color:#75715e># trend (order 1 means linear)</span>
</span></span><span style=display:flex><span>    seasonal<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,               <span style=color:#75715e># weekly seasonality (indicators)</span>
</span></span><span style=display:flex><span>    additional_terms<span style=color:#f92672>=</span>[fourier],  <span style=color:#75715e># annual seasonality (fourier)</span>
</span></span><span style=display:flex><span>    drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,                   <span style=color:#75715e># drop terms to avoid collinearity</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> dp<span style=color:#f92672>.</span>in_sample()  <span style=color:#75715e># create features for dates in tunnel.index</span>
</span></span></code></pre></td></tr></table></div></div><p>Model prediction:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>y <span style=color:#f92672>=</span> tunnel[<span style=color:#e6db74>&#34;NumVehicles&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression(fit_intercept<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X), index<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>X_fore <span style=color:#f92672>=</span> dp<span style=color:#f92672>.</span>out_of_sample(steps<span style=color:#f92672>=</span><span style=color:#ae81ff>90</span>)
</span></span><span style=display:flex><span>y_fore <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X_fore), index<span style=color:#f92672>=</span>X_fore<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>plot(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>, style<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;.&#39;</span>, title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Tunnel Traffic - Seasonal Forecast&#34;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Seasonal&#34;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_fore<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Seasonal Forecast&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax<span style=color:#f92672>.</span>legend()
</span></span></code></pre></td></tr></table></div></div><h2 id=4-time-series-as-features>4. Time Series as Features<a hidden class=anchor aria-hidden=true href=#4-time-series-as-features>#</a></h2><p>For some time series, they can only be modeled as a serially dependent properties, that is using as features past values of the target series. The goal in this lesson is to train models to fit curves to plots like those on the right &ndash; we want them to learn serial dependence:</p><p>One common way for serial dependence to manifest is in cycle - patterns of growth and decay in a time series associated with how the value in a series at one time depends on values at previous times, but not necessarily on the time step itself. Cyclic behavior is a characteristic of systems that can effect themselves, economies, epidemics, animal populations and volcano eruptions often display cyclic behavior:</p><blockquote><p>What distinguishes cyclic behavior from seasonality is that cycles are not necessarily time dependent, as seasons are. What happens in a cycle is less about the particular date of occurrence, and more about what has happened in the recent past</p></blockquote><h3 id=41-lagged-series--lag-plots>4.1 Lagged Series & Lag Plots<a hidden class=anchor aria-hidden=true href=#41-lagged-series--lag-plots>#</a></h3><p>To investigate serial dependence, we need to create &ldquo;lagged&rdquo; copies of the series. When we say &ldquo;lagging&rdquo;, it means we are shifting the time series values forward by one or more time steps. By lagging a time series, we make past values appear contemporaneous with the values we are trying to predict.</p><pre tabindex=0><code>
            y	    y_lag_1	y_lag_2			
1954-07	    5.8	    NaN	    NaN
1954-08	    6.0	    5.8	    NaN
1954-09	    6.1	    6.0	    5.8
1954-10	    5.7	    6.1	    6.0
1954-11	    5.3	    5.7	    6.1
</code></pre><p>A lag plot shows a time series values plotted against its lags. In the below images, there is a strong linear relationship between current unemployment rate and past rates.</p><p>In order to measure serial dependence, we can use autocorrelation - the correlation a time series has with one of its lag. In general, it would not be useful to include every lag with a large autocorrelation. We can find the partial autocorrelation that tells us the correlation of a lag accounting for all the previous lags (amount of new correlation the lag contribute).</p><p>In the figure below, lag 1 through lag 6 fall outside the intervals of &ldquo;no correlation&rdquo; (in blue), so we might choose lags 1 through lag 6 as features for US Unemployment. (Lag 11 is likely a false positive.)</p><p>Importantly, we need to be mindful that autocorrelation and partial autocorrelation are measures of linear dependence. Real-world time series often have non-linear dependences, it&rsquo;s good that a make a lag plot when choosing lag features.</p><p>Some non-linear relationship is the above image can be transformed to linear or learned by an appropriate algorithm.</p><h3 id=42-example>4.2 Example<a hidden class=anchor aria-hidden=true href=#42-example>#</a></h3><p>Let&rsquo;s define some functions for it to be used for the flu trend dataset, containing records of doctor&rsquo;s visits for the flu for weeks between 2009 and 2016:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">74
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> scipy.signal <span style=color:#f92672>import</span> periodogram
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> statsmodels.graphics.tsaplots <span style=color:#f92672>import</span> plot_pacf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>lagplot</span>(x, y<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, lag<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, standardize<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, ax<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, <span style=color:#f92672>**</span>kwargs):
</span></span><span style=display:flex><span>    <span style=color:#f92672>from</span> matplotlib.offsetbox <span style=color:#f92672>import</span> AnchoredText
</span></span><span style=display:flex><span>    x_ <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>shift(lag)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> standardize:
</span></span><span style=display:flex><span>        x_ <span style=color:#f92672>=</span> (x_ <span style=color:#f92672>-</span> x_<span style=color:#f92672>.</span>mean()) <span style=color:#f92672>/</span> x_<span style=color:#f92672>.</span>std()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> y <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        y_ <span style=color:#f92672>=</span> (y <span style=color:#f92672>-</span> y<span style=color:#f92672>.</span>mean()) <span style=color:#f92672>/</span> y<span style=color:#f92672>.</span>std() <span style=color:#66d9ef>if</span> standardize <span style=color:#66d9ef>else</span> y
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        y_ <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>    corr <span style=color:#f92672>=</span> y_<span style=color:#f92672>.</span>corr(x_)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> ax <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>    scatter_kws <span style=color:#f92672>=</span> dict(
</span></span><span style=display:flex><span>        alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.75</span>,
</span></span><span style=display:flex><span>        s<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    line_kws <span style=color:#f92672>=</span> dict(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>, )
</span></span><span style=display:flex><span>    ax <span style=color:#f92672>=</span> sns<span style=color:#f92672>.</span>regplot(x<span style=color:#f92672>=</span>x_,
</span></span><span style=display:flex><span>                     y<span style=color:#f92672>=</span>y_,
</span></span><span style=display:flex><span>                     scatter_kws<span style=color:#f92672>=</span>scatter_kws,
</span></span><span style=display:flex><span>                     line_kws<span style=color:#f92672>=</span>line_kws,
</span></span><span style=display:flex><span>                     lowess<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>                     ax<span style=color:#f92672>=</span>ax,
</span></span><span style=display:flex><span>                     <span style=color:#f92672>**</span>kwargs)
</span></span><span style=display:flex><span>    at <span style=color:#f92672>=</span> AnchoredText(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>corr<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>        prop<span style=color:#f92672>=</span>dict(size<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;large&#34;</span>),
</span></span><span style=display:flex><span>        frameon<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>        loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;upper left&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    at<span style=color:#f92672>.</span>patch<span style=color:#f92672>.</span>set_boxstyle(<span style=color:#e6db74>&#34;square, pad=0.0&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>add_artist(at)
</span></span><span style=display:flex><span>    ax<span style=color:#f92672>.</span>set(title<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Lag </span><span style=color:#e6db74>{</span>lag<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, xlabel<span style=color:#f92672>=</span>x_<span style=color:#f92672>.</span>name, ylabel<span style=color:#f92672>=</span>y_<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> ax
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_lags</span>(x, y<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, lags<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, nrows<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, lagplot_kwargs<span style=color:#f92672>=</span>{}, <span style=color:#f92672>**</span>kwargs):
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> math
</span></span><span style=display:flex><span>    kwargs<span style=color:#f92672>.</span>setdefault(<span style=color:#e6db74>&#39;nrows&#39;</span>, nrows)
</span></span><span style=display:flex><span>    kwargs<span style=color:#f92672>.</span>setdefault(<span style=color:#e6db74>&#39;ncols&#39;</span>, math<span style=color:#f92672>.</span>ceil(lags <span style=color:#f92672>/</span> nrows))
</span></span><span style=display:flex><span>    kwargs<span style=color:#f92672>.</span>setdefault(<span style=color:#e6db74>&#39;figsize&#39;</span>, (kwargs[<span style=color:#e6db74>&#39;ncols&#39;</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, nrows <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>0.5</span>))
</span></span><span style=display:flex><span>    fig, axs <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharey<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, squeeze<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, <span style=color:#f92672>**</span>kwargs)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> ax, k <span style=color:#f92672>in</span> zip(fig<span style=color:#f92672>.</span>get_axes(), range(kwargs[<span style=color:#e6db74>&#39;nrows&#39;</span>] <span style=color:#f92672>*</span> kwargs[<span style=color:#e6db74>&#39;ncols&#39;</span>])):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> k <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> lags:
</span></span><span style=display:flex><span>            ax <span style=color:#f92672>=</span> lagplot(x, y, lag<span style=color:#f92672>=</span>k <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, ax<span style=color:#f92672>=</span>ax, <span style=color:#f92672>**</span>lagplot_kwargs)
</span></span><span style=display:flex><span>            ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Lag </span><span style=color:#e6db74>{</span>k <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, fontdict<span style=color:#f92672>=</span>dict(fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>))
</span></span><span style=display:flex><span>            ax<span style=color:#f92672>.</span>set(xlabel<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>, ylabel<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            ax<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>setp(axs[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, :], xlabel<span style=color:#f92672>=</span>x<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>setp(axs[:, <span style=color:#ae81ff>0</span>], ylabel<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>name <span style=color:#66d9ef>if</span> y <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> <span style=color:#66d9ef>None</span> <span style=color:#66d9ef>else</span> x<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span>    fig<span style=color:#f92672>.</span>tight_layout(w_pad<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, h_pad<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> fig
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_dir <span style=color:#f92672>=</span> Path(<span style=color:#e6db74>&#34;../input/ts-course-data&#34;</span>)
</span></span><span style=display:flex><span>flu_trends <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(data_dir <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;flu-trends.csv&#34;</span>)
</span></span><span style=display:flex><span>flu_trends<span style=color:#f92672>.</span>set_index(
</span></span><span style=display:flex><span>    pd<span style=color:#f92672>.</span>PeriodIndex(flu_trends<span style=color:#f92672>.</span>Week, freq<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;W&#34;</span>),
</span></span><span style=display:flex><span>    inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>flu_trends<span style=color:#f92672>.</span>drop(<span style=color:#e6db74>&#34;Week&#34;</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits<span style=color:#f92672>.</span>plot(title<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Flu Trends&#39;</span>, <span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax<span style=color:#f92672>.</span>set(ylabel<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Office Visits&#34;</span>)
</span></span></code></pre></td></tr></table></div></div><blockquote><p>Flu Trends data shows irregular cycles instead of a regular seasonality: the peak tends to occur around the new year, but sometimes earlier or later, sometimes larger or smaller.</p></blockquote><p>Let&rsquo;s look at the lag and autocorrelation plot:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>_ <span style=color:#f92672>=</span> plot_lags(flu_trends<span style=color:#f92672>.</span>FluVisits, lags<span style=color:#f92672>=</span><span style=color:#ae81ff>12</span>, nrows<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> plot_pacf(flu_trends<span style=color:#f92672>.</span>FluVisits, lags<span style=color:#f92672>=</span><span style=color:#ae81ff>12</span>)
</span></span></code></pre></td></tr></table></div></div><p>From the lag plot, it seems that the relationship of the flu visits to its lags is mostly linear. For PACF plot, we can capture the serial dependence using lags 1, 2, 3 and 4. Here&rsquo;s how to make lag and fill the <code>NaN</code> cells with 0:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_lags</span>(ts, lags):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> pd<span style=color:#f92672>.</span>concat(
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;y_lag_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>: ts<span style=color:#f92672>.</span>shift(i)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, lags <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>        axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> make_lags(flu_trends<span style=color:#f92672>.</span>FluVisits, lags<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>fillna(<span style=color:#ae81ff>0.0</span>)
</span></span></code></pre></td></tr></table></div></div><p>Making forecast:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># Create target series and data splits</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>60</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit and predict</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()  <span style=color:#75715e># `fit_intercept=True` since we didn&#39;t use DeterministicProcess</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X_train), index<span style=color:#f92672>=</span>y_train<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>y_fore <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X_test), index<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_train<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_test<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> y_fore<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>)
</span></span></code></pre></td></tr></table></div></div><p>To improve the forecast we could try to find leading indicators, time series that could provide an &ldquo;early warning&rdquo; for changes in flu cases. For our second approach then we&rsquo;ll add to our training data the popularity of some flu-related search terms as measured by Google Trends.</p><p>Plotting the search phrase &lsquo;FluCough&rsquo; against the target &lsquo;FluVisits&rsquo; suggests such search terms could be useful as leading indicators: flu-related searches tend to become more popular in the weeks prior to office visits.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>ax <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    y<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;FluCough&#34;</span>, <span style=color:#e6db74>&#34;FluVisits&#34;</span>],
</span></span><span style=display:flex><span>    secondary_y<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;FluCough&#34;</span>,
</span></span><span style=display:flex><span>)
</span></span></code></pre></td></tr></table></div></div><p>Filtering the search terms:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>search_terms <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;FluContagious&#34;</span>, <span style=color:#e6db74>&#34;FluCough&#34;</span>, <span style=color:#e6db74>&#34;FluFever&#34;</span>, <span style=color:#e6db74>&#34;InfluenzaA&#34;</span>, <span style=color:#e6db74>&#34;TreatFlu&#34;</span>, <span style=color:#e6db74>&#34;IHaveTheFlu&#34;</span>, <span style=color:#e6db74>&#34;OverTheCounterFlu&#34;</span>, <span style=color:#e6db74>&#34;HowLongFlu&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create three lags for each search term</span>
</span></span><span style=display:flex><span>X0 <span style=color:#f92672>=</span> make_lags(flu_trends[search_terms], lags<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>X0<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39; &#39;</span><span style=color:#f92672>.</span>join(col)<span style=color:#f92672>.</span>strip() <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> X0<span style=color:#f92672>.</span>columns<span style=color:#f92672>.</span>values]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create four lags for the target, as before</span>
</span></span><span style=display:flex><span>X1 <span style=color:#f92672>=</span> make_lags(flu_trends[<span style=color:#e6db74>&#39;FluVisits&#39;</span>], lags<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Combine to create the training data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat([X0, X1], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>fillna(<span style=color:#ae81ff>0.0</span>)
</span></span></code></pre></td></tr></table></div></div><p>Forecast:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">9
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>60</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X_train), index<span style=color:#f92672>=</span>y_train<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>y_fore <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(model<span style=color:#f92672>.</span>predict(X_test), index<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> y_test<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> y_fore<span style=color:#f92672>.</span>plot(ax<span style=color:#f92672>=</span>ax, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>)
</span></span></code></pre></td></tr></table></div></div><p>Our forecasts are a bit rougher, but our model appears to be better able to anticipate sudden increases in flu visits, suggesting that the several time series of search popularity were indeed effective as leading indicators.</p><blockquote><p>The time series illustrated in this lesson are what you might call &ldquo;purely cyclic&rdquo;: they have no obvious trend or seasonality. It&rsquo;s not uncommon though for time series to possess trend, seasonality, and cycles &ndash; all three components at once. You could model such series with linear regression by just adding the appropriate features for each component. You can even combine models trained to learn the components separately</p></blockquote><h2 id=5-hybrid-models>5. Hybrid Models<a hidden class=anchor aria-hidden=true href=#5-hybrid-models>#</a></h2><p>To design an effective hybrid, we have to know how a time series is constructed. Previously, we learned about trend, season and cycles. Many time series can be described by an additive model of these three components plus some error term:</p><pre tabindex=0><code>series = trend + seasons + cycles + error
</code></pre><p>Residuals of a model are the difference between the model&rsquo;s target and the prediction, as illustrated below:</p><p>Now imagine that we learn the time series components in an iterative manner: we start by learning the trend, then by subtracting it out, we learn the series seasonality, follow by cycles and then the error term:</p><p>Of course, it is possible for use to use one algorithm for some components and another algorithm for the rest. That means, we use one algorithm to fit the original series and another algorithm for the residuals series:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># 1. Train and predict with first model</span>
</span></span><span style=display:flex><span>model_1<span style=color:#f92672>.</span>fit(X_train_1, y_train)
</span></span><span style=display:flex><span>y_pred_1 <span style=color:#f92672>=</span> model_1<span style=color:#f92672>.</span>predict(X_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. Train and predict with second model on residuals</span>
</span></span><span style=display:flex><span>model_2<span style=color:#f92672>.</span>fit(X_train_2, y_train <span style=color:#f92672>-</span> y_pred_1)
</span></span><span style=display:flex><span>y_pred_2 <span style=color:#f92672>=</span> model_2<span style=color:#f92672>.</span>predict(X_train_2)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. Add to get overall predictions</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> y_pred_1 <span style=color:#f92672>+</span> y_pred_2
</span></span></code></pre></td></tr></table></div></div><p>While it&rsquo;s possible to use more than two models, in practice it doesn&rsquo;t seem to be especially helpful. In fact, the most common strategy for constructing hybrids is the one we&rsquo;ve just described: a simple (usually linear) learning algorithm followed by a complex, non-linear learner like GBDTs or a deep neural net, the simple model typically designed as a &ldquo;helper&rdquo; for the powerful algorithm that follows.</p><p>There are generally two ways a regression algorithm can make predictions: either by transforming the features or by transforming the target. Feature-transforming algorithms learn some mathematical function that takes features as an input and then combines and transforms them to produce an output that matches the target values in the training set. Linear regression and neural nets are of this kind.</p><p>Target-transforming algorithms use the features to group the target values in the training set and make predictions by averaging values in a group; a set of feature just indicates which group to average. Decision trees and nearest neighbors are of this kind.</p><p>The important thing is this: feature transformers generally can extrapolate target values beyond the training set given appropriate features as inputs, but the predictions of target transformers will always be bound within the range of the training set. If the time dummy continues counting time steps, linear regression continues drawing the trend line. Given the same time dummy, a decision tree will predict the trend indicated by the last step of the training data into the future forever. Decision trees cannot extrapolate trends. Random forests and gradient boosted decision trees (like XGBoost) are ensembles of decision trees, so they also cannot extrapolate trends.</p><p>So, we could use linear regression to extrapolate the trend, transform the target to remove the trend, and apply XGBoost to the detrended residuals. To hybridize a neural net (a feature transformer), you could instead include the predictions of another model as a feature, which the neural net would then include as part of its own predictions. The method of fitting to residuals is actually the same method the gradient boosting algorithm uses, so we will call these boosted hybrids; the method of using predictions as features is known as &ldquo;stacking&rdquo;, so we will call these stacked hybrids.</p><h3 id=51-example>5.1 Example<a hidden class=anchor aria-hidden=true href=#51-example>#</a></h3><p>In this example, we will use the US Retail Sales data set from 1992 to 2019. We will also create a linear regression and XGBoost hybrid for prediction.</p><pre tabindex=0><code>            BuildingMaterials	FoodAndBeverage	
1992-01-01	8964	            29589
1992-02-01	9023	            28570
1992-03-01	10608	            29682
1992-04-01	11630	            30228
1992-05-01	12327	            31677
</code></pre><p>We will start by learning the trend of the series using linear regression (a quadratic trend is used)</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>y <span style=color:#f92672>=</span> retail<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create trend features</span>
</span></span><span style=display:flex><span>dp <span style=color:#f92672>=</span> DeterministicProcess(
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>index,  <span style=color:#75715e># dates from the training data</span>
</span></span><span style=display:flex><span>    constant<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,  <span style=color:#75715e># the intercept</span>
</span></span><span style=display:flex><span>    order<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,        <span style=color:#75715e># quadratic trend</span>
</span></span><span style=display:flex><span>    drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,      <span style=color:#75715e># drop terms to avoid collinearity</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> dp<span style=color:#f92672>.</span>in_sample()  <span style=color:#75715e># features for the training data</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Test on the years 2016-2019. It will be easier for us later if we</span>
</span></span><span style=display:flex><span><span style=color:#75715e># split the date index instead of the dataframe directly.</span>
</span></span><span style=display:flex><span>idx_train, idx_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    y<span style=color:#f92672>.</span>index, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>12</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>X_train, X_test <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>loc[idx_train, :], X<span style=color:#f92672>.</span>loc[idx_test, :]
</span></span><span style=display:flex><span>y_train, y_test <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>loc[idx_train], y<span style=color:#f92672>.</span>loc[idx_test]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit trend model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression(fit_intercept<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Make predictions</span>
</span></span><span style=display:flex><span>y_fit <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>predict(X_train),
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>y_train<span style=color:#f92672>.</span>index,
</span></span><span style=display:flex><span>    columns<span style=color:#f92672>=</span>y_train<span style=color:#f92672>.</span>columns,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>predict(X_test),
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>index,
</span></span><span style=display:flex><span>    columns<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>columns,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Plot</span>
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_train<span style=color:#f92672>.</span>plot(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_test<span style=color:#f92672>.</span>plot(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_fit<span style=color:#f92672>.</span>plot(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C0&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>plot(color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ax <span style=color:#f92672>in</span> axs: ax<span style=color:#f92672>.</span>legend([])
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>suptitle(<span style=color:#e6db74>&#34;Trends&#34;</span>)
</span></span></code></pre></td></tr></table></div></div><p>Linear regression algorithm is capable of multi-output regression, the XGBoost algorithm is not. To predict multiple series at once with XGBoost, we&rsquo;ll instead convert these series from wide format, with one time series per column, to long format, with series indexed by categories along rows.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># The `stack` method converts column labels to row labels, pivoting from wide format to long</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> retail<span style=color:#f92672>.</span>stack()  <span style=color:#75715e># pivot dataset wide to long</span>
</span></span><span style=display:flex><span>display(X<span style=color:#f92672>.</span>head())
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>pop(<span style=color:#e6db74>&#39;Sales&#39;</span>)  <span style=color:#75715e># grab target series</span>
</span></span></code></pre></td></tr></table></div></div><pre tabindex=0><code>            Industries	
1992-01-01	BuildingMaterials	8964
            FoodAndBeverage	    29589
1992-02-01	BuildingMaterials	9023
            FoodAndBeverage	    28570
1992-03-01	BuildingMaterials	10608
</code></pre><p>Construct the train and test set:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># Turn row labels into categorical feature columns with a label encoding</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>reset_index(<span style=color:#e6db74>&#39;Industries&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># Label encoding for &#39;Industries&#39; feature</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> colname <span style=color:#f92672>in</span> X<span style=color:#f92672>.</span>select_dtypes([<span style=color:#e6db74>&#34;object&#34;</span>, <span style=color:#e6db74>&#34;category&#34;</span>]):
</span></span><span style=display:flex><span>    X[colname], _ <span style=color:#f92672>=</span> X[colname]<span style=color:#f92672>.</span>factorize()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Label encoding for annual seasonality</span>
</span></span><span style=display:flex><span>X[<span style=color:#e6db74>&#34;Month&#34;</span>] <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>month  <span style=color:#75715e># values are 1, 2, ..., 12</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create splits</span>
</span></span><span style=display:flex><span>X_train, X_test <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>loc[idx_train, :], X<span style=color:#f92672>.</span>loc[idx_test, :]
</span></span><span style=display:flex><span>y_train, y_test <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>loc[idx_train], y<span style=color:#f92672>.</span>loc[idx_test]
</span></span></code></pre></td></tr></table></div></div><p>Convert the trend predictions made earlier to long format and then subtract them from the original series. That will give us detrended (residual) series that XGBoost can learn.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># Pivot wide to long (stack) and convert DataFrame to Series (squeeze)</span>
</span></span><span style=display:flex><span>y_fit <span style=color:#f92672>=</span> y_fit<span style=color:#f92672>.</span>stack()<span style=color:#f92672>.</span>squeeze()    <span style=color:#75715e># trend from training set</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> y_pred<span style=color:#f92672>.</span>stack()<span style=color:#f92672>.</span>squeeze()  <span style=color:#75715e># trend from test set</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create residuals (the collection of detrended series) from the training set</span>
</span></span><span style=display:flex><span>y_resid <span style=color:#f92672>=</span> y_train <span style=color:#f92672>-</span> y_fit
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train XGBoost on the residuals</span>
</span></span><span style=display:flex><span>xgb <span style=color:#f92672>=</span> XGBRegressor()
</span></span><span style=display:flex><span>xgb<span style=color:#f92672>.</span>fit(X_train, y_resid)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Add the predicted residuals onto the predicted trends</span>
</span></span><span style=display:flex><span>y_fit_boosted <span style=color:#f92672>=</span> xgb<span style=color:#f92672>.</span>predict(X_train) <span style=color:#f92672>+</span> y_fit
</span></span><span style=display:flex><span>y_pred_boosted <span style=color:#f92672>=</span> xgb<span style=color:#f92672>.</span>predict(X_test) <span style=color:#f92672>+</span> y_pred
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_train<span style=color:#f92672>.</span>unstack([<span style=color:#e6db74>&#39;Industries&#39;</span>])<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>5</span>), subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    title<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;BuildingMaterials&#39;</span>, <span style=color:#e6db74>&#39;FoodAndBeverage&#39;</span>],
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_test<span style=color:#f92672>.</span>unstack([<span style=color:#e6db74>&#39;Industries&#39;</span>])<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0.25&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_fit_boosted<span style=color:#f92672>.</span>unstack([<span style=color:#e6db74>&#39;Industries&#39;</span>])<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C0&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>axs <span style=color:#f92672>=</span> y_pred_boosted<span style=color:#f92672>.</span>unstack([<span style=color:#e6db74>&#39;Industries&#39;</span>])<span style=color:#f92672>.</span>plot(
</span></span><span style=display:flex><span>    color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;C3&#39;</span>, subplots<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, sharex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, ax<span style=color:#f92672>=</span>axs,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ax <span style=color:#f92672>in</span> axs: ax<span style=color:#f92672>.</span>legend([])
</span></span></code></pre></td></tr></table></div></div><h2 id=6-forecasting-with-machine-learning>6. Forecasting with Machine Learning<a hidden class=anchor aria-hidden=true href=#6-forecasting-with-machine-learning>#</a></h2><p>Before we design a forecasting model, we should ask:</p><ul><li>What information is available at the time the forecast is made</li><li>Time period during which you require the forecasted values</li></ul><p>The <strong>forecast origin</strong> is time at which you are making a forecast. Practically, you might consider the forecast origin to be the last time for which you have training data for the time being predicted. Everything up to he origin can be used to create features.</p><p>The <strong>forecast horizon</strong> is the time for which you are making a forecast. We often describe a forecast by the number of time steps in its horizon: a &ldquo;1-step&rdquo; forecast or &ldquo;5-step&rdquo; forecast, say. The forecast horizon describes the target.</p><p>The time between the origin and the horizon is the lead time (or sometimes latency) of the forecast. A forecast&rsquo;s lead time is described by the number of steps from origin to horizon: a &ldquo;1-step ahead&rdquo; or &ldquo;3-step ahead&rdquo; forecast, say. In practice, it may be necessary for a forecast to begin multiple steps ahead of the origin because of delays in data acquisition or processing.</p><p>To forecast time series with ML algorithm, we have to transform the series into a <code>DataFrame</code> that we can use with the algorithms. Each row in a <code>DataFrame</code> represents a single forecast. The time index of the row is the first time in the forecast horizon, but we arrange values for the entire horizon in the same row. For multistep forecasts, this means we are requiring a model to produce multiple outputs, one for each step.</p><p>The above illustrates how a dataset would be prepared similar to the Defining a Forecast figure: a three-step forecasting task with a two-step lead time using five lag features. The original time series is y_step_1. The missing values we could either fill in or drop.</p><h3 id=61-multistep-forecasting-strategies>6.1 Multistep Forecasting Strategies<a hidden class=anchor aria-hidden=true href=#61-multistep-forecasting-strategies>#</a></h3><p><strong>Direct Strategy</strong>
Train a separate model for each step in the horizon: one model forecasts 1-step ahead, another 2-steps ahead, and so on. Forecasting 1-step ahead is a different problem than 2-steps ahead (and so on), so it can help to have a different model make forecasts for each step. The downside is that training lots of models can be computationally expensive.</p><p><strong>Recursive Strategy</strong>
Train a single one-step model and use its forecasts to update the lag features for the next step. With the recursive method, we feed a model&rsquo;s 1-step forecast back in to that same model to use as a lag feature for the next forecasting step. We only need to train one model, but since errors will propagate from step to step, forecasts can be inaccurate for long horizons.</p><p><strong>DirRec Strategy</strong>
A combination of the direct and recursive strategies: train a model for each step and use forecasts from previous steps as new lag features. Step by step, each model gets an additional lag input. Since each model always has an up-to-date set of lag features, the DirRec strategy can capture serial dependence better than Direct, but it can also suffer from error propagation like Recursive.</p><h3 id=62-example>6.2 Example<a hidden class=anchor aria-hidden=true href=#62-example>#</a></h3><p>Here, let&rsquo;s take a look at the flu trends dataset previously used. We will apply multi-output and direct strategy to the dataset for forecast.</p><p>Preparing datset:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_lags</span>(ts, lags, lead_time<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> pd<span style=color:#f92672>.</span>concat(
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;y_lag_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>: ts<span style=color:#f92672>.</span>shift(i)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(lead_time, lags <span style=color:#f92672>+</span> lead_time)
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>        axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Four weeks of lag features</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> make_lags(y, lags<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)<span style=color:#f92672>.</span>fillna(<span style=color:#ae81ff>0.0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>make_multistep_target</span>(ts, steps):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> pd<span style=color:#f92672>.</span>concat(
</span></span><span style=display:flex><span>        {<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;y_step_</span><span style=color:#e6db74>{</span>i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>: ts<span style=color:#f92672>.</span>shift(<span style=color:#f92672>-</span>i)
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(steps)},
</span></span><span style=display:flex><span>        axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Eight-week forecast</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> make_multistep_target(y, steps<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>)<span style=color:#f92672>.</span>dropna()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Shifting has created indexes that don&#39;t match. Only keep times for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># which we have both targets and features.</span>
</span></span><span style=display:flex><span>y, X <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>align(X, join<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;inner&#39;</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># Create splits</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.25</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_fit <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(model<span style=color:#f92672>.</span>predict(X_train), index<span style=color:#f92672>=</span>X_train<span style=color:#f92672>.</span>index, columns<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>columns)
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(model<span style=color:#f92672>.</span>predict(X_test), index<span style=color:#f92672>=</span>X_test<span style=color:#f92672>.</span>index, columns<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>columns)
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>train_rmse <span style=color:#f92672>=</span> mean_squared_error(y_train, y_fit, squared<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>test_rmse <span style=color:#f92672>=</span> mean_squared_error(y_test, y_pred, squared<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>print((<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train RMSE: </span><span style=color:#e6db74>{</span>train_rmse<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test RMSE: </span><span style=color:#e6db74>{</span>test_rmse<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>palette <span style=color:#f92672>=</span> dict(palette<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;husl&#39;</span>, n_colors<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>fig, (ax1, ax2) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>ax1 <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits[y_fit<span style=color:#f92672>.</span>index]<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params, ax<span style=color:#f92672>=</span>ax1)
</span></span><span style=display:flex><span>ax1 <span style=color:#f92672>=</span> plot_multistep(y_fit, ax<span style=color:#f92672>=</span>ax1, palette_kwargs<span style=color:#f92672>=</span>palette)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax1<span style=color:#f92672>.</span>legend([<span style=color:#e6db74>&#39;FluVisits (train)&#39;</span>, <span style=color:#e6db74>&#39;Forecast&#39;</span>])
</span></span><span style=display:flex><span>ax2 <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits[y_pred<span style=color:#f92672>.</span>index]<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params, ax<span style=color:#f92672>=</span>ax2)
</span></span><span style=display:flex><span>ax2 <span style=color:#f92672>=</span> plot_multistep(y_pred, ax<span style=color:#f92672>=</span>ax2, palette_kwargs<span style=color:#f92672>=</span>palette)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax2<span style=color:#f92672>.</span>legend([<span style=color:#e6db74>&#39;FluVisits (test)&#39;</span>, <span style=color:#e6db74>&#39;Forecast&#39;</span>])
</span></span></code></pre></td></tr></table></div></div><p>XGBoost can&rsquo;t produce multiple outputs for regression tasks. But by applying the Direct reduction strategy, we can still use it to produce multi-step forecasts. This is as easy as wrapping it with scikit-learn&rsquo;s MultiOutputRegressor.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.multioutput <span style=color:#f92672>import</span> MultiOutputRegressor
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> MultiOutputRegressor(XGBRegressor())
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_fit <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(model<span style=color:#f92672>.</span>predict(X_train), index<span style=color:#f92672>=</span>X_train<span style=color:#f92672>.</span>index, columns<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>columns)
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(model<span style=color:#f92672>.</span>predict(X_test), index<span style=color:#f92672>=</span>X_test<span style=color:#f92672>.</span>index, columns<span style=color:#f92672>=</span>y<span style=color:#f92672>.</span>columns)
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>train_rmse <span style=color:#f92672>=</span> mean_squared_error(y_train, y_fit, squared<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>test_rmse <span style=color:#f92672>=</span> mean_squared_error(y_test, y_pred, squared<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>print((<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train RMSE: </span><span style=color:#e6db74>{</span>train_rmse<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test RMSE: </span><span style=color:#e6db74>{</span>test_rmse<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>palette <span style=color:#f92672>=</span> dict(palette<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;husl&#39;</span>, n_colors<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>fig, (ax1, ax2) <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>ax1 <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits[y_fit<span style=color:#f92672>.</span>index]<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params, ax<span style=color:#f92672>=</span>ax1)
</span></span><span style=display:flex><span>ax1 <span style=color:#f92672>=</span> plot_multistep(y_fit, ax<span style=color:#f92672>=</span>ax1, palette_kwargs<span style=color:#f92672>=</span>palette)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax1<span style=color:#f92672>.</span>legend([<span style=color:#e6db74>&#39;FluVisits (train)&#39;</span>, <span style=color:#e6db74>&#39;Forecast&#39;</span>])
</span></span><span style=display:flex><span>ax2 <span style=color:#f92672>=</span> flu_trends<span style=color:#f92672>.</span>FluVisits[y_pred<span style=color:#f92672>.</span>index]<span style=color:#f92672>.</span>plot(<span style=color:#f92672>**</span>plot_params, ax<span style=color:#f92672>=</span>ax2)
</span></span><span style=display:flex><span>ax2 <span style=color:#f92672>=</span> plot_multistep(y_pred, ax<span style=color:#f92672>=</span>ax2, palette_kwargs<span style=color:#f92672>=</span>palette)
</span></span><span style=display:flex><span>_ <span style=color:#f92672>=</span> ax2<span style=color:#f92672>.</span>legend([<span style=color:#e6db74>&#39;FluVisits (test)&#39;</span>, <span style=color:#e6db74>&#39;Forecast&#39;</span>])
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/time-series/>Time Series</a></li><li><a href=http://localhost:1313/tags/forecasting/>Forecasting</a></li><li><a href=http://localhost:1313/tags/python/>Python</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/2023/2023-08-19-data-cleaning/><span class=title>« Bài mới hơn</span><br><span>Data Cleaning</span>
</a><a class=next href=http://localhost:1313/posts/2023/2023-08-15-data-visualization/><span class=title>Bài cũ hơn »</span><br><span>Data Visualization</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on x" href="https://x.com/intent/tweet/?text=Time%20Series&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f&amp;hashtags=TimeSeries%2cForecasting%2cPython"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f&amp;title=Time%20Series&amp;summary=Time%20Series&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f&title=Time%20Series"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on whatsapp" href="https://api.whatsapp.com/send?text=Time%20Series%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on telegram" href="https://telegram.me/share/url?text=Time%20Series&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Time Series on ycombinator" href="https://news.ycombinator.com/submitlink?t=Time%20Series&u=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-08-19-time-series%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>The Financial Engineer</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Sao chép";function s(){t.innerHTML="Đã sao chép!",setTimeout(()=>{t.innerHTML="Sao chép"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>