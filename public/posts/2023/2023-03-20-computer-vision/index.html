<!doctype html><html lang=vi dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Computer Vision | The Financial Engineer</title>
<meta name=keywords content="Python,Computer Vision,Image Classification,Kaggle"><meta name=description content="My Kaggle Learning Note 5"><meta name=author content="Kean Teng Blog"><link rel=canonical href=http://localhost:1313/posts/2023/2023-03-20-computer-vision/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=vi href=http://localhost:1313/posts/2023/2023-03-20-computer-vision/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Computer Vision"><meta property="og:description" content="My Kaggle Learning Note 5"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/2023/2023-03-20-computer-vision/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-20T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-20T00:00:00+00:00"><meta property="og:site_name" content="QHung's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Computer Vision"><meta name=twitter:description content="My Kaggle Learning Note 5"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Computer Vision","item":"http://localhost:1313/posts/2023/2023-03-20-computer-vision/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Computer Vision","name":"Computer Vision","description":"My Kaggle Learning Note 5","keywords":["Python","Computer Vision","Image Classification","Kaggle"],"articleBody":" Disclaimer: This article is my learning note from the courses I took from Kaggle.\nComputer vision literally means computer able to see and recognize stuff. Applications such as Google Lens and Google Image Search are some good examples of where computer vision is being used in our daily life.\nIn this course, we will explore some technique used to empower computer with the power of seeing:\nBuilding an image classifier with Keras Concepts of visual feature extraction Custom covnet Apply data augmentation to extend dataset. 1. Convolutional Classifier Convolutional neural networks or “covnet” is a neural network specializes in computer vision. A covnet used for image classification has two parts: a convolutional base and a dense head. The base is used to extract the features of an image while the head is used to determine the class of the image. So, the aims of training a neural network are simply to know which feature to extract from a particular image and to know which class the image will belong from the features.\nHere is how we can train a covnet on Python to recognize a car and a truck:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # 1. load pretrained base pretrained_base = tf.keras.models.load_model( # file path '../input/cv-course-models/cv-course-models/vgg16-pretrained-base', ) pretrained_base.trainable = False # 2. attach classfier head from tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ pretrained_base, layers.Flatten(), # transform 2d output to 1d layers.Dense(6, activation = 'relu'), layers.Dense(1, activation = 'sigmoid'), # transform output to class probability (truck) ]) # 3. model fitting model.compile( optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accurary'], ) history = model.fit( ds_train, validation_data = ds_valid, epochs = 30, verbose = 0, ) # 4. visualize model loss import pandas as pd history_frame = pd.DataFrame(history.history) history_frame.loc[:, ['loss', 'val_loss']].plot() history_frame.loc[:, ['binary_accurary', 'val_binary_accurary']].plot(); 2. Features Extraction 2.1 Convolution and ReLU The process of feature extraction does three things. It filters an image for a certain feature; it detects the feature within the filtered image, and it condenses the image to enhance the features.\nIn training, the covnet will learn weights from image features and the weights are contained in the convolutional layers. The weights are known as kernels which can be presented as an array of number. A kernel will scan over an image and produce a weighted sum of pixel values (finding the best kernel values) — emphasizing and de-emphasizing certain image patterns and information.\nActivations in the network is called feature maps. Feature maps is the result when filter is applied to image — it contains features a kernel extract.\nAfter filtering, the feature maps will be passed to an activation function which can be though as scoring pixel values according to some measure of importance. For example, ReLU activation assumes negative values are not important, so they are set to zero. In fact, these images are how the head of a network is able to solve the classification problem — looking for a particular characteristic of images that we want to classify.\nHere’s how to can perform feature extraction in Python:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # define kernel import tensorflow as tf kernel =tf.constant([ [-1, -1, -1], [-1, 8, -1], [-1, -1, -1], ]) plt.figure(figsize = (3,3)) show_kernel(kernel) # applying kernel image_filter = tf.nn.conv2d( input = image, fitlers = kernel, strides = 1, # section 3 padding = 'SAME', ) plt.figure(figsize = (6,6)) plt.imshow(tf.squeeze(image_filter)) plt.axis('off') plt.show(); # applying activation function image_detect = tf.nn.relu(image_filter) plt.figure(figsize = (6,6)) plt.imshow(tf.squeeze(image_filter)) plt.axis('off') plt.show(); 2.2 Maximum Pooling 1 2 3 4 5 6 7 8 from tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Conv2D(filters=64, kernel_size=3), # activation is None layers.MaxPool2D(pool_size=2), # More layers follow ]) Notice that after the Conv2D layer, we will apply a MaxPool2D layer for the condensation step. This layer will not contain any trainable weights as of the previous layer, but it will condense the feature maps to only retain important feature. This is what maximum pooling does. It takes patches of activations in the original feature maps and replaces them with maximum activation in those patches. The pooling steps will increase the proportions of active pixels to zero pixels — intensifying the feature after ReLU activation.\nIs zero pixels unimportant? In fact, zero pixels carries positional information and MaxPool2D function will remove them (positional information of the feature maps) and this will lead to a property in covnet known as translation invariance.\nThis means that a covnet with maximum pooling tend to not distinguish features by their location in image. Notice from the first row of images below, after repeated pooling, the positional information is destroyed and no longer distinguishable. But pooling only causes translation invariance in network over small distance. The second row of the image features two dots far apart and this feature remains distinct after repeated pooling.\nIn fact, such invariance is good for an image classifier as it reduces data for training since we do not need to teach the network differences in perspective and framing when same features are positioned on different part of an original image.\n3. Sliding Window Both convolution and pooling steps are performed over a sliding window with parameters “kernel_size” for convolution and “pool_size” for pooling.\nNotice in section 2.1, when we perform pooling, there are two extra parameters: strides and padding. strides means how far the window will move each step and padding describes how the pixels at the edge are being handle.\nConsidering the sliding window process, is it necessary to always stay within the boundary? In fact, there is a trade-off between staying within and out of bound by changing the parameter padding in our code:\npadding = ‘valid’: Convolution window stay entirely inside input. Output will shrink. It will shrink more for larger kernels. This will limit the number of layers contained in a network, notably small size input. padding = ‘same’: Pad the input with 0’s around the border to make size of output and input the same. However, this will dilute the influence of pixels at the borders. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'), layers.MaxPool2D(pool_size=2, strides=1, padding='same') # More layers follow ]) Example for visualization:\n1 2 3 4 5 6 7 8 9 10 11 show_extraction( image, kernel, # Window parameters conv_stride=3, pool_size=2, pool_stride=2, subplot_shape=(1, 4), figsize=(14, 6), ) Since the circle is just 1 pixel wide, using stride = 3 is too coarse to produce a decent feature maps. We should then reduce the number of strides for a better feature map.\n4. Custom Covnet Through feature extraction, we learned how to extract simple features from an image through filter, detect and pooling. By repeating the extraction process, we can extract more complex and refined features as the process travel deeper into the network.\nThis can be done through convolution blocks with stacks of Conv2D and MaxPool2D layers as below:\nHere’s how we can design a covnet that can extract complex features:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 1. define model from tensorflow import keras from tensorflow.keras import layers model = keras.Sequential([ # First Convolutional Block layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same', input_shape=[128, 128, 3]), layers.MaxPool2D(), # Second Convolutional Block layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'), layers.MaxPool2D(), # Third Convolutional Block layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'), layers.MaxPool2D(), # Classifier Head layers.Flatten(), layers.Dense(units=6, activation=\"relu\"), layers.Dense(units=1, activation=\"sigmoid\"), ]) model.summary() # 2. model training model.compile( optimizer=tf.keras.optimizers.Adam(epsilon=0.01), loss='binary_crossentropy', metrics=['binary_accuracy'] ) history = model.fit( ds_train, validation_data=ds_valid, epochs=40, verbose=0, ) # 3. model loss evaluation import pandas as pd history_frame = pd.DataFrame(history.history) history_frame.loc[:, ['loss', 'val_loss']].plot() history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(); 5. Data Augmentation More data will generally help a model performs better — to better differentiate image. In this section, we will learn to augment our data by applying transformation to our datasets such as rotation, flipping, warping and changing of contrast and color tone. Here’s how to perform data augmentation in Python:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 1. define model - with augmentation from tensorflow import keras from tensorflow.keras import layers pretrained_base = tf.keras.models.load_model( '../input/cv-course-models/cv-course-models/vgg16-pretrained-base', ) pretrained_base.trainable = False model = keras.Sequential([ # Preprocessing layers.RandomFlip('horizontal'), # flip left-to-right layers.RandomContrast(0.5), # contrast change by up to 50% # Base pretrained_base, # Head layers.Flatten(), layers.Dense(6, activation='relu'), layers.Dense(1, activation='sigmoid'), ]) # 2. model training model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'], ) history = model.fit( ds_train, validation_data=ds_valid, epochs=30, verbose=0, ) # 3. model loss evaluation import pandas as pd history_frame = pd.DataFrame(history.history) history_frame.loc[:, ['loss', 'val_loss']].plot() history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(); ","wordCount":"1551","inLanguage":"vi","datePublished":"2023-03-20T00:00:00Z","dateModified":"2023-03-20T00:00:00Z","author":{"@type":"Person","name":"Kean Teng Blog"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2023/2023-03-20-computer-vision/"},"publisher":{"@type":"Organization","name":"The Financial Engineer","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="The Financial Engineer (Alt + H)">The Financial Engineer</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Computer Vision</h1><div class=post-description>My Kaggle Learning Note 5</div><div class=post-meta><span title='2023-03-20 00:00:00 +0000 UTC'>tháng 3 20, 2023</span>&nbsp;·&nbsp;8 phút&nbsp;·&nbsp;Kean Teng Blog</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Mục lục</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-convolutional-classifier>1. Convolutional Classifier</a></li><li><a href=#2-features-extraction>2. Features Extraction</a><ul><li><a href=#21-convolution-and-relu>2.1 Convolution and ReLU</a></li><li><a href=#22-maximum-pooling>2.2 Maximum Pooling</a></li></ul></li><li><a href=#3-sliding-window>3. Sliding Window</a></li><li><a href=#4-custom-covnet>4. Custom Covnet</a></li><li><a href=#5-data-augmentation>5. Data Augmentation</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p><em>Disclaimer: This article is my learning note from the courses I took from Kaggle.</em></p></blockquote><p>Computer vision literally means computer able to see and recognize stuff. Applications such as Google Lens and Google Image Search are some good examples of where computer vision is being used in our daily life.</p><p>In this course, we will explore some technique used to empower computer with the power of seeing:</p><ul><li>Building an image classifier with Keras</li><li>Concepts of visual feature extraction</li><li>Custom <code>covnet</code></li><li>Apply data augmentation to extend dataset.</li></ul><h2 id=1-convolutional-classifier>1. Convolutional Classifier<a hidden class=anchor aria-hidden=true href=#1-convolutional-classifier>#</a></h2><p>Convolutional neural networks or “<code>covnet</code>” is a neural network specializes in computer vision. A <code>covnet</code> used for image classification has two parts: a convolutional base and a dense head. The base is used to extract the features of an image while the head is used to determine the class of the image. So, the aims of training a neural network are simply to know which feature to extract from a particular image and to know which class the image will belong from the features.</p><p>Here is how we can train a covnet on Python to recognize a car and a truck:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># 1. load pretrained base</span>
</span></span><span style=display:flex><span>pretrained_base <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>load_model(
</span></span><span style=display:flex><span>    <span style=color:#75715e># file path</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;../input/cv-course-models/cv-course-models/vgg16-pretrained-base&#39;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>pretrained_base<span style=color:#f92672>.</span>trainable <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. attach classfier head</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>  pretrained_base,
</span></span><span style=display:flex><span>  layers<span style=color:#f92672>.</span>Flatten(), <span style=color:#75715e># transform 2d output to 1d</span>
</span></span><span style=display:flex><span>  layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>6</span>, activation <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>  layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>1</span>, activation <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;sigmoid&#39;</span>), <span style=color:#75715e># transform output to class probability (truck)</span>
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. model fitting</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(
</span></span><span style=display:flex><span>  optimizer <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;adam&#39;</span>,
</span></span><span style=display:flex><span>  loss <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>  metrics <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;binary_accurary&#39;</span>],
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>  ds_train,
</span></span><span style=display:flex><span>  validation_data <span style=color:#f92672>=</span> ds_valid,
</span></span><span style=display:flex><span>  epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>30</span>,
</span></span><span style=display:flex><span>  verbose <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 4. visualize model loss</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_frame <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(history<span style=color:#f92672>.</span>history)
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;loss&#39;</span>, <span style=color:#e6db74>&#39;val_loss&#39;</span>]]<span style=color:#f92672>.</span>plot()
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;binary_accurary&#39;</span>, <span style=color:#e6db74>&#39;val_binary_accurary&#39;</span>]]<span style=color:#f92672>.</span>plot();
</span></span></code></pre></td></tr></table></div></div><h2 id=2-features-extraction>2. Features Extraction<a hidden class=anchor aria-hidden=true href=#2-features-extraction>#</a></h2><h3 id=21-convolution-and-relu>2.1 Convolution and ReLU<a hidden class=anchor aria-hidden=true href=#21-convolution-and-relu>#</a></h3><p>The process of feature extraction does three things. It filters an image for a certain feature; it detects the feature within the filtered image, and it condenses the image to enhance the features.</p><p>In training, the covnet will learn weights from image features and the weights are contained in the convolutional layers. The weights are known as <strong>kernels</strong> which can be presented as an array of number. A kernel will scan over an image and produce a weighted sum of pixel values (finding the best kernel values) — emphasizing and de-emphasizing certain image patterns and information.</p><p>Activations in the network is called feature maps. Feature maps is the result when filter is applied to image — it contains features a kernel extract.</p><p>After filtering, the feature maps will be passed to an activation function which can be though as scoring pixel values according to some measure of importance. For example, ReLU activation assumes negative values are not important, so they are set to zero. In fact, these images are how the head of a network is able to solve the classification problem — looking for a particular characteristic of images that we want to classify.</p><p>Here’s how to can perform feature extraction in Python:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># define kernel</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span>kernel <span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>constant([
</span></span><span style=display:flex><span>    [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>    [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>8</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>    [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span>show_kernel(kernel)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># applying kernel</span>
</span></span><span style=display:flex><span>image_filter <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>conv2d(
</span></span><span style=display:flex><span>  input <span style=color:#f92672>=</span> image,
</span></span><span style=display:flex><span>  fitlers <span style=color:#f92672>=</span> kernel, 
</span></span><span style=display:flex><span>  strides <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, <span style=color:#75715e># section 3</span>
</span></span><span style=display:flex><span>  padding <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;SAME&#39;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(tf<span style=color:#f92672>.</span>squeeze(image_filter))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># applying activation function</span>
</span></span><span style=display:flex><span>image_detect <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>relu(image_filter)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(tf<span style=color:#f92672>.</span>squeeze(image_filter))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>axis(<span style=color:#e6db74>&#39;off&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show();
</span></span></code></pre></td></tr></table></div></div><h3 id=22-maximum-pooling>2.2 Maximum Pooling<a hidden class=anchor aria-hidden=true href=#22-maximum-pooling>#</a></h3><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>), <span style=color:#75715e># activation is None</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>MaxPool2D(pool_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># More layers follow</span>
</span></span><span style=display:flex><span>])
</span></span></code></pre></td></tr></table></div></div><p>Notice that after the Conv2D layer, we will apply a MaxPool2D layer for the condensation step. This layer will not contain any trainable weights as of the previous layer, but it will condense the feature maps to only retain important feature. This is what maximum pooling does. It takes patches of activations in the original feature maps and replaces them with maximum activation in those patches. The pooling steps will increase the proportions of active pixels to zero pixels — intensifying the feature after ReLU activation.</p><p>Is zero pixels <strong>unimportant</strong>? In fact, zero pixels carries positional information and MaxPool2D function will remove them (positional information of the feature maps) and this will lead to a property in covnet known as translation invariance.</p><p>This means that a covnet with maximum pooling tend to not distinguish features by their location in image. Notice from the first row of images below, after repeated pooling, the positional information is destroyed and no longer distinguishable. But pooling only causes translation invariance in network over small distance. The second row of the image features two dots far apart and this feature remains distinct after repeated pooling.</p><p>In fact, such invariance is good for an image classifier as it reduces data for training since we do not need to teach the network differences in perspective and framing when same features are positioned on different part of an original image.</p><h2 id=3-sliding-window>3. Sliding Window<a hidden class=anchor aria-hidden=true href=#3-sliding-window>#</a></h2><p>Both convolution and pooling steps are performed over a sliding window with parameters “kernel_size” for convolution and “pool_size” for pooling.</p><p>Notice in section 2.1, when we perform pooling, there are two extra parameters: <code>strides</code> and <code>padding</code>. <code>strides</code> means how far the window will move each step and padding describes how the pixels at the edge are being handle.</p><p>Considering the sliding window process, is it necessary to always stay within the boundary? In fact, there is a trade-off between staying within and out of bound by changing the parameter <code>padding</code> in our code:</p><ul><li><code>padding = ‘valid’</code>: Convolution window stay entirely inside input. Output will shrink. It will shrink more for larger kernels. This will limit the number of layers contained in a network, notably small size input.</li><li><code>padding = ‘same’</code>: Pad the input with 0’s around the border to make size of output and input the same. However, this will dilute the influence of pixels at the borders.</li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>,
</span></span><span style=display:flex><span>                  kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>                  strides<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                  padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;same&#39;</span>,
</span></span><span style=display:flex><span>                  activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>MaxPool2D(pool_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>                     strides<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                     padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># More layers follow</span>
</span></span><span style=display:flex><span>])
</span></span></code></pre></td></tr></table></div></div><p>Example for visualization:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>show_extraction(
</span></span><span style=display:flex><span>    image, kernel,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Window parameters</span>
</span></span><span style=display:flex><span>    conv_stride<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>    pool_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>    pool_stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    subplot_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>    figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>6</span>),    
</span></span><span style=display:flex><span>)
</span></span></code></pre></td></tr></table></div></div><p>Since the circle is just 1 pixel wide, using <code>stride = 3</code> is too coarse to produce a decent feature maps. We should then reduce the number of strides for a better feature map.</p><h2 id=4-custom-covnet>4. Custom Covnet<a hidden class=anchor aria-hidden=true href=#4-custom-covnet>#</a></h2><p>Through feature extraction, we learned how to extract simple features from an image through filter, detect and pooling. By repeating the extraction process, we can extract more complex and refined features as the process travel deeper into the network.</p><p>This can be done through convolution blocks with stacks of Conv2D and MaxPool2D layers as below:</p><p>Here’s how we can design a <code>covnet</code> that can extract complex features:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># 1. define model</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># First Convolutional Block</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>, padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;same&#39;</span>,
</span></span><span style=display:flex><span>                  input_shape<span style=color:#f92672>=</span>[<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>3</span>]),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>MaxPool2D(),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Second Convolutional Block</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>, padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;same&#39;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>MaxPool2D(),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Third Convolutional Block</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>, padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;same&#39;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>MaxPool2D(),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Classifier Head</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(units<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(units<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sigmoid&#34;</span>),
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>summary()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. model training</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>Adam(epsilon<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>),
</span></span><span style=display:flex><span>    loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>    metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;binary_accuracy&#39;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>    ds_train,
</span></span><span style=display:flex><span>    validation_data<span style=color:#f92672>=</span>ds_valid,
</span></span><span style=display:flex><span>    epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>40</span>,
</span></span><span style=display:flex><span>    verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. model loss evaluation</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_frame <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(history<span style=color:#f92672>.</span>history)
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;loss&#39;</span>, <span style=color:#e6db74>&#39;val_loss&#39;</span>]]<span style=color:#f92672>.</span>plot()
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;binary_accuracy&#39;</span>, <span style=color:#e6db74>&#39;val_binary_accuracy&#39;</span>]]<span style=color:#f92672>.</span>plot();
</span></span></code></pre></td></tr></table></div></div><h2 id=5-data-augmentation>5. Data Augmentation<a hidden class=anchor aria-hidden=true href=#5-data-augmentation>#</a></h2><p>More data will generally help a model performs better — to better differentiate image. In this section, we will learn to augment our data by applying transformation to our datasets such as rotation, flipping, warping and changing of contrast and color tone. Here’s how to perform data augmentation in Python:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e># 1. define model - with augmentation</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pretrained_base <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>load_model(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;../input/cv-course-models/cv-course-models/vgg16-pretrained-base&#39;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>pretrained_base<span style=color:#f92672>.</span>trainable <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>    <span style=color:#75715e># Preprocessing</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>RandomFlip(<span style=color:#e6db74>&#39;horizontal&#39;</span>), <span style=color:#75715e># flip left-to-right</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>RandomContrast(<span style=color:#ae81ff>0.5</span>), <span style=color:#75715e># contrast change by up to 50%</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Base</span>
</span></span><span style=display:flex><span>    pretrained_base,
</span></span><span style=display:flex><span>    <span style=color:#75715e># Head</span>
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>6</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>1</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sigmoid&#39;</span>),
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. model training</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>,
</span></span><span style=display:flex><span>    loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>    metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;binary_accuracy&#39;</span>],
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>    ds_train,
</span></span><span style=display:flex><span>    validation_data<span style=color:#f92672>=</span>ds_valid,
</span></span><span style=display:flex><span>    epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>,
</span></span><span style=display:flex><span>    verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. model loss evaluation</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_frame <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(history<span style=color:#f92672>.</span>history)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;loss&#39;</span>, <span style=color:#e6db74>&#39;val_loss&#39;</span>]]<span style=color:#f92672>.</span>plot()
</span></span><span style=display:flex><span>history_frame<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#39;binary_accuracy&#39;</span>, <span style=color:#e6db74>&#39;val_binary_accuracy&#39;</span>]]<span style=color:#f92672>.</span>plot();
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/python/>Python</a></li><li><a href=http://localhost:1313/tags/computer-vision/>Computer Vision</a></li><li><a href=http://localhost:1313/tags/image-classification/>Image Classification</a></li><li><a href=http://localhost:1313/tags/kaggle/>Kaggle</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/2023/2023-04-09-creating-a-website-with-hugo--papermode/><span class=title>« Bài mới hơn</span><br><span>Creating a Website With Hugo & PaperMode</span>
</a><a class=next href=http://localhost:1313/posts/2023/2023-03-15-intro-to-sql/><span class=title>Bài cũ hơn »</span><br><span>Intro to SQL</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on x" href="https://x.com/intent/tweet/?text=Computer%20Vision&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f&amp;hashtags=Python%2cComputerVision%2cImageClassification%2cKaggle"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f&amp;title=Computer%20Vision&amp;summary=Computer%20Vision&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f&title=Computer%20Vision"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on whatsapp" href="https://api.whatsapp.com/send?text=Computer%20Vision%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on telegram" href="https://telegram.me/share/url?text=Computer%20Vision&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Computer Vision on ycombinator" href="https://news.ycombinator.com/submitlink?t=Computer%20Vision&u=http%3a%2f%2flocalhost%3a1313%2fposts%2f2023%2f2023-03-20-computer-vision%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>The Financial Engineer</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Sao chép";function s(){t.innerHTML="Đã sao chép!",setTimeout(()=>{t.innerHTML="Sao chép"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>