[{"content":"Đây là bài viết đầu tiên trong chuỗi series “LLM, AI agent, kinh tế học và đầu tư” của miquant. Chuỗi bài này mong muốn cung cấp cho nhà đầu tư, nhà phân tích và người dùng một góc nhìn tổng quan về mô hình ngôn ngữ lớn (LLM), trí tuệ nhân tạo (AI) và cách các công cụ này đang thay đổi thế giới nói chung và cách chúng ta đầu tư nói riêng.\nSự tổng hợp của Trí tuệ Trong câu chuyện về sự tiến hóa của công nghệ, có những khoảnh khắc đặc biệt khi ranh giới giữa tưởng tượng và thực tế trở nên mờ nhạt. Trí tuệ nhân tạo là một câu chuyện như vậy - một hành trình từ ý tưởng táo bạo trở thành hiện thực đang định hình lại thế giới của chúng ta. Giống như cách ánh sáng điện đã thắp sáng bóng tối, hay Internet đã kết nối nhân loại, AI đang viết nên chương mới trong câu chuyện tiến hóa của công nghệ. Từ những giấc mơ về máy móc thông minh, chúng ta đã chứng kiến sự xuất hiện của những người bạn số có thể hiểu, giao tiếp và sáng tạo theo cách tưởng chừng chỉ có trên phim.\nKhông giống như các cuộc cách mạng công nghệ trước đây thường tập trung vào việc tăng cường sức mạnh thể chất, AI đang khuếch đại chính khả năng trí tuệ - thứ làm nên bản chất con người. Đây không đơn thuần là một công cụ mới, mà là một người cộng sự mới trong hành trình khám phá và sáng tạo của nhân loại.\nTrí tuệ nhân tạo AI, định nghĩa chung Dưới góc nhìn của miquant, AI được mô tả như sau:\nAI (trí tuệ nhân tạo) là tập hợp các thuật toán có khả năng lý luận (reason), học hỏi (learn) và hành động (act) theo cách mà thông thường đòi hỏi trí thông minh của con người. Điểm khác biệt lớn nhất giữa AI và con người nằm ở cường độ và tốc độ xử lý thông tin—AI có thể tiếp nhận và phân tích dữ liệu với quy mô vượt xa khả năng của con người. Trong một hệ thống AI, yếu tố cốt lõi tạo nên sự khác biệt chính là dữ liệu mà nó được “dạy”. Tương tự con người, khả năng lý luận, học hỏi và hành động ở AI cũng hình thành từ quá trình tích lũy kinh nghiệm, kiến thức và trải nghiệm. Khi gặp một vấn đề mới, con người thường tìm kiếm các trường hợp tương tự (tối ưu hóa xác suất) và áp dụng những giải pháp đã có.\nĐiều thú vị là AI cũng được xây dựng và tối ưu dựa trên nguyên lý tương tự. Từ bắt đầu, các thuật toán AI đã được thiết kế để tìm ra mối quan hệ giữa các sự vật hiện tượng thông qua phương thức pattern-matching (tìm kiếm điểm tương đồng). Bằng cách quan sát và học từ rất nhiều ví dụ, khi gặp một tình huống gần giống, AI sẽ đưa ra dự đoán có xác suất tương đồng cao nhất. Con người cũng hoạt động theo cách này—trước khi đến tuổi đi học, chúng ta học ngôn ngữ mẹ đẻ thông qua vô vàn ví dụ từ cha mẹ, được lặp đi lặp lại hằng ngày. Hoặc khi học một môn thể thao, chúng ta phải tập thử nhiều lần để dần đoán được hướng đi của quả bóng khi đá mạnh hay nhẹ.\nTrong vòng 5 năm trở lại đây, AI đã có một bước tiến vượt bậc—đến mức được xem như cột mốc lịch sử. Cũng như con người khác biệt với động vật ở khả năng hiểu và sử dụng ngôn ngữ, các nhà khoa học đã nhận ra tầm quan trọng của ngôn ngữ trong AI. Họ thành công xây dựng các mô hình ngôn ngữ lớn (Large Language Model—LLM) dựa trên cơ chế tương tự, coi đó như một phương thức giao tiếp chung giữa người với máy, giữa máy với máy, và giữa nhiều lĩnh vực khác nhau.\nCode là ngôn ngữ của máy tính, protein và phân tử là ngôn ngữ của tế bào. Giờ đây, các mô hình ngôn ngữ lớn (LLM) trở thành cây cầu nối giúp kết hợp khả năng suy luận và kiến thức, tạo nên một nền tảng chung vững chắc.\nPhần tiếp theo của bài viết sẽ đào sâu vào chủ đề LLM và giải thích tại sao nó đã và đang thay đổi cách con người làm việc.\nAI trong thập niên 2010 Trong thập niên 2010, trí tuệ nhân tạo (AI) chủ yếu được phát triển với mục tiêu giải quyết các nhiệm vụ cụ thể, như một loạt các “chuyên gia” nhỏ trong mỗi lĩnh vực. Các hệ thống AI thời đó được thiết kế để thực hiện những tác vụ định sẵn với hiệu suất cao, thay vì cố gắng hiểu và xử lý mọi vấn đề một cách tổng quát.\nVí dụ, trong lĩnh vực xử lý ngôn ngữ tự nhiên, các mô hình như máy dịch tự động hay phân tích cảm xúc (sentiment analysis) được tạo ra riêng biệt dành cho một ngôn ngữ xác định trước. Các hệ thống này được tạo ra với một múc đích xác định và cố gắng tối ưu duy nhất bài toán đó.\nHay trong tài chính, các mô hình AI như dự đoán giá cổ phiếu, giá commodity hay tối ưu hoá danh mục được thiết kế riêng nhằm tối ưu hoá bài toán cụ thể này.\nTrong thập kỷ này, sự thành công của AI nằm ở phương pháp học có giám sát (supervised learning) thông qua mô hình các học sâu (Deep learning) mà nền tảng của chúng là các mạng neural.\nVới học có giám sát, ở từng bài toán cụ thể, nhà phát triển (Developer) sẽ gán nhãn (label) các ví dụ để biểu diễn các hành vi mà họ muốn mô hình AI học và huấn luyện dựa trên các ví dụ đó. Sau khi được huấn luyện, các mô hình AI này có thể được áp dụng vào dữ liệu mới. Ví dụ, để đào tạo mô hình phát hiện gian lận, các giao dịch sẽ được gán nhãn (target) là \u0026ldquo;lừa đảo\u0026rdquo; hoặc \u0026ldquo;không lừa đảo\u0026rdquo; cùng với các đặc điểm của từng giao dịch (features). Sau khi mô hình học được từ các đặc điểm này (như địa điểm gửi tiền, số tiền, tốc độ, cường độ\u0026hellip;) và các nhãn tương ứng, nó có thể dự đoán liệu một giao dịch mới có phải là lừa đảo hay không chỉ dựa trên các đặc điểm tương tự.\nKhoảnh khắc ChatGPT (ChatGPT moment) Vào ngày 30/11/2022, ChatGPT, một mô hình ngôn ngữ lớn đột phá từ OpenAI ra mắt, đánh dấu một cột mốc quan trọng trong lịch sử công nghệ. Không phải là một phép màu, ChatGPT là kết quả tổng hợp của nhiều thập kỷ nghiên cứu từ những năm 1950.\nTổng quát mà nói, mô hình ngôn ngữ (language model) hoạt động theo nguyên tắc đơn giản: chúng mã hóa ngôn ngữ thành các thông tin mang tính thống kê để ước tính xác suất xuất hiện của một từ trong một ngữ cảnh nhất định. Điều này giúp mô hình dự đoán và tạo ra văn bản một cách tự nhiên, phù hợp với ngữ cảnh. Ví dụ, với ngữ cảnh \u0026ldquo;Yếu tố quan trọng nhất ảnh hưởng đến thị trường tài chính là __\u0026rdquo;, một mô hình ngôn ngữ sẽ dự đoán xác suất xuất hiện của chữ \u0026ldquo;kì vọng\u0026rdquo; sẽ cao hơn nhiều so với chữ \u0026ldquo;thời tiết\u0026rdquo;.\nDưới góc nhìn của thuật toán, khác với con người, thay vì nhìn một câu dài với nhiều kí tự, chúng sẽ sử dụng “token”. Một token có thể là một từ, một phần của từ hoặc thậm chí là các ký tự đơn lẻ, ví dụ chữ “nhắc” là 2 token là “nh” và “ắc” được biểu diễn bằng 2 token 5380 và 35708; trong khi chữ “đẹp” được biểu diễn bằng 1 token 75134. Với phương pháp trên, một câu sẽ được biểu diễn bằng nhiều token khác nhau.\nTiếng Việt:\nThông qua dataset trên hugging face, team miquant nhận thấy rằng, sau khi chuyển sang token (GPT-4o), một câu tiếng Việt ở dạng token sẽ dài hơn trung bình 35% so với câu nguyên bản. Tức 100 chữ tiếng Việt sẽ xấp xỉ 135 token.\nDựa trên các token này, một mô hình ngôn ngữ sẽ cố gắng dự đoán lần lượt các token tiếp theo có xác suất xuất hiện cao nhất dựa trên các token trước đó. Các mô hình này liên tục dự đoán lần lượt từng token cho đến khi hoàn thành câu. Quy trình này hoạt động dựa trên xác suất và không đảm bảo luôn luôn chính xác. Tuy nhiên, nhờ vào cơ chế này, LLM lại có một sức mạnh to lớn so với rất nhiều mô hình AI khác.\nVới mọi yêu cầu bạn đặt ra (prompt), các mô hình LLM này luôn cố gắng hoàn thành nó, vì thế được gọi là tác vụ hoàn thành (completion tasks). Rất nhiều vấn đề của chúng ta có thể được diễn giải thành các tác vụ phải hoàn thành. Các bài toán như phiên dịch, lập trình, phân tích dữ liệu, hay giải toán hay phân tích cơ bản, doanh thu đều có thể được thiết kế dưới dạng các tác vụ hoàn thành thông qua cách bạn thiết kế câu prompt. Từ đó, các mô hình ngôn ngữ sẽ cố gắng đưa ra câu trả lời có xác suất cao nhất dựa trên tất cả thông tin bạn cung cấp.\nVí dụ cụ thể\nCâu hỏi: Dựa trên bài báo được cung cấp, hãy phân tích cảm xúc (Sentiment) của bài báo này.\n\u0026lt;Tiêu đề\u0026gt;\nQuốc Hội đề xuất ….\n\u0026lt;Nội dung\u0026gt;\nNgày 28/12 vừa qua \u0026hellip;\nTrả lời: Tích cực!\nMô hình ngôn ngữ sẽ cố gắng xác định bài báo với nội dung này có cảm xúc là tích cực, tiêu cực hay trung tính. Từ đó, mô hình ngôn ngữ đã trở thành một mô hình phân loại cảm xúc cho tin tức thông qua quá trình tối ưu hoá xác suất.\nAI trong tài chính Như đã bàn luận kĩ ở trên, bản thân các mô hình ngôn ngữ có sức mạnh rất lớn, nhờ vào khả năng hoàn thành các yêu cầu được giao. Tuy nhiên, cần nhấn mạnh rằng quy trình này là một quy trình dự đoán dựa trên xác suất, nên không đảm bảo luôn luôn chính xác. Mặc dù vậy, nhờ khả năng này, rất nhiều tác vụ trước đây tốn nhiều nhân lực, nguồn lực và thời gian đã trở nên đơn giản hơn, hiệu quả hơn và còn có độ chính xác cao hơn rất nhiều.\nLấy một ví dụ cụ thể, tại miquant, trong các nghiên cứu đã thực hiện, việc tạo ra một mô hình phân tích cảm xúc cho các thông tin báo chí Việt Nam đòi hỏi một lượng dữ liệu có cấu trúc (structured data) rất lớn. Miquant từng xây dựng bộ dữ liệu với 20.000 điểm mẫu phân loại thông tin tích cực, tiêu cực hay trung tính. Không chỉ vậy, việc huấn luyện một mô hình nhận diện cảm xúc còn đòi hỏi rất nhiều thời gian để huấn luyện, kiểm tra và triển khai. Tuy nhiên, kể từ khi LLM xuất hiện, miquant đã tối ưu hóa đáng kể cho bài toán phân tích cảm xúc. Thay vì 20.000 điểm mẫu, miquant chỉ cần sử dụng chưa đến 200 mẫu, đồng thời thời gian triển khai được rút ngắn xuống còn vài giây để xử lý các bài báo khác nhau—với độ chính xác thậm chí còn cao hơn trước. Một kết quả mà ngay cả đội ngũ miquant cũng không ngờ tới!\nNgoài ra, các mô hình LLM cũng đã được thử nghiệm cho quá trình thu thập dữ liệu, backtest các chiến lược đầu tư, tối ưu hoá danh mục, hay gần hơn, các mô hình về AI agent nhằm tăng độ chính xác cho các bài toán phức tạp hơn.\nSong, miquant tin rằng, sức mạnh lớn nhất của các mô hình LLM chính là tự động hoá khâu phân tính định tính (qualitative analysis) hơn là cho các phân tích về định lượng (quantitative analysis) trong đầu tư. Dựa trên cơ chế khác hẳn các mô hình AI truyền thống, LLM có thể hiểu ngôn ngữ (understanding) , suy luận (reasoning) và đưa ra một kết luận hay khuyến nghị (acting). Chính nhờ các yếu tố này, khâu phân tính về định tính mà chỉ con người mới có thể làm được, giờ đây đã được tự động hoá.\n(https://arxiv.org/pdf/2405.05345v1)\nPhân tích định tính truyền thống trong đầu tư tài chính thường đòi hỏi chuyên gia xử lý và nghiên cứu hàng trăm báo cáo tài chính, tin tức, và tài liệu khác để đánh giá các yếu tố không thể lượng hóa như chiến lược công ty, năng lực ban lãnh đạo, các xu hướng thị trường và cảm xúc của nhà đầu tư. Với sự xuất hiện của các mô hình LLM, phân tích định tính không chỉ được tự động hoá mà còn nâng cao đáng kể theo nhiều cách:\nPhân tích báo cáo tài chính toàn diện: LLM có thể nhanh chóng đọc và tóm tắt các báo cáo tài chính dài, xác định các điểm mạnh, điểm yếu, cơ hội và thách thức mà công ty đang đối mặt. Các mô hình này có thể đạt độ chính xác tương đương với phương pháp tuyền thống như các analyst trên thị trường. Điều đặc biệt ở đây chính là tốc độ và độ bao phủ (cover) khắp các mã trên thị trường. Đánh giá điểm nhìn chung (consensus) thị trường: LLM có thể phân tích hàng nghìn bài báo, bình luận trên mạng xã hội và diễn đàn đầu tư để đánh giá cảm xúc thị trường đối với một cổ phiếu hoặc ngành cụ thể. Điều này giúp nhà đầu tư hiểu được phần \u0026ldquo;tâm lý\u0026rdquo; của thị trường, một yếu tố quan trọng trong việc định giá tài sản. Mặc dù vậy, cần lưu ý rằng LLM không phải là giải pháp tuyệt đối. Các mô hình này vẫn có thể gặp phải vấn đề như \u0026ldquo;ảo giác\u0026rdquo; (hallucination), khi chúng tạo ra thông tin không chính xác hoặc không tồn tại, điều này chính là một điểm yếu lớn vì bản thân cơ chế của LLM là dự đoán dựa trên xác suất. Do đó, vai trò của con người vẫn rất quan trọng trong việc xác minh, đánh giá và đưa ra quyết định cuối cùng dựa trên những phân tích này.\nĐể sử dụng được các mô hình LLM hiệu quả, điều quan trọng nhất là không được lệ thuộc vào nó. Như mọi giai đoạn phát triển của lịch sử khác, công nghệ đến rồi đi. Tất cả công nghệ cũng chỉ là công cụ nhằm hỗ trợ cho con người thực hiện được các tác vụ của họ với tốc độ nhanh nhất, xử lý được nhiều tác vụ nhất và độ chính xác là cao nhất.\nKết luận Trong thời đại của sự bùng nổ công nghệ AI, các mô hình ngôn ngữ lớn (LLM) và AI agent đang dần định hình lại cách thức hoạt động của ngành tài chính và đầu tư. Những công cụ này không chỉ đơn thuần là phương tiện tự động hóa các tác vụ lặp đi lặp lại, mà còn mở ra một kỷ nguyên mới trong phân tích tài chính—nơi phân tích định tính được thực hiện với tốc độ, quy mô và độ chính xác chưa từng có.\nTại miquant, chúng tôi tin rằng tương lai của đầu tư tài chính sẽ là sự kết hợp hài hòa giữa sức mạnh của AI và kinh nghiệm của con người. LLM và AI agent sẽ tiếp tục phát triển, trở thành những công cụ không thể thiếu cho các nhà đầu tư hiện đại, giúp họ đưa ra quyết định sáng suốt hơn trong một thị trường ngày càng phức tạp và biến động.\nTuy nhiên, đừng quên rằng, dù công nghệ có tiên tiến đến đâu, trí tuệ, kinh nghiệm và khả năng phán đoán của con người vẫn là yếu tố quyết định cuối cùng trong hành trình đầu tư thành công. Những công cụ AI chỉ thực sự phát huy giá trị khi được sử dụng như một phần bổ sung cho kiến thức và kỹ năng của nhà đầu tư, chứ không phải thay thế hoàn toàn vai trò của họ.\nTrong các bài viết tiếp theo của chuỗi series này, chúng tôi sẽ đi sâu hơn vào những ứng dụng cụ thể của LLM và AI agent trong đầu tư, chia sẻ những nghiên cứu và kinh nghiệm thực tế từ miquant, đồng thời mang đến những góc nhìn mới về tương lai của ngành tài chính trong kỷ nguyên trí tuệ nhân tạo.\n","permalink":"http://localhost:1313/posts/2025/2025-03-03-llm-concept-and-application/","summary":"Miquant khám phá cơ chế của các mô hình ngôn ngữ lớn (LLM) và tác động của AI trong đầu tư, nhấn mạnh khả năng tự động hóa phân tích định tính, cải thiện hiệu suất và độ chính xác trong các tác vụ tài chính, đồng thời khẳng định vai trò quan trọng của con người trong quá trình ra quyết định.","title":"AI - Người làm việc không ngừng nghỉ"},{"content":" Bài viết này thử nghiệm tối ưu hoá danh mục sử dụng Large Language Model (LLM). Thư viện langchain và OpenAI gpt4o và 4o-mini sẽ được sử dụng cho thử nghiệm.\nConcept Tối ưu hoá danh mục Tối ưu hóa danh mục đầu tư là quá trình phân bổ tài sản vào các khoản đầu tư khác nhau nhằm đạt được sự cân bằng tối ưu giữa lợi nhuận kỳ vọng và rủi ro. Các phương pháp tối ưu hóa truyền thống, như Modern Portfolio Theory hay Mean-variance optimization, chủ yếu dựa vào dữ liệu lịch sử và các giả định về phân phối lợi nhuận. Tuy nhiên, chúng có một số hạn chế:\nKhó khăn trong việc tích hợp các yếu tố định tính: Các phương pháp này thường không xem xét các yếu tố định tính như tin tức thị trường, sự kiện kinh tế hoặc quan điểm của chuyên gia, tiềm năng từ câu chuyện kinh doanh dẫn đến việc thiếu linh hoạt trong phản ứng với các biến động thị trường. Giả định đơn giản hóa: Việc giả định rằng lợi nhuận tuân theo phân phối chuẩn và mối quan hệ giữa các tài sản là tuyến tính có thể không phản ánh chính xác thực tế phức tạp của thị trường. LLM là gì? Mô hình ngôn ngữ lớn (LLM) là các mô hình học sâu được huấn luyện trên khối lượng dữ liệu văn bản khổng lồ, giúp chúng có khả năng hiểu và tạo ra ngôn ngữ tự nhiên. Với khả năng đọc hiểu ngôn ngữ này, LLM có thể trích xuất thông tin và phân tích dữ liệu phi cấu trúc nhanh chóng và đơn giản hơn nhiều so với các phương pháp truyền thống. Ví dụ, LLM có thể đọc 10 bài báo gần đây và tổng hợp ra 3 luận điểm đầu tư phổ biến nhất từ các bài báo đó—một nhiệm vụ mà các phương pháp truyền thống khó thực hiện được.\nTản mạn: một cách khoa học mà nói, chúng ta có thể \u0026ldquo;hình dung\u0026rdquo; LLM như sau: LLM là một cỗ máy đưa ra kết quả dựa trên trường hợp có xác suất cao nhất. Các câu prompt đóng vai trò giới hạn phạm vi lựa chọn của LLM, từ đó tăng xác suất cho kết quả mong muốn.\nLLM cho tối ưu hoá danh mục Với khả năng phân tích và tận dụng các dữ liệu phi cấu trúc trên, LLM là một ứng cử viên sáng giá cho quá trình tối ưu hoá danh mục khi có thể tận dụng được: (1) dữ liệu có cấu trúc, thống kê lợi nhuận rủi ro; (2) dữ liệu phi cấu trúc như tiềm năng tăng trưởng công ty, …; (3) đáp ứng được các yêu cầu về mục tiêu đầu tư (objective), hay các rằng buộc đi kèm (constraints) một các nhanh chóng.\nĐể dễ dàng hình dung, chúng ta sẽ cùng nhau đi qua thử nghiệm thực tế cho 6 cổ phiếu FPT, HPG, MWG, REE, VCB và VNM!\nXây dựng danh mục đầu tư sử dụng LLM Quy trình tối ưu sẽ nhau sau\nB1: Xác định rổ cổ phiếu đầu tư B2: Thu thập thông tin: (1) Sentiment của cổ phiếu; (2) Các luận điểm đầu tư - rủi ro của cổ phiếu; (3) tín hiệu kĩ thuật; (4) Độ tương quan giữa các cổ phiếu với nhau B3: Tối ưu hoá danh mục: (1) Các mục tiêu đầu tư cũng như giới hạn cho phép; (2) Xem xét danh mục quá khứ và hiệu suất quý gần nhất. B4: Backtest Thu thập tin tức từ google Tại bước đầu tiên, chúng ta cần xây dựng một pipeline để thu thập được các tin tức liên quan đến từng cổ phiếu, và phải phù hợp với thời gian của giai đoạn backtest. Tại khâu này, chúng ta sẽ sử dụng thư viện langchain để xây dựng pipeline và mô hình gpt-4o-mini để xử lý tin tức\n1 2 3 4 5 6 7 8 9 10 11 def load_google_news_before(query: str, before_date: datetime.date, num_results: int = 30): \u0026#34;\u0026#34;\u0026#34; Query Google News via LangChain’s Google Serper API Wrapper, filtering articles so that only those published before the given date are returned. \u0026#34;\u0026#34;\u0026#34; cd_min = convert_date_to_str(before_date - datetime.timedelta(days=90)) cd_max = convert_date_to_str(before_date) tbs = f\u0026#34;cdr:1,cd_min:{cd_min},cd_max:{cd_max}\u0026#34; search = GoogleSerperAPIWrapper(type=\u0026#34;news\u0026#34;, tbs=tbs, gl=\u0026#34;vn\u0026#34;,hl=\u0026#39;vi\u0026#39;,k=num_results) results = search.results(query) return results Ta có thể dễ dàng tạo ra một hàm đọc tin tức sử dụng Serper và thư viện langchain. Hàm trên thiết kế để lấy các tin tức trong vào 90 ngày trước ngày truyền vào.\nTrích xuất các thông tin mong muốn Để thu thập thông tin phục vụ đầu tư, ta tìm kiếm các bài báo với từ khóa \u0026ldquo;đầu tư vào cổ phiếu ABC\u0026rdquo;, trong đó ABC là mã cổ phiếu cần phân tích.\nSau khi có được các bài báo liên quan, ta thu thập các thông tin quan trọng bao gồm: (1) sentiment của cổ phiếu trong quý vừa qua; (2) lý giải cho kết quả sentiment đó; (3) các luận điểm đầu tư (Catalyst); (4) các yếu tố rủi ro.\nĐể thực hiện việc này, ta thiết kế câu prompt dựa trên các yêu cầu trên và sử dụng mô hình LLM gpt-4o-mini. Vì nhiệm vụ này chủ yếu là tổng hợp thông tin, không đòi hỏi nhiều suy luận phức tạp, nên việc sử dụng một mô hình nhỏ gọn, nhanh và tiết kiệm như gpt-4o-mini là lựa chọn phù hợp.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 ## Sử dụng pydantic để ép model trả về dạng dữ liệu như mong muốn class Sentiment(BaseModel): sentiment: str = Field(default=None, description=\u0026#34;The financial market sentiment of all news\u0026#34;, enum=[\u0026#34;bearish\u0026#34;, \u0026#34;bullish\u0026#34;, \u0026#34;neutral\u0026#34;]) explanation: str = Field(default=None, description=\u0026#34;The short explanation about the chosen sentiment \u0026#34;) catalyst: List[str] = Field(default=None, description=\u0026#34;The catalyst based on all news\u0026#34;) risk_factor: List[str] = Field(default=None, description=\u0026#34;The risk factor based on all news\u0026#34;) def extract_key_info(stock , date): \u0026#34;\u0026#34;\u0026#34; Extract key information from a news article. \u0026#34;\u0026#34;\u0026#34; nest_asyncio.apply() query = f\u0026#34;đầu tư cổ phiếu {stock}\u0026#34; # For example, retrieve articles published before January 1, 2025. cutoff_date = date articles = load_google_news_before(query, cutoff_date, num_results=15) links = pd.DataFrame(articles[\u0026#39;news\u0026#39;])[\u0026#39;link\u0026#39;].to_list() ## drop the link from https://etime.danviet.vn links = [link for link in links if \u0026#39;danviet.vn\u0026#39; not in link] ## skip for danviet.vn as it block the request loader = WebBaseLoader(links, continue_on_failure=True) loader.requests_per_second = 0.5 docs = loader.aload() ls = [] for doc in docs: ls.append(doc.page_content.replace(\u0026#39;\\n\\n\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;\\n\u0026#39;, \u0026#39; \u0026#39;)) llm = ChatOpenAI(model=\u0026#39;gpt-4o-mini\u0026#39;) prompt = \u0026#34;\u0026#34;\u0026#34; You\u0026#39;re a senior analyst. You are analyzing stock {stock} Your tasks are: - Analyze the sentiment of the given news - Explain the sentiment in few words - Identify the key catalysts or drivers - Identify the risk factors {document} Requirement - Be specific and concise - Do not make up information or make assumption - Do not use external source \u0026#34;\u0026#34;\u0026#34;.format(stock = stock,document=ls) response = llm.with_structured_output(Sentiment).invoke(prompt) return response date = datetime.date(2024, 1, 1) extract_key_info(\u0026#39;HPG\u0026#39;, date) Kết quả của hàm trên sẽ như sau:\nSentiment(sentiment=\u0026lsquo;bearish\u0026rsquo;, explanation=\u0026lsquo;Sentiment is bearish due to significant losses reported by HPG and related companies, along with ongoing challenges in the steel market.\u0026rsquo;, catalyst=[\u0026lsquo;Increased production and sales in October 2023\u0026rsquo;, \u0026lsquo;Expected recovery in demand and prices for steel\u0026rsquo;, \u0026lsquo;Completion of Dung Quất 2 project may increase capacity\u0026rsquo;], risk_factor=[\u0026lsquo;High competition in the steel industry\u0026rsquo;, \u0026lsquo;Dependence on domestic market recovery\u0026rsquo;, \u0026lsquo;Fluctuations in raw material prices\u0026rsquo;])\nTối ưu hoá danh mục Khi tối ưu hoá danh mục, việc xây dựng câu prompt chi tiết và cụ thể sẽ giúp giảm thiểu lỗi và tạo ra tỷ trọng hợp lý hơn. Do độ phức tạp tại khâu này tăng cao, chúng ta cần sử dụng một mô hình LLM mạnh mẽ hơn. Bài viết chọn sử dụng gpt-4o.\nMục tiêu đầu tư: Phân bổ tỷ trọng cho các cổ phiếu có tiềm năng tăng trưởng cao, dựa trên tín hiệu kỹ thuật, sentiment và các luận điểm đầu tư.\nCác rằng buộc:\nLong-only portfolio Không sử dụng margin Hold trong 3 tháng Không cần đầu tư hết 6 cổ phiếu nhưng phải có ít nhất 4 cổ phiếu Ngoài ra, câu prompt cũng bao gồm một workflow (quy trình) để LLM có thể dựa vào đó để đưa ra quyết định phân bổ tỷ trọng\nDựa trên các luận điểm đầu tư để xác định các cổ phiếu tiềm năng Đánh giá sentiment của các cổ phiếu đã chọn Sử dụng tín hiệu kỹ thuật để xác nhận thêm tiềm năng của các cổ phiếu Cuối cùng, sử dụng dữ liệu rủi ro-lợi nhuận của 3 tháng qua để xác định các cổ phiếu được mua quá mức hoặc bị thổi phồng, tránh phân bổ quá nhiều vốn cho chúng. Tuy nhiên, nếu luận điểm đầu tư hứa hẹn, ta vẫn có thể phân bổ tiền cho cổ phiếu đó nếu tin rằng nó có tiềm năng đáng kể Chia tỷ trọng cho từng cổ phiếu dựa trên tiềm năng của các luận điểm đầu tư Phân bổ nhiều tỷ trọng hơn cho các cổ phiếu có luận điểm đầu tư khả thi và tiềm năng cao 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 prompt = \u0026#34;\u0026#34;\u0026#34; Create a portfolio with the following stocks: {stocks} Objective: - Use the technical signal, market sentiment and catalysts to assign weight to each stock for a long-only portfolio - The portfolio aim to invest in the stock with the highest potential return Constraints: - The portfolio should be well diversified - You can invest in each stock with a maximum of 0.5 of the portfolio - You do not need to invest in all stocks, but you must invest in at least 4 stocks. Only select the most promising stocks. - There is no leverage \u0026amp; short selling - The holding period is 3 months (1 quarter) - The weight should be a float number between 0 and 1 - The sum of all weights should be 1 Workflow: 1. Analyze information first. 2. Based on the catalysts, identify the stocks that are likely to perform well. 3. Assess the sentiment of the news to confirm the potential of the selected stocks. 4. Use the technical signal to further confirm the potential of the stocks. 5. Finally, use the past 3 months\u0026#39; risk-return data to identify overbought or hyped stocks to avoid allocating too much capital to them. However, if the catalyst is highly promising, you may still allocate funds to it if you believe it has significant potential. 6. Assign weights to each stock based on the potential return driven by the catalyst. 7. Allocate more weight to stocks where the catalyst is more likely to occur and has a higher magnitude. 8. Be confident in assigning higher weights to stocks with better catalysts and sentiment. 9. **Think carefully; do not simply split the weights equally.** Technical signal: simple EMA50-200 crossover, 1 for bullish, 0 for bearish {ta_signal} Past 3 risk return {risk_return} News sentiment (0 for bearish, 1 for bullish, 2 for neutral) \u0026amp; Catalysts {sentiment} Correlation between stocks {correlation} Your previous portfolio {past_portfolios} Your previous return: {last_period_return} Output - A list with weight for every stock. The weight must correspond to the oder {stocks}. For stock that not invest, simple return 0 for the weight - A detailed explanation of the rationale behind the portfolio allocation \u0026#34;\u0026#34;\u0026#34; Sau đó, ta sẽ tính toán các tham số và đưa các thông tin cần thiết vào trong mô hình để mô hình thực hiện và tính toán.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class PortfolioOptimizationResult(BaseModel): \u0026#34;\u0026#34;\u0026#34; A class to represent the result of portfolio optimization. \u0026#34;\u0026#34;\u0026#34; stock_weight: List[float] = Field( default=None, description=\u0026#34;A list containing the weight for all stocks in the portfolio.\u0026#34; ) explanation: str = Field( default=None, description=\u0026#34;A detailed explanation of the rationale behind the portfolio allocation.\u0026#34; ) def llm_optimizer(date, stocks = [\u0026#39;FPT\u0026#39;, \u0026#39;HPG\u0026#39;, \u0026#39;MWG\u0026#39;, \u0026#39;REE\u0026#39;, \u0026#39;VCB\u0026#39;, \u0026#39;VNM\u0026#39;], past_portfolios = None, last_period_return = None): results = run_in_parallel(stocks, date) llm = ChatOpenAI(model=\u0026#39;gpt-4o\u0026#39;) ta_signal = ta_compare[:date].iloc[-1] start_sample = date - datetime.timedelta(days=30*3) ## 3 months sample_rets = rets[start_sample:date] risk_return = ((1+sample_rets).product()-1).to_frame() risk_return.columns = [\u0026#39;past_3m_rets\u0026#39;] risk_return[\u0026#39;past_3m_volatility\u0026#39;] = sample_rets.std() risk_return[\u0026#39;past_3m_sharpe_ratio\u0026#39;] = sample_rets.mean()/risk_return[\u0026#39;past_3m_volatility\u0026#39;] risk_return = risk_return.round(4) correlation = sample_rets.corr().round(4) chatprompt = prompt.format(ta_signal=ta_signal, sentiment=results, risk_return=risk_return, stocks=stocks, correlation=correlation, past_portfolios=past_portfolios, last_period_return=last_period_return) optimizer = llm.with_structured_output(PortfolioOptimizationResult).invoke(chatprompt) weight = pd.DataFrame(optimizer.stock_weight, index=stocks, columns=[\u0026#39;weights\u0026#39;]) weight = weight/weight.sum() ## make sure the sum of weight is 1 retionale = optimizer.explanation return weight, retionale weight, expla = llm_optimizer(datetime.date(2024, 6, 1)) ## this takes around 35 seconds Sau khi chạy hàm trên, ta sẽ nhận được kết quả như sau (danh mục cho tháng 6.2024):\nTỷ trọng danh mục\nweights FPT 0.25 HPG 0.2 MWG 0.3 REE 0.15 VCB 0.1 VNM 0.0 Lý do cho tỷ trọng trên\nIn constructing this portfolio, we focused on stocks with strong bullish technical signals and favorable market sentiment, while considering catalysts and risks.\nFPT (Weight: 0.25): FPT has a bullish technical signal, strong sentiment driven by its partnership with NVIDIA for AI development, and projected revenue growth. Although its valuation is high, its catalysts are promising, warranting a significant allocation. HPG (Weight: 0.2): HPG also exhibits a bullish technical signal and optimistic market sentiment due to strong Q1 financial results and upcoming projects like Dung Quất 2. Despite high debt levels, its growth potential justifies a substantial allocation. MWG (Weight: 0.3): MWG has demonstrated strong past returns and a bullish sentiment, supported by strategic investments and projected growth. The high weight reflects its potential for recovery and profit, despite some risks. REE (Weight: 0.15): REE\u0026rsquo;s neutral sentiment and mixed outlook are balanced by its dividend plans and growth in renewable energy. Its lower weight reflects these uncertainties, but its diversification benefits and potential in energy justify inclusion. VCB (Weight: 0.1): Despite a neutral sentiment and recent negative returns, VCB\u0026rsquo;s catalysts such as planned capital increases and potential equity sales offer upside potential, meriting a smaller allocation. VNM (Weight: 0): VNM is excluded due to bearish sentiment and negative past performance, with significant foreign sell-offs and declining market position, making it less attractive for the portfolio. Overall, this portfolio is designed to be diversified and capitalize on stocks with strong potential returns driven by clear catalysts, while mitigating risks associated with each stock\u0026rsquo;s market position and sentiment.\nBacktest cho phương pháp trên Ta tiến hành xây dựng mô hình backtest đơn giản.\nMua danh mục vào đầu mỗi quý Bỏ qua các yếu tố như phí giao dịch, market impact 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 ## backtest the strategy - \u0026gt;=35s for 1 loop -\u0026gt; 4 years = 4*4*35s \u0026gt;= 560s ~ 9.3 minutes ## create a function that takes the weights and returns the portfolio returns def backtest_strategy(weights, returns): \u0026#34;\u0026#34;\u0026#34; Backtest the strategy \u0026#34;\u0026#34;\u0026#34; port_rets = returns @ weights port_rets.rename(columns={\u0026#39;weights\u0026#39;:\u0026#39;rets\u0026#39;}, inplace=True) return port_rets date_idx = pd.date_range(\u0026#39;2020-12-31\u0026#39;, \u0026#39;2024-12-31\u0026#39;, freq=\u0026#39;QE\u0026#39;) llm_rets = pd.DataFrame() llm_retionale = {} llm_weights = {} for date in date_idx[:-1]: i = 0 start_sample = date - pd.DateOffset(years=3) end_sample = date start_out_sample = date+ pd.DateOffset(days=1) end_out_sample = date + pd.DateOffset(months=3) ## data for the sample period sample_data = rets[start_sample:end_sample] out_sample = rets[start_out_sample:end_out_sample] # run the optimizer if i \u0026gt;=1: past_port = pd.DataFrame(llm_weights[previous_date.strftime(\u0026#34;%Y-%m-%d\u0026#34;)]) w, explanation = llm_optimizer(date, past_portfolios=past_port, last_period_return= past_return) else: w, explanation = llm_optimizer(date) llm_retionale[date.strftime(\u0026#34;%Y-%m-%d\u0026#34;)] = explanation llm_weights[date.strftime(\u0026#34;%Y-%m-%d\u0026#34;)] = w.to_dict()[\u0026#34;weights\u0026#34;] # run the backtest llm_backtest = backtest_strategy(w, out_sample) llm_rets = pd.concat([llm_rets, llm_backtest], axis=0) i+=1 previous_date = date past_return = (1+llm_backtest).product()-1 Từ đó, ta thu được kết quả sau:\nLợi nhuận danh mục từ 2021 tới nay\nThống kê liên quan\nLLM VNINDEX Lợi nhuận tích luỹ 70.9% 12.6% Lợi nhuận trung bình hàng năm 14.52% 3.04% Độ biến động trung bình hằng năm 21.66% 19.6% Sharpe ratio 0.73 0.25 Lần sụt giảm mạnh nhất 24.19% 40.34% Chiến lược sử dụng LLM cho kết quả tương đối tốt với lợi nhuận tích luỹ 70.9% so với 12.6% của vnindex qua 4 năm. Tuy nhiên, tỷ lệ sharpe thì tương đối khiêm tốn chỉ 0.73 với độ biến động 21.6%. Ngoài ra lần sụt giảm lớn nhất đạt 24.19% là một kết quả chấp nhận được trong đầu tư.\nDanh mục qua từng giai đoạn\nKết luận Bài viết đã tiến hành xây dựng tối ưu hoá danh mục sử dụng LLM. Thông qua LLM, ta có thể đưa các dữ liệu phi cấu trúc (unstructured-data) vào trong quá trình tối ưu. Đây là một điểm thú vị và các phương pháp truyền thống tận dụng các tính chất thống kê chưa đưa vào được. Tuy nhiên, phải nhấn mạnh lại rằng, tối ưu danh mục theo phương pháp này thì mang nặng yếu tố định tính (qualitative) hơn so với định lượng (quantitative).\nMột điểm thú vị này, ta có thể kết hợp 2 phương pháp này với nhau. Thông qua LLM, ta có thể tìm ra một prior belief mang tính định tính và dùng nó để bắt đầu quá trình tối ưu hoá định lượng hơn (bayesian style).\nBài viết sau sẽ tiến hành so sánh các phương pháp truyền thống với các phương pháp mới này. Để nhận file code và data đầy đủ, xin hãy để comment vào bài viết trên linkedin hoặc gửi email đến hung.ha@miquant.vn.\n","permalink":"http://localhost:1313/posts/2025/2025-02-03-llm-portfolio-optimization/","summary":"Trong kỷ nguyên mới, dữ liệu phi cấu trúc như tin tức, báo cáo phân tích, và thống kê kinh tế trở thành nguồn thông tin quan trọng trong quyết định đầu tư. Tuy nhiên, các mô hình tài chính truyền thống như Lý thuyết Danh mục Hiện đại (MPT) và Tối ưu Rủi ro-Lợi nhuận (Mean-Variance Optimization) chủ yếu dựa vào dữ liệu định lượng, bỏ qua yếu tố định tính quan trọng. Sự phát triển của Large Language Model (LLM) mang đến tiềm năng kết hợp dữ liệu định lượng và dữ liệu phi cấu trúc trong quản lý danh mục đầu tư. Bài viết này trình bày một thực nghiệm ứng dụng LLM trong quá trình tối ưu danh mục.","title":"Tối ưu hoá danh mục thông qua LLM"},{"content":" Concept AI Agent, một topic hiện đang rất hot trên thế giới về lĩnh vực AI.\nTheo fpt.ai:\nAI Agent là một hệ thống phần mềm hoặc phần cứng được thiết kế để thực hiện các nhiệm vụ một cách tự động và độc lập, nhằm đạt được những mục tiêu nhất định.\nMột AI Agent có khả năng xử lý thông tin, đưa ra quyết định và thực hiện các hành động để tương tác với các điều kiện và hệ thống liên quan. Nhân sự AI tạo sinh có thể áp dụng cho nhiều lĩnh vực, từ trợ lý ảo cho khách hàng đến hệ thống điều khiển tự động phức tạp, thậm chí là robot trong các môi trường thực tế.\nTheo IBM:\nAn artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.\nTóm gọn lại: AI agent là một hệ thống thông minh và autonomous (tự trị → tự suy nghĩ, suy luận, ra quyết định,…). Mỗi agent có thể thực hiện được các task mà người thiết kế giao. Và một điểm đặc biệt so với chatbot thông thường là người thiết kế cho thể đưa cho Agent các tools để tự sử dụng và các Agent phối hợp với nhau để hoàn thành mục tiêu cuối cùng.\nVí dụ, trong đầu tư, ngày xưa bạn có tool lấy giữ liệu từ database lên. Bạn sử dụng nó và tool trả ra output, bạn dùng output này cho vô AI. Giờ thì đã khác, bạn có thể đưa sẵn tool cho Agent, và các Agent này sẽ sử dụng chính cái tool này để thực hiện các task cần thiết, loại bỏ bạn ra trong quá trình “tự trị” của nó.\nNếu bạn chưa hiểu thì hãy tưởng tượng như sau.\nBạn là 1 financial analysis, trong quá trình phân tích, bạn sẽ luôn follow 1 số quy trình nhất định và sử dụng 1 vài tools nhất định.\nB1: lên google search cổ phiếu HPG.\nTại bước này, bạn sử dụng 1 tools là google_search\nB2: download các bài báo về, lưu xuống database, sử dụng 1 tool sentiment calculator để tính điểm các bài báo này.\nTại bước này, bạn sử dụng 1 tools là sentiment_calculator\nB3: Viết report theo 1 khung nhất định (Thân bài, mở bài, kết bài) đi kèm các tool khác như: vẽ chart correlation với thị trường, tính toán các chỉ số tài chính ,..\nTại bước này, bạn sử dụng 2 tools là report_writing và metrics_calculator.\nVà, điều thú vị ở đây là, bạn chỉ cần chuẩn hoá các tools trên như là 1 function trong python và đưa cho Agent. Các Agent đã có thể thực hiện từ bước 1 đến bước 3 mà không cần bạn can thiệp vào bước nào. Ngoài ra, thông qua cơ chế Specialization và Multi-Agent system, bạn còn tăng được độ chính xác, hiệu quả và khả năng thích ứng của hệ thống tự trị này (fpt.ai).\nVà điều thú vị hơn nữa, là làm những thứ này, rất đơn giản, thông qua kĩ thuật prompt engineering.\nXây dựng một hệ thống phân tích kĩ thuật, thông tin và tư vấn chiến lược đầu tư. Hãy cùng nhau thử nghiệm đi xây dựng một team phân tích tư vấn như một phòng trong công ty chứng khoán nhé. Lưu ý, phòng tư vấn này “tự trị” - autonomous. Việc cần làm là đưa vào 1 mã cổ phiếu (ví dụ HPG), các AI Agent sẽ tự xử lý 100%.\nPhòng tư vấn của ctck có mô hình tổ chức đơn giản nhất như sau:\n1 bạn phân tích kĩ thuật (technical analyst) 1 bạn phân tích thông tin, báo (news analyst) 1 bạn tư vấn đầu tư (investment advisor) 1 bạn xây dựng chiến lược giao dịch (strategy advisor) Cùng nhau xây phòng tư vấn nào. Trước tiên, để thực hiện các nghiệp vụ trên, ta cần các công cụ sau:\nLấy giá cổ phiếu, tính các chỉ báo kĩ thuật Lên google search và thu thập các thông tin liên quan đến cổ phiếu ta muốn 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## Mình sử dụng gpt-4o-mini là model llm bên dưới llm = ChatOpenAI(model=\u0026#34;gpt-4o-mini\u0026#34;) ## Tools def load_price_and_ta(company_stock): query = f\u0026#34;SELECT * FROM eod WHERE symbol = \u0026#39;{company_stock}\u0026#39; order by timestamp DESC LIMIT 1000\u0026#34; host = \u0026#39;xyz\u0026#39; (database link) response = requests.get( host + \u0026#39;/exec\u0026#39;, params={\u0026#39;query\u0026#39;: query}).json() df = pd.DataFrame(response[\u0026#39;dataset\u0026#39;], columns=pd.DataFrame(response[\u0026#39;columns\u0026#39;])[\u0026#39;name\u0026#39;].values) df.set_index(\u0026#39;timestamp\u0026#39;, inplace=True) df.index = pd.to_datetime(df.index).strftime(\u0026#39;%Y-%m-%d\u0026#39;) df = df.iloc[::-1] ## indicator df[\u0026#39;RSI\u0026#39;] = ta.rsi(df[\u0026#39;close\u0026#39;]) adx = ta.adx(df[\u0026#39;high\u0026#39;], df[\u0026#39;low\u0026#39;], df[\u0026#39;close\u0026#39;], 14) df[adx.columns] = adx bbands = ta.bbands(df[\u0026#39;close\u0026#39;]) df[bbands.columns] = bbands df[\u0026#39;SMA200\u0026#39;] = ta.sma(df[\u0026#39;close\u0026#39;], 200) df[\u0026#39;SMA50\u0026#39;] = ta.sma(df[\u0026#39;close\u0026#39;], 50) df[\u0026#39;SMA20\u0026#39;] = ta.sma(df[\u0026#39;close\u0026#39;], 20) macd = ta.macd(df[\u0026#39;close\u0026#39;]) df[macd.columns] = macd return df.dropna() ## Tool lấy giá và tính các indicator ta_tool = Tool( name = \u0026#34;Price and technical indicator tools for Vietnam stock\u0026#34;, description = \u0026#34;Collect stocks prices adn technical indicator for {company_stock} about a specific company in Vietnam stock market.\u0026#34;, func= lambda symbol: load_price_and_ta(symbol) ) ## Tool search web search_tool = SerperDevTool( country=\u0026#34;vn\u0026#34;,locale=\u0026#34;vn\u0026#34;,location=\u0026#34;Vietnam\u0026#34;, n_results=20, ) ## Tool scraping scrape_tool = ScrapeWebsiteTool() Sau đó, chúng ta sẽ tiến hành đi xây dựng các nhân sự.\nNhân sự AI Bài viết sử dụng framework Crewai nhằm xây dựng các agent. Để xây dựng 1 agent, ta cần các thông tin sau:\nRole: vai trò của agent này là gì? Goal: mục tiêu của agent này là gì? Backstory: câu chuyện về agent này là gì? Bạn có thể đọc thêm tại Crew.ai\nTechnical analyst 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## Chuyên viên phân tích kĩ thuật ## Phân tích TA, dự đoán giá trong 20 ngày tới technicalAnalyst = Agent( role= \u0026#34;Senior Technical Analyst\u0026#34;, goal=\u0026#34;\u0026#34;\u0026#34;Provide the most recent technical analysis about trend, momentum and stockprice prediction in short timeframe (20 days) for targeted stock\u0026#34;\u0026#34;\u0026#34;, backstory=\u0026#34;\u0026#34;\u0026#34;You\u0026#39;re the best at technical analysis, stock price trend prediction and market risk assessment. and you\u0026#39;re working for a top security firm in Vietnam.\u0026#34;\u0026#34;\u0026#34;, verbose=True, tools=[ta_tool], allow_delegation=True, llm = llm ) News analyst 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## chuyên viên phân tích thông tin ## tìm catalyst, phân tích các yếu tố rủi ro newsAnalyst = Agent( role= \u0026#34;Senior Market Analyst\u0026#34;, goal=\u0026#34;\u0026#34;\u0026#34;Provide the most recent news and market sentiment analysis that can highly affect stock price performance. Also, you must provide the top catalyst as well as risk factors that can highly affect company business performance.\u0026#34;\u0026#34;\u0026#34;, backstory= \u0026#34;\u0026#34;\u0026#34; You\u0026#39;re highly experienced in analyzing the market information and risk assessment that can affect company revenue. You are also excel in analyzing market sentiment and always skepticism and consider also the source of the news articles. \u0026#34;\u0026#34;\u0026#34;, verbose=True, tools=[search_tool,scrape_tool], allow_delegation=True, llm=llm, ) Investment advisor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## chuyên viên tư vấn đầu tư ## Phân tích dựa vào 2 nhân tố giá và thông tin để đưa ra tư vấn đầu tư investmentAdvisor = Agent( role= \u0026#34;Senior Investment Advisor\u0026#34;, goal=\u0026#34;\u0026#34;\u0026#34;Impress your customers with full analyses over stocks based on technical, and news insights and complete investment recommendations. All the information must come from the technicalAnalyst and newsAnalyst.\u0026#34;\u0026#34;\u0026#34;, backstory= \u0026#34;\u0026#34;\u0026#34; You\u0026#39;re the best at providing investment advice and risk management for the targeted stock. You\u0026#39;re also excel in risk management and always consider the risk factors that can affect the investment performance. You are now working for a super important customer you need to impress. \u0026#34;\u0026#34;\u0026#34;, verbose=True, allow_delegation=True, tools=[search_tool, scrape_tool], llm=llm, ) Strategy builder 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## chuyên viên xây dựng chiến lược ## chiến lược mua hợp lý tối ưu hoá lợi nhuận tradingAdvisor = Agent( role=\u0026#34;Trade Advisor\u0026#34;, goal=\u0026#34;\u0026#34;\u0026#34;Develop and test various trading strategies based on the technicalAnalyst and investmentAdvisor\u0026#39;s recommendation. Finally, you must provide the best trading strategy to maximize profit\u0026#34;\u0026#34;\u0026#34;, backstory=\u0026#34;This agent specializes in analyzing the timing, price, \u0026#34; \u0026#34;and logistical details of potential trades. By evaluating \u0026#34; \u0026#34;these factors, it provides well-founded suggestions for \u0026#34; \u0026#34;when and how trades should be executed to maximize \u0026#34; \u0026#34;efficiency and adherence to strategy.\u0026#34;, verbose=True, allow_delegation=True, tools = [ta_tool], llm=llm, ) Ta đã có đủ nhân sự rồi, giờ chúng ta sẽ xây dựng các “nhiệm vụ” để hoàn thành được công việc.\nQuy trình sẽ như sau:\nPhân tích giá cổ phiếu, TA Phân tích thông tin, tìm kiếm catalyst, phân tích các rủi ro có thể có Tổng hợp và đưa ra khuyến nghị Xây dựng chiến lược mua bán hợp lý Nhiệm vụ Phân tích giá cổ phiếu, TA 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## phân tích TA, kháng cự, hỗ trợ ## tìm hiểu xem cổ phiếu quá mua/bán chưa getStockPrice = Task( description= \u0026#34;\u0026#34;\u0026#34; Conduct a technical analysis of {company_stock} stock price trends and patterns, resistance and support level utilizing technical indicators that have provided. Considering whether the stock is overbought or oversold. \u0026#34;\u0026#34;\u0026#34;, expected_output = \u0026#34;\u0026#34;\u0026#34; The final report must include a detailed analysis of the stock\u0026#39;s price trends, key technical indicators, support-resistance level, and any potential buy/sell signals. Make sure to provide a clear and concise summary of the stock\u0026#39;s current technical position and any potential price targets or risk levels. Make sure to use the most recent data possible. Finally, please translate the final output to Vietnamese. \u0026#34;\u0026#34;\u0026#34;, agent= technicalAnalyst, output_file = \u0026#34;TA_analyses.md\u0026#34; ) Phân tích thông tin, tìm kiếm catalyst, phân tích các rủi ro có thể có 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## phân tích các thông tin gần nhất ## xem xét coi có sự kiện gì sắp xảy ra không ## tâm lý thị trường đang như thế nào, các analyst đang nghĩ gì get_news = Task( description= \u0026#34;\u0026#34;\u0026#34; Collect and summarize recent news articles, press releases, and market analyses related to the {company_stock} stock and its industry. Pay special attention to any significant events, market sentiments, and analysts\u0026#39; opinions. Also include upcoming events like earnings and others.\u0026#34;\u0026#34;\u0026#34;, expected_output = \u0026#34;\u0026#34;\u0026#34; A summary of the overall market and short summary. Include a sentiment score for targeted stock based on the news, notable shifts in market sentiment, and potential impacts for the stock. Make sure to use the most recent data as possible. Finally, please translate the final output to Vietnamese. \u0026#34;\u0026#34;\u0026#34;, agent= newsAnalyst, output_file = \u0026#34;news_analyses.md\u0026#34; ) Tổng hợp và đưa ra khuyến nghị 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## tổng hợp thông tin và đưa ra quyết định có nên tư vấn không writeAnalyses = Task( description = \u0026#34;\u0026#34;\u0026#34;Use the stock price analysis and the news analysis to create an report and investment advice about the {company_stock} company. Focus on the stock price trend, news and market sentiment. What are the near future considerations? Include the previous analyses of stock trend and news summary. Be straight foward and cite or provide reasons for each of your point.\u0026#34;\u0026#34;\u0026#34;, expected_output= \u0026#34;\u0026#34;\u0026#34; A research report of the {company_stock} formated as markdown in an easy readable manner. It should contain: - An overall summary - A detailed analysis of the stock price trend from the Technical Analyst - A detailed analysis of the stock news from the News Analyst - Key catalysts and risks for the stock - Price prediction for the stock in future and does it over or under value with the current price based on the catalysts and risks - A conclusion about key facts and concrete future trend prediction - up, down or sideways. Will it worth to buy or sell the stock when take into account the risk and catalysts. Finally, please translate the final output to Vietnamese. \u0026#34;\u0026#34;\u0026#34;, agent = investmentAdvisor, output_file = \u0026#34;final_report.md\u0026#34; ) Xây dựng chiến lược mua bán hợp lý 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## xây dựng chiến lược mua khi cổ phiếu quá bán ## bán khi cổ phiếu có sentiment lên quá cao tradingStrategy = Task( description= \u0026#34;\u0026#34;\u0026#34;Develop and refine trading strategies based on the insights from the technical analyst and investment advisor. The objective strategy is buy when the stock is oversold and sell when the sentiment is too high. Also, consider the risk factors that can affect the stock price based on the news analysis \u0026#34;\u0026#34;\u0026#34;, expected_output= \u0026#34;\u0026#34;\u0026#34;A set of potential trading strategies for {company_stock} that align with the objective startegy. Finally, please translate the final output to Vietnamese.\u0026#34;\u0026#34;\u0026#34;, agent=tradingAdvisor, output_file = \u0026#34;trading_strategy.md\u0026#34; ) Kết quả Mình có lưu lại kết quả ở các phase, các bạn có thể vô đọc file markdown. Ngoài ra, file Full chain of thought sẽ cho ta thấy được toàn thể quá trình vận hành của team tư vấn này ^^.\nPhân tích kĩ thuật\nPhân tích thông tin\nTư vấn đầu tư\nTư vấn chiến lược giao dịch\nFull Chain-of-thought\nMình lấy ra 1 vài mẫu mình thấy đặc biệt để cùng nhau cảm nhận (mình làm mẫu trên cổ phiếu HPG)\nTA Analyst\n5. **Tóm tắt vị thế kỹ thuật hiện tại:** - Cổ phiếu HPG hiện đang có xu hướng giảm nhưng không bị quá bán. Tuy nhiên, các chỉ số cho thấy có thể có sự phục hồi nhẹ nếu vượt qua ngưỡng kháng cự. - Cần theo dõi các mức hỗ trợ và kháng cự để đưa ra quyết định đầu tư hợp lý. 6. **Mục tiêu giá và mức rủi ro:** - **Mục tiêu giá ngắn hạn:** Nếu cổ phiếu vượt qua mức kháng cự 27.00 VNĐ, có thể hướng tới mục tiêu 28.00 VNĐ. - **Mức rủi ro:** Cần cẩn trọng nếu giá xuống dưới 26.30 VNĐ, có thể dẫn đến sự sụt giảm sâu hơn. Tóm lại, cổ phiếu HPG hiện tại đang trong giai đoạn điều chỉnh, và cần lưu ý các yếu tố kỹ thuật trước khi tham gia giao dịch. News analyst\n5. **Sự kiện sắp tới**: - HPG dự kiến sẽ công bố báo cáo lợi nhuận từ ngày 28 tháng 1 đến ngày 3 tháng 2 năm 2025. Đây sẽ là một sự kiện quan trọng, vì phản ứng của thị trường có thể bị ảnh hưởng bởi kết quả. 9. **Yếu tố kích thích và rủi ro**: - **Yếu tố kích thích hàng đầu**: - Bứt phá trên mức kháng cự 27,00 VNĐ. - Báo cáo lợi nhuận tích cực vào đầu tháng Hai. - **Yếu tố rủi ro**: - Tiếp tục giảm giá thép. - Tăng áp lực bán từ nước ngoài. Advisor\n2. **Khuyến Nghị Từ Các Nhà Phân Tích**: - Các nhà phân tích đồng thuận rằng giá cổ phiếu sẽ tăng 25.5% trong năm tới. - Các mục tiêu giá đã được điều chỉnh tăng lên nhiều lần, với mục tiêu mới nhất được đặt là ₫34,075. 3. **Cảm Nhận Thị Trường**: - Sự giảm giá gần đây của cổ phiếu đã khiến HPG được xem là không được định giá đúng, làm tăng sự quan tâm của các nhà đầu tư. ## Các Yếu Tố Thúc Đẩy - **Nhu Cầu Tăng**: Ngành xây dựng tại Việt Nam tiếp tục phát triển, thúc đẩy nhu cầu cho các sản phẩm thép. - **Tăng Trưởng Lợi Nhuận**: Dự báo tăng trưởng lợi nhuận 24.27% mỗi năm, được thúc đẩy bởi khối lượng bán hàng cao hơn và biên lợi nhuận cải thiện. - **Vị Trí Thị Trường**: HPG nắm giữ thị phần lớn trong thép xây dựng và đang ở vị trí tốt để tận dụng các xu hướng ngành. Strategy recommendation\n1. **Tín hiệu Mua**: - Khi chỉ số sức mạnh tương đối (RSI) dưới 30, cho thấy cổ phiếu bị bán quá mức. Việc cổ phiếu được phân loại là bị bán quá mức cho thấy rằng nó có thể được định giá thấp, tạo ra cơ hội mua vào tiềm năng. - Thêm vào đó, xem xét giá cổ phiếu hiện tại là ₫26,750, thấp hơn khoảng 30.7% so với giá trị hợp lý ước tính, càng củng cố thêm cho trường hợp vào lệnh khi RSI chỉ ra điều kiện đánh giá thấp. Kết luận Topic về AI Agent mình tin sẽ sắp được ứng dụng rộng rãi vào thị trường trong 5 năm tới. Việc tạo ra một agent rất dễ. Cái khó ở đây là tạo ra 1 agent đáng tin và đủ giỏi để thực hiện các việc tự động hoá suy luận cao cấp hơn.\nTại start up của mình và các ae (miquant.vn), AI Agent cũng là một trong những sản phẩm đang được chú trọng xây dựng. Thay vì chỉ sử dụng các phương pháp prompt đơn giản như này, tụi mình nâng cấp lên thông qua các công cụ phân tích định lượng cũng như các dự báo kinh tế, expertise include, … nhằm nâng cao tính “trustworthy” của các agent này.\nStay tuned.\nRef Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research ","permalink":"http://localhost:1313/posts/2024/2024-12-02-ai-agent-for-investment/","summary":"AI Agent là một hệ thống tự động và độc lập, có khả năng xử lý thông tin, ra quyết định và thực hiện các nhiệm vụ trong nhiều lĩnh vực. Bài viết mô tả cách xây dựng một đội ngũ phân tích đầu tư tự trị với các vai trò như phân tích kỹ thuật, phân tích thông tin, tư vấn đầu tư và xây dựng chiến lược giao dịch, sử dụng các công cụ để tự động hóa quy trình phân tích và ra quyết định. AI Agent có tiềm năng ứng dụng rộng rãi trong tương lai gần, tuy nhiên, việc tạo ra một agent đáng tin cậy vẫn là thách thức lớn.","title":"AI Agent: The future of Investment research"},{"content":"Giới thiệu Stochastic process là ngôn ngữ để miêu tả sự ngẫu nhiên, cũng giống như Calculus là ngôn ngữ để miêu tả sự thay đổi của hàm số.\nBài viết giới thiệu về stochastic process thông qua bài toán Gambler\u0026rsquo;s Ruin. Bài viết cũng mô phỏng chiến lược giao dịch VN30F1M như một trường hợp của Gambler\u0026rsquo;s ruin và sử dụng phương pháp Monte Carlo để xấp xỉ các giá trị cần thiết, nhấn mạnh tầm quan trọng của xác suất và kỳ vọng trong việc ra quyết định.\nConcept Gambler’s Ruin, hay Sự phá sản của con bạc, là một trong những concept cổ điển trong lý thuyết xác suất (probability theory) và quá trình ngẫu nhiên (stochastic process). Vấn đề này có thể được mô tả trong nhiều trường hợp, trong đó phổ biến nhất là:\nMột con bạc bước vào sòng bạc với số tiền $n trong tay và bắt đầu chơi một trò chơi, trong đó anh ta thắng với xác suất p và thua với xác suất $q = 1-p$. Người chơi lặp lại trò chơi này nhiều lần, đặt cược $1 mỗi lượt. Anh ta sẽ rời khỏi trò chơi nếu tổng số tiền của anh ta đạt đến $N hoặc nếu anh ta hết tiền (phá sản), tùy thuộc vào điều gì xảy ra trước. Xác suất mà con bạc bị phá sản hoặc thắng chung cuộc là bao nhiêu?\nXác suất con bạc thắng cả trận Gambler’s Ruin có thể được mô hình hoá như một bước đi ngẫu nhiên (random walk) mà ở đó chúng ta quan tâm đến xác suất người chơi sẽ thắng khi đạt được $N mong muốn. Ở bài viết này, mình sẽ sử dụng kết quả, bước giải chi tiết các bạn có thể tham khảo tại đây.\nVới $P_N(n)$ là xác suất người chơi sẽ đạt được $N với số tiền hiện tại là $n. Tương tự, $P_N(n+1)$ là xác suất người chơi sẽ đạt được $N với số tiền hiện tại là $n+1. $p$ là xác suất thắng 1 trận, $q = 1 - p$ là xác suất thua của 1 trận.\n$$ P(\\text{sucess}) = P(\\text{sucess}| \\text{win first round}) P(\\text{win first round})\\\\ + P(\\text{sucess}| \\text{lose first round}) P(\\text{lose first round}) \\\\ P_N(n) = P(n| W) P(W) + P(n| L) P(L) \\\\ P_N(n) = P_N(n+1) p + P_N(n-1) q $$Với $\\lambda = \\frac{q}{p}$, xác suất người chơi sẽ đạt được N là:\n$$ P_N(n) = \\begin{cases} \\frac{1 - \\lambda^n}{1 - \\lambda^N}, \u0026 \\lambda \\neq 1 \\\\ \\frac{n}{N}, \u0026 \\lambda = 1 \\end{cases} \\tag{1} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def win_probability(p, initial_cap, expected_cap): assert 0\u0026lt;= p \u0026lt;=1 , \u0026#34;`p` must be a probability between 0 and 1.\u0026#34; assert 0 \u0026lt;= initial_cap \u0026lt;= expected_cap, \u0026#34;`` an initial_cap integer between 0 and expected_cap.\u0026#34; very_small_number = 1e-12 lambda_ = (1-p)/p if p\u0026lt;= very_small_number: return 0 if p\u0026gt;= 1-very_small_number: return 1 if lambda_==1: return initial_cap/expected_cap return (1-lambda_**initial_cap)/(1-lambda_**expected_cap) Bài toán giả định như sau:\nGiả sử trường hợp sau, anh A có 10 đồng và quyết định đi đánh black jack (xì dách) với mục tiêu sẽ gấp đôi số tiền (20 đồng), mỗi trận thắng/thua anh A sẽ lời/mất 1 đồng. Anh A sử dụng chiến thuật với xác suất thắng trong 1 ván là (a) 50%, (b) 55%, (c) 45% thì xác suất anh A đạt được mục tiêu 20 đồng là bao nhiêu.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ### Closed-form solution p = 0.5 initial_cap = 10 expected_cap = 20 win_rate = round(win_probability(p, initial_cap, expected_cap),5) p = 0.55 win_rate = round(win_probability(p, initial_cap, expected_cap),5) p = 0.45 win_rate = round(win_probability(p, initial_cap, expected_cap),5) ----------------------------------- Output: Win rate: 0.5, Initial capital: 10, Expected capital: 20 Sucess rate: 50% ----------------------------------- Win rate: 0.55, Initial capital: 10, Expected capital: 20 Sucess rate: 88.15% ----------------------------------- Win rate: 0.45, Initial capital: 10, Expected capital: 20 Sucess rate: 11.85% ----------------------------------- Từ công thức trên, ta có thể tính toán được xác suất con bạc thắng chung cuộc. Vậy, trong thực tế, nó sẽ “trông” như thế nào nhỉ?\nTa tiến hành giả lập chuỗi thời gian của bài toán này. Từ xác suất trên, ta có thể tính toán được nhiều thứ. Giá trị kì vọng trong 3 trường hợp 0.5, 0.55, 0.45 lần lượt là 10, 18, 2. Với việc giả lập 30 lần, ta có thể thấy giá trị trung bình (hay kì vọng) cũng tiến tới mức này.\nThời gian kỳ vọng con bạc dừng lại Ngoài ra, dựa trên giả lập trên, ta cũng có thể nhận thấy 1 tính chất rằng, sẽ tới 1 thời gian là các chuỗi sẽ đạt tới điểm dừng (absorbing state). Nôm na là thời điểm kì vọng (hay trung bình) con bạc đạt được $N hoặc thua hết “xèng”.\nVới S là thời gian kỳ vọng, D là bước (step), ta có:\n$$ \\begin{align*} E(\\text{duration}) = E(\\text{duration}| \\text{win first round}) P(\\text{win first round}) \\\\+ E(\\text{duration}| \\text{lose first round}) P(\\text{lose first round})\\\\ \\end{align*}\\\\ $$$$ \\begin{align*} E_n(S) \u0026= E(S|D_1=n+1)p +E(S|D_1=n-1)q\\\\ \u0026= (1+E(S|D_0=n+1))p + (1+E(S|D_0=n-1))q\\\\ \u0026= p+q+E(S|D_0=n+1)p +E(S|D_0=n-1)q\\\\ \u0026= 1+E_{n+1}(S)p +E_{n-1}(S)q \\end{align*} $$$$ \\begin{align*} E_n(S) = \\frac{n}{q - p} - \\frac{N}{q - p} \\cdot \\frac{(\\frac{q}{p})^n - 1}{(\\frac{q}{p})^N - 1} \\end{align*} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def expected_duration(p, initial_cap, expected_cap): assert 0\u0026lt;= p \u0026lt;=1 , \u0026#34;`p` must be a probability between 0 and 1.\u0026#34; assert 0 \u0026lt;= initial_cap \u0026lt;= expected_cap, \u0026#34;`` an initial_cap integer between 0 and expected_cap.\u0026#34; very_small_number = 1e-12 q = 1-p lambda_ = q/p if lambda_==1: return initial_cap*(expected_cap - initial_cap) duration = ( initial_cap/(q-p) - expected_cap/(q-p)* ((lambda_**initial_cap-1)/(lambda_**expected_cap-1)) ) return duration ------- initial_cap = 10 expected_cap = 20 Win rate: 0.5, Expected duration: 100 Win rate: 0.45, Expected duration: 76.3 Win rate: 0.55, Expected duration: 76.3 Vậy, ta có thể tự tin nói rằng: Nếu xác suất của ván bài là 50/50 cho mỗi ván, thì kỳ vọng con bạc sẽ dừng cuộc chơi (cả thắng lẫn thua) sẽ là sau 100 ván. Còn nếu xác suất là 45% hoặc 55% thì (dự kiến) sau 77 ván con bạc sẽ dừng cuộc chơi.\nVN30F1M Bối cảnh về con bạc đã xong, giờ ta qua tới VN30F1. Ta sẽ trade với chiến lược siêu đơn giản như sau: Long giá mở cửa (Open) và đóng giá đóng cửa (Close). Với dữ liệu daily từ 2018 tới nay, ta thu được các kết quả như sau:\nTrung bình tăng: 9.21 Trung bình giảm: -10.14 Số ngày tăng: 777; Số ngày giảm 734 Xác suất tăng giảm hằng ngày: 51% Cũng khá tương đồng với bài toán black jack ở trên 🙂. Từ các tham số trên, ta mô hình hoá như sau: Xác suất lời lỗ là 50%, mỗi ngày tăng giảm trung bình 10 điểm. Giả sử bạn 1 số tiền đủ để bạn “risk” 200 điểm (~200tr). Bạn kỳ vọng sẽ gấp đôi trong 400 điểm. Để đưa về bài toán gambler’s ruin, ta cần chuẩn hoá lời lỗ về 1 điểm. Từ đó, thông số của bài toán sẽ là p=0.5, n=20, N= 40.\nSucess_prob = n/N = 20/40 = 50%\nExpected_duration = n*(N-n) = 20*(40-20) = 400 (days)\nLợi nhuận kỳ vọng: 40 * 50% + 0 * 50% = 20 (bằng số vốn ban đầu)\nTừ đó công thức ta có thể suy luận các ý như sau:\nKhi bạn kỳ vọng càng cao (so với số tiền bạn có) thì xác suất bạn thành công càng thấp và thời gian dự kiến bạn lỗ sạch càng nhanh. Bạn muốn tăng xác suất thành công thì nên có vốn dài (hay có nhiều tiền) 😃 Tăng xác suất thắng cho từng lần trade thì lợi nhuận kỳ vọng tăng và xác suất bạn thua sạch càng thấp. Giả lập VN30F1M cho các trường hợp xác suất thắng cho từng lần trade là 55%, 45% và 50%.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def simulation_plot(p, initial_cap, each_step, expected_cap, n, n_sim, expected_stopping = None,title = \u0026#39;Simulate Gambler Ruin\u0026#39;): capital = np.zeros((n_sim, n)) for i in range(n_sim): capital[i] = simulate_gambler_ruin(p, initial_cap, expected_cap, each_step, n) plt.figure(figsize=(15,5), dpi = 200) plt.plot(capital.T, alpha = 0.75) ## Mean and standard deviation plt.hlines(initial_cap, 0, n, colors=\u0026#39;black\u0026#39;, linestyles=\u0026#39;dashed\u0026#39;, label=\u0026#39;Initial capital\u0026#39;) # plt.fill_between(np.arange(n), np.min(capital, axis = 0), np.max(capital, axis = 0), color = \u0026#39;gray\u0026#39;, alpha = 0.5, label = \u0026#39;Mean +/- std\u0026#39;) #Mean plt.plot(np.mean(capital, axis = 0), color = \u0026#39;black\u0026#39;, linewidth = 2, label = \u0026#39;Mean\u0026#39;) if expected_stopping: plt.vlines(expected_stopping,0, expected_cap, colors=\u0026#39;black\u0026#39;, label=\u0026#39;Expected stopping point\u0026#39;) plt.title(title) plt.xlabel(\u0026#39;tradingDate\u0026#39;) plt.ylabel(\u0026#39;Cumulative points\u0026#39;) plt.show() return capital initial_cap = 200 each_step = 10 expected_cap = 400 n= 500 n_sim = 100 Với chiến lược có xác suất lời 55%, chỉ có 2 lần là bạn thua sạch tiền trong số 100 lần giả lập.\nTừ giả lập trên, ta có thể dễ dàng nhận ra 1 số tính chất cơ bản và nền móng của stochastic process như sau:\nNếu xác suất là p=0.5, giá trị kỳ vọng bằng đúng với giá trị ban đầu. Đây là tính chất martingale cơ bản trong stochastic process $E(X_n) = E(X_0) \\text{ với } n \\ge 0$ . Với p \u0026gt; 0.5, ta có thể thấy xu hướng của chuỗi thời gian có chiều hướng lên (positive drift), và ngược lại với. p\u0026lt; 0.5, xu hướng có chiều hướng xuống (negative drift). Giá trị của $X_{n+1}$ chỉ phụ thuộc vào $X_{n}$, hay giá trị của ngày hôm sau chỉ phụ thuộc vào ngày hôm nay và không phụ thuộc vào quá khứ trước đó. Đây là tính chất Markov. Variance của chuỗi thời gian này mở rộng theo thời gian (hay phụ thuộc vào thời gian t). Ngoài lề: Monte carlo simulation xấp xỉ các giá trị cần thiết Ngoài ra, dựa vào phương pháp giả lập (Monte carlo) này, ta có thể xấp xỉ các giá trị xác suất, kỳ vọng như phương pháp closed-form solution như trên. Dựa trên lý thuyết số lớn (Law of large number), bằng cách lấy mẫu ngẫu nhiên nhiều lần, ta có thể mô phỏng lại các trường hợp có thể xảy ra nhằm tính toán các giá trị mong muốn.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # tham số initial_cap = 200 each_step = 10 expected_cap = 400 ## giả lập n = 2000 # (giả lập tới vô cực; 2000 là cũng đủ lớn) n_sim = 20000 # (giả lập nhiều lần; 20000 là cũng đủ lớn) capital_up = simulation_plot(0.55, initial_cap, each_step, expected_cap, n, n_sim, title = \u0026#39;Simulate Gambler Ruin with positive drift (p\u0026gt;0.5)\u0026#39;) capital_down = simulation_plot(0.45, initial_cap, each_step, expected_cap, n, n_sim, title = \u0026#39;Simulate Gambler Ruin with negative drift (p\u0026lt;0.5)\u0026#39;) capital_neutral = simulation_plot(0.5, initial_cap, each_step, expected_cap, n, n_sim, title = \u0026#39;Simulate Gambler Ruin with no drift (p=0.5)\u0026#39;) def stopping_time(capital, threshold): ls_positive = [] ls_negative = [] for i in range(capital.shape[0]): ls_positive.append(np.argmax(capital[i,:]\u0026gt;=threshold)) ls_negative.append(np.argmax(capital[i,:]\u0026lt;=0)) # ls = ls_positive + ls_negative ls = pd.DataFrame([ls_positive, ls_negative]).sum(axis = 0).mean() return ls ## tính toán xác suất unique, counts = np.unique(capital_neutral[:,-1], return_counts=True) print(counts/np.sum(counts)) unique, counts = np.unique(capital_up[:,-1], return_counts=True) print(counts/np.sum(counts)) unique, counts = np.unique(capital_down[:,-1], return_counts=True) print(counts/np.sum(counts)) ## Tính toán stopping time stopping_time(capital_neutral, 400), stopping_time(capital_up, 400), stopping_time(capital_down, 400) Kết quả giả lập so với sử dụng closed-form như sau:\nSucess probability Expected duration p Simulation Closed-form Simulation Closed-form 0.5 0.4944 0.5 395.27 400 0.55 0.9803 0.98 190.263 192.9 0.45 0.0157 0.02 190.594 192.9 Từ đó, ta có thể thấy rằng, với những bài toán chưa có một cách giải “đẹp”, ta có thể tiến hành giả lập các trường hợp xảy ra như một phương án chữa cháy để tính toán các giá trị mong muốn. Tuy nhiên, ta phải đánh đổi bằng tốc độ và độ “đẹp” của kết quả.\nKết luận Okay, đã đủ cho bài giới thiệu về stochastic process rồi. Chúng ta đã cùng nhau đi qua nhiều thứ nền móng: (1) Gambler’s ruin để giới thiệu về stochastic process; (2) Giả lập cho VN30F1M; (3) Monte Carlo để đi xấp xỉ các giá trị cần thiết.\nThông qua bài viết trên, bạn đã nắm được gì:\nNền móng cho việc “gambling”: dựa vào xác suất, vốn của bạn, và kỳ vọng, bạn có thể gamble tốt hơn rồi đó. Trước khi bắt đầu bet vào một thứ gì đó, hãy chậm lại 1 bước, suy nghĩ về toán một tí, rồi mới quyết định chơi hay không. Hay đúng không nào ^^ Khi gặp 1 bài toán và bí. Hãy đi giả lập nó để xấp xỉ trước kết quả cuối cùng. Strategy phái sinh có xác suất thắng dưới 50% thì nên xem xét lại. Nền móng cho vài tính chất cơ bản của stochastic process. Ngoài ra, mình có để những bài viết rất hay của chủ đề tương tự ở phần ref, bạn nên nghía qua để hiểu sâu hơn về phần toán ở phía dưới nhé!\nRef https://randomdeterminism.wordpress.com/2010/07/07/gamblers-ruin/\nhttps://web.mit.edu/neboat/Public/6.042/randomwalks.pdf\nhttps://sites.pitt.edu/~jdnorton/teaching/paradox/chapters/probability_from_expectation/gambler_ruin.pdf\nhttps://en.wikipedia.org/wiki/Monte_Carlo_method#:~:text=Sawilowsky distinguishes between a simulation,uses repeated sampling to obtain\n","permalink":"http://localhost:1313/posts/2024/2024-10-20-stochastic-process-part-1/","summary":"Bài viết giới thiệu về quá trình ngẫu nhiên thông qua bài toán Gambler\u0026rsquo;s Ruin. Bài viết cũng mô phỏng chiến lược giao dịch VN30F1M và sử dụng phương pháp Monte Carlo để xấp xỉ các giá trị cần thiết, nhấn mạnh tầm quan trọng của xác suất và kỳ vọng trong việc ra quyết định.","title":"Stochastic process part 1: Gambler's ruin of VN30F"},{"content":"Hôm nay, chúng ta sẽ cùng nhau thảo luận về các phương pháp khác nhau để giải quyết bài toán Linear regression - Hồi quy tuyến tính.\nVậy Linear regression là gì? Hồi quy tuyến tính là phương pháp thống kê dùng để mô hình hóa mối quan hệ giữa biến phụ thuộc và các biến độc lập. Hay nói cách khác, hồi quy tuyến tính là đi tìm mối quan hệ tuyến tính (y=ax+b) giữa 2 biến với nhau.\nỞ bài này, mình sẽ không bàn luận sâu về toán, các bạn có thể đọc ở đây để nắm lý thuyết cần thiết link. Thay vào đó, bài viết này sẽ đi thực hiện bài toán đơn giản này theo 3 cách tiếp cận khác nhau:\nSử dụng linear algebra để tính trực tiếp Thông qua deep learning, sử dụng đạo hàm Thông qua bayesian inference, sử dụng phương pháp lấy mẫu (sampling) Ngoài ra, bài viết sẽ áp dụng phương pháp này để đi xác định hệ số Beta cho cổ phiếu HPG. Các bạn có thể đọc về beta tại đây.\nỞ bài toán này, dữ liệu X sẽ là VNINDEX, trong khi y sẽ là HPG.\nVề mặt tài chính, điều này có thể được xem như là ước tính rủi ro thị trường, hay rủi ro hệ thống (market risk, systematic risk) cho HPG.\n1. Tính trực tiếp từ dữ liệu Lời giả cho phương pháp này là:\n$$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top y $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Algebra_linear_regression: def __init__(self): self.coef_ = None self.intercept_ = None def fit(self, X, y): X = np.array(X) y = np.array(y) X = np.c_[np.ones(X.shape[0]), X] self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y self.intercept_ = self.coef_[0] self.coef_ = self.coef_[1:] def predict(self, X): X = np.array(X) return X @ self.coef_ + self.intercept_ def score(self, X, y): X = np.array(X) y = np.array(y) y_pred = self.predict(X) return 1 - ((y - y_pred) ** 2).sum() / ((y - y.mean()) ** 2).sum() model = Algebra_linear_regression() model.fit(X,y) model.coef_.round(3), model.intercept_.round(4) -\u0026gt; output: (array([[1.23]]), array([0.0005])) Từ phương pháp này, ta có thể ước lượng được rằng hệ số beta cho cổ phiếu HPG là 1.23 tương ứng với việc rủi ro thị trường tương đối cao.\n2. Sử dụng deep learning Deep learning cũng là một trong những phương pháp thông dụng có thể được sử dụng trong bài toán này. Thông qua thuật toán Gradient Descent, ta có đi tìm bộ tham số phù hợp với hàm mất mát (loss function) là thấp nhất.\nQuá trình đi tìm điểm tối ưu của bài toán này giống như khi bạn đi xuống núi. Ban đầu, bạn sẽ bắt đầu ở một điểm nào đó, tại mỗi điểm bạn sẽ luôn biết nên đi hướng nào. Mục tiêu của bạn sẽ đi xuống núi từng bước nhỏ một. Bạn cứ liên tục đi cho đến khi bạn đạt đến điểm trũng của thung lũng!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import torch import torch.nn as nn # Create class class LinearRegressionModel(nn.Module): def __init__(self, input_dim, output_dim): super(LinearRegressionModel, self).__init__() self.linear = nn.Linear(input_dim, output_dim) def forward(self, x): out = self.linear(x) return out input_dim = 1 output_dim = 1 model = LinearRegressionModel(input_dim, output_dim) criterion = nn.MSELoss() learning_rate = 0.001 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) epochs = 1000 losses = [] # List to store loss at each epoch for epoch in range(epochs): epoch += 1 # Convert numpy array to torch Variable inputs = torch.from_numpy(X).requires_grad_() labels = torch.from_numpy(y) # Clear gradients w.r.t. parameters optimizer.zero_grad() # Forward to get output outputs = model(inputs) # Calculate Loss loss = criterion(outputs, labels) # Getting gradients w.r.t. parameters loss.backward() # Updating parameters optimizer.step() losses.append(loss.item()) print(\u0026#39;epoch {}, loss {}\u0026#39;.format(epoch, loss.item())) Thông qua phương pháp này, ta cũng tìm được mối quan hệ giống hệt với phương pháp tính trực tiếp!\n3. Bayesian linear regression Thay vì chỉ đưa ra một giá trị cố định cho các hệ số như hồi quy tuyến tính thông thường, phương pháp bayes coi các hệ số là những giá trị có thể thay đổi và có xác suất xảy ra. Ban đầu, ta có một \u0026ldquo;niềm tin\u0026rdquo; về các tham số này (prior). Khi thu thập thêm dữ liệu, ta sẽ cập nhật niềm tin đó, từ đó giúp dự đoán chính xác hơn và biết mức độ chắc chắn của các kết quả (posterior). Khoá Coursera này sẽ cho bạn cái nhìn kĩ hơn về phương pháp này.\nĐể hiểu đơn giản hơn, ta có một ví dụ này: Với 2 phương pháp trên, hệ số beta của HPG là 1.23. Vậy có bao nhiêu phần trăm (%) hệ số beta là 1.23, hệ số beta lớn hơn 1 với độ tự tin bao nhiêu phần trăm (%)? Giá trị của hệ số beta của HPG có thể có giá trị từ đâu tới đâu với độ tư tin là bao nhiêu phần trăm (%)?\nĐây là một trong những vấn đề có thể được giải quyết thông qua phương pháp Bayes. Bạn có thể đọc kĩ hơn về ý tưởng đằng sau phương pháp này tại đây.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def numpyro_model(X, y): # Priors for the parameters num_features = X.shape[1] beta = numpyro.sample(\u0026#34;beta\u0026#34;, dist.Normal(0,1)) # Coefficients intercept = numpyro.sample(\u0026#34;intercept\u0026#34;, dist.Normal(0, 1)) # Intercept sigma = numpyro.sample(\u0026#34;sigma\u0026#34;, dist.Normal(0,1)) # Noise level # Linear model mean = jnp.dot(X, beta) + intercept # Likelihood numpyro.sample(\u0026#34;obs\u0026#34;, dist.Normal(mean, sigma), obs=y) # Instantiate a `MCMC` object using a NUTS sampler mcmc = MCMC(sampler=NUTS(numpyro_model), num_warmup=1000, num_samples=1000, num_chains=4) # Run the MCMC sampler and collect samples mcmc.run(rng_key=random.PRNGKey(seed=42), X=X, y=y) az.plot_trace(mcmc, var_names=[\u0026#39;intercept\u0026#39;, \u0026#39;beta\u0026#39;, \u0026#39;sigma\u0026#39;], figsize=(9,9)); $$ Y = \\beta_0 + \\beta_1 X + \\epsilon $$ Phương pháp biểu diễn các biến trong Bayesian inference (plate notation). Ở bài toán này, ta sẽ có 3 biến chính: beta, intercept và sigma. Tất cả đều được giả định là phân phối chuẩn.\nmean std median 5.0% 95.0% n_eff r_hat beta 1.23 0.03 1.23 1.18 1.28 734.39 1.01 intercept 0.00 0.00 0.00 -0.00 0.00 3212.78 1.00 sigma 0.02 0.00 0.02 0.02 0.02 5063.55 1.00 Hình này được gọi là trace plot. Phương pháp này được dùng để đánh giá quá trình hội tụ của mô hình Bayes. Cột bên trái cho ta thấy phân phối, trong khi bên phải cho ta thấy sự giao động của các tham số.\nTừ kết quả mô hình trên, ta ra được kết luận rằng, hệ số beta trung bình cho cổ phiếu HPG cũng là 1.23, và ta có thể tự tin nói rằng, 90% trường hợp hệ số beta của HPG sẽ trong vùng 1.18 - 1.23.\nKết luận Từ 3 phương pháp trên ta đều thu được chung 1 kết quả. Ngoài ra, mỗi phương pháp có ưu và nhược điểm của mình.\nVới phương pháp tính toán trực tiếp, ta có thể dễ dàng tính toán ra được đáp án với độ phức tạp là thấp nhất. Tuy nhiên, với những trường hợp mà dữ liệu là không khả nghịch (singular), thì bài toán có khả năng không có khả năng giải được theo phương pháp này (analytical solution).\nNgược lại, với phương pháp deep learning, ta có thể dễ dàng xử lý các bài toán khi không thể giải trực tiếp (analytical solution). Thông qua Gradient Descent, ta có thể ước tính được các điểm tối ưu, tuy nhiên đi kèm với đó là yêu cầu tính toán lớn hơn nhiều (computational cost).\nCuối cùng, phương pháp Bayesian có thể được sử dụng khi ta mong muốn đưa niềm tin của ta vào mô hình, cũng như đầu ra mong muốn là một phân phối các kết quả có thể xảy ra thay vì chỉ muốn một điểm ước lượng duy nhất. Quan trọng nhất là mô hình hoá được độ không chắc chắn (uncertainty). Tuy nhiên, yếu tố giả định của người sử dụng có thể có tác động tiêu cực đến mô hình nếu giả định sai.\nVà tất nhiên, 2 phương pháp sau là phức tạp hoá vấn đề cho bài toán đơn giản này. Tuy nhiên, để gần gũi nhất thì mình chọn ước lượng beta cho dễ hình dung!\n","permalink":"http://localhost:1313/posts/2024/2024-10-10-linear-regression/","summary":"\u003cp\u003eHôm nay, chúng ta sẽ cùng nhau thảo luận về các phương pháp khác nhau để giải quyết bài toán Linear regression - Hồi quy tuyến tính.\u003c/p\u003e\n\u003ch2 id=\"vậy-linear-regression-là-gì\"\u003eVậy Linear regression là gì?\u003c/h2\u003e\n\u003cp\u003eHồi quy tuyến tính là phương pháp thống kê dùng để mô hình hóa mối quan hệ giữa biến phụ thuộc và các biến độc lập. Hay nói cách khác, hồi quy tuyến tính là đi tìm mối quan hệ tuyến tính (y=ax+b) giữa 2 biến với nhau.\u003c/p\u003e","title":"Linear regression"},{"content":"Hi, mình là Hùng.\nHiện mình là sinh viên thạc sĩ AI tại RMIT Vietnam với đam mê dành cho mảng đầu tư định lượng (Quant).\nBlog này là nơi mình chia sẻ kiến thức (đa phần là lưu trữ cái mình học) và nếu nó giúp được bạn trong chuyến phiêu lưu ngành quant thì mình rất vui!\nCác mảng yêu thích Ứng dụng: Learning to Rank, Probabilistic forecasting, Network Science … Lý thuyết: Causal ML, Bayesian Inference, Stochastic process … Tài chính: Portfolio optimization, Asset pricing, Factor investing, … Rất mong muốn hợp tác để thực hiện publication (không giới hạn vào các chủ đề trên) Học vấn MSc Artificial Intelligent (RMIT Vietnam) BSc Economics \u0026amp; Finance (RMIT Vietnam) CFA lev 1 Self taught Data Sci \u0026amp; Quant! Liên hệ Email: hungha1412@gmail.com LinkedIn: qhung ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eHi, mình là Hùng.\u003c/p\u003e\n\u003cp\u003eHiện mình là sinh viên thạc sĩ AI tại RMIT Vietnam với đam mê dành cho mảng đầu tư định lượng (Quant).\u003c/p\u003e\n\u003cp\u003eBlog này là nơi mình chia sẻ kiến thức (đa phần là lưu trữ cái mình học) và nếu nó giúp được bạn trong chuyến phiêu lưu ngành quant thì mình rất vui!\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"các-mảng-yêu-thích\"\u003eCác mảng yêu thích\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eỨng dụng: Learning to Rank, Probabilistic forecasting, Network Science …\u003c/li\u003e\n\u003cli\u003eLý thuyết: Causal ML, Bayesian Inference, Stochastic process …\u003c/li\u003e\n\u003cli\u003eTài chính: Portfolio optimization, Asset pricing, Factor investing, …\u003c/li\u003e\n\u003cli\u003eRất mong muốn hợp tác để thực hiện publication (không giới hạn vào các chủ đề trên)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003chr\u003e\n\u003ch2 id=\"học-vấn\"\u003eHọc vấn\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eMSc Artificial Intelligent (RMIT Vietnam)\u003c/li\u003e\n\u003cli\u003eBSc Economics \u0026amp; Finance (RMIT Vietnam)\u003c/li\u003e\n\u003cli\u003eCFA lev 1\u003c/li\u003e\n\u003cli\u003eSelf taught Data Sci \u0026amp; Quant!\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"liên-hệ\"\u003eLiên hệ\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eEmail: \u003ca href=\"mailto:hungha1412@gmail.com\"\u003ehungha1412@gmail.com\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eLinkedIn: \u003ca href=\"https://www.linkedin.com/in/haquochung11/\"\u003eqhung\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"About"},{"content":"","permalink":"http://localhost:1313/blog/","summary":"blog","title":"Blog"},{"content":"","permalink":"http://localhost:1313/research/","summary":"","title":"Research"}]